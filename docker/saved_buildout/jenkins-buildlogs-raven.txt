Started by user Long Vu
 > git rev-parse --is-inside-work-tree # timeout=10
Setting origin to https://github.com/Ouranosinc/PAVICS-e2e-workflow-tests.git
 > git config remote.origin.url https://github.com/Ouranosinc/PAVICS-e2e-workflow-tests.git # timeout=10
Fetching origin...
Fetching upstream changes from origin
 > git --version # timeout=10
 > git config --get remote.origin.url # timeout=10
 > git fetch --tags --progress -- origin +refs/heads/*:refs/remotes/origin/* # timeout=10
Seen branch in repository origin/current-production-version
Seen branch in repository origin/devel-new-extensions
Seen branch in repository origin/extended_tests
Seen branch in repository origin/force-newer-intake
Seen branch in repository origin/make-it-easier-to-add-new-nb-or-repos
Seen branch in repository origin/master
Seen branch in repository origin/new-docker-build
Seen branch in repository origin/pin-jupyter-env
Seen branch in repository origin/test-dockerhub-build
Seen branch in repository origin/twitcher_perf_test_notebook
Seen 10 remote branches
Obtained Jenkinsfile from 79171bfd1cffa6c4c2510b9979d343573ad64126
Running in Durability level: MAX_SURVIVABILITY
[Pipeline] Start of Pipeline
[Pipeline] node
Running on linux1 in /home/jenkins/agent/workspace/_workflow-tests_new-docker-build@2
[Pipeline] {
[Pipeline] stage
[Pipeline] { (Declarative: Checkout SCM)
[Pipeline] checkout
No credentials specified
Fetching changes from the remote Git repository
Fetching without tags
Checking out Revision 79171bfd1cffa6c4c2510b9979d343573ad64126 (new-docker-build)
Commit message: "release: update to use image pavics/workflow-tests:py311-250109"
 > git rev-parse --is-inside-work-tree # timeout=10
 > git config remote.origin.url https://github.com/Ouranosinc/PAVICS-e2e-workflow-tests.git # timeout=10
Fetching upstream changes from https://github.com/Ouranosinc/PAVICS-e2e-workflow-tests.git
 > git --version # timeout=10
 > git fetch --no-tags --progress -- https://github.com/Ouranosinc/PAVICS-e2e-workflow-tests.git +refs/heads/*:refs/remotes/origin/* # timeout=10
 > git config core.sparsecheckout # timeout=10
 > git checkout -f 79171bfd1cffa6c4c2510b9979d343573ad64126 # timeout=10
 > git rev-list --no-walk 79171bfd1cffa6c4c2510b9979d343573ad64126 # timeout=10
[Pipeline] }
[Pipeline] // stage
[Pipeline] withEnv
[Pipeline] {
[Pipeline] isUnix
[Pipeline] sh
+ docker inspect -f . pavics/workflow-tests:py311-250109
.
[Pipeline] withDockerContainer
linux1 seems to be running inside container 6ca2491e7f43a3bf757202f625309feff7bf027df899f42e43bc71ba740ac9b6
$ docker run -t -d -u 1000:1000 -w /home/jenkins/agent/workspace/_workflow-tests_new-docker-build@2 --volumes-from 6ca2491e7f43a3bf757202f625309feff7bf027df899f42e43bc71ba740ac9b6 -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** pavics/workflow-tests:py311-250109 cat
$ docker top e606fce6e884cbfc727842848edd63e06ef3529ac74bebbe6cb9fd762aa3c6d2 -eo pid,comm
[Pipeline] {
[Pipeline] ansiColor
[Pipeline] {
[Pipeline] timestamps
[Pipeline] {
[Pipeline] timeout
[2025-01-09T19:22:19.551Z] Timeout set to expire in 2 hr 0 min
[Pipeline] {
[Pipeline] stage
[Pipeline] { (Run tests)
[Pipeline] script
[Pipeline] {
[Pipeline] withCredentials
[2025-01-09T19:22:19.692Z] Masking supported pattern matches of $ESGF_AUTH_USERNAME or $ESGF_AUTH_PASSWORD or $ESGF_AUTH_TOKEN or $COMPUTE_TOKEN
[Pipeline] {
[Pipeline] sh
[2025-01-09T19:22:20.002Z] + VERIFY_SSL=true SAVE_RESULTING_NOTEBOOK=true ./testall
[2025-01-09T19:22:20.002Z] TEST_PAVICS_SDI_REPO has been set to 'true'
[2025-01-09T19:22:20.002Z] PAVICS_SDI_BRANCH has been set to 'master'
[2025-01-09T19:22:20.002Z] PAVICS_SDI_REPO has been set to 'Ouranosinc/pavics-sdi'
[2025-01-09T19:22:20.002Z] TEST_FINCH_REPO has been set to 'true'
[2025-01-09T19:22:20.002Z] FINCH_BRANCH has been set to 'master'
[2025-01-09T19:22:20.002Z] FINCH_REPO has been set to 'bird-house/finch'
[2025-01-09T19:22:20.002Z] TEST_PAVICS_LANDING_REPO has been set to 'true'
[2025-01-09T19:22:20.002Z] PAVICS_LANDING_BRANCH has been set to 'master'
[2025-01-09T19:22:20.002Z] PAVICS_LANDING_REPO has been set to 'Ouranosinc/PAVICS-landing'
[2025-01-09T19:22:20.002Z] TEST_RAVEN_REPO has been set to 'false'
[2025-01-09T19:22:20.002Z] RAVEN_BRANCH has been set to 'main'
[2025-01-09T19:22:20.002Z] RAVEN_REPO has been set to 'Ouranosinc/raven'
[2025-01-09T19:22:20.002Z] TEST_RAVENPY_REPO has been set to 'false'
[2025-01-09T19:22:20.002Z] RAVENPY_BRANCH has been set to 'master'
[2025-01-09T19:22:20.002Z] RAVENPY_REPO has been set to 'CSHS-CWRA/RavenPy'
[2025-01-09T19:22:20.002Z] TEST_ESGF_COMPUTE_API_REPO has been set to 'false'
[2025-01-09T19:22:20.002Z] ESGF_COMPUTE_API_BRANCH has been set to 'devel'
[2025-01-09T19:22:20.002Z] ESGF_COMPUTE_API_REPO has been set to 'ESGF/esgf-compute-api'
[2025-01-09T19:22:20.002Z] TEST_LOCAL_NOTEBOOKS has been set to 'true'
[2025-01-09T19:22:20.002Z] + [ -n https://gist.githubusercontent.com/tlvu/813a1bcd325d753664c09526e4a5b759/raw/528d77c2553ce500553332279902b04f8a04ebe1/jenkins-params-raven-nb-only.include.sh ]
[2025-01-09T19:22:20.002Z] + TMP_PARAMS_OVERRIDE=/tmp/jenkins_params_override
[2025-01-09T19:22:20.002Z] + rm -vf /tmp/jenkins_params_override
[2025-01-09T19:22:20.002Z] removed '/tmp/jenkins_params_override'
[2025-01-09T19:22:20.002Z] + curl --silent https://gist.githubusercontent.com/tlvu/813a1bcd325d753664c09526e4a5b759/raw/528d77c2553ce500553332279902b04f8a04ebe1/jenkins-params-raven-nb-only.include.sh
[2025-01-09T19:22:20.002Z] + tee /tmp/jenkins_params_override
[2025-01-09T19:22:20.260Z] #!/bin/sh
[2025-01-09T19:22:20.260Z] # https://github.com/Ouranosinc/PAVICS-e2e-workflow-tests/blob/master/test-override/jenkins-params-raven-nb-only.include.sh
[2025-01-09T19:22:20.260Z] 
[2025-01-09T19:22:20.260Z] # Sample Jenkins params override script to only run Raven notebooks
[2025-01-09T19:22:20.260Z] # with the proper --nbval-lax switch.
[2025-01-09T19:22:20.260Z] 
[2025-01-09T19:22:20.260Z] # Disable default repos.
[2025-01-09T19:22:20.260Z] TEST_PAVICS_SDI_REPO="false"
[2025-01-09T19:22:20.260Z] TEST_FINCH_REPO="false"
[2025-01-09T19:22:20.260Z] TEST_PAVICS_LANDING_REPO="false"
[2025-01-09T19:22:20.260Z] TEST_LOCAL_NOTEBOOKS="false"
[2025-01-09T19:22:20.260Z] 
[2025-01-09T19:22:20.260Z] # Enable raven repos.
[2025-01-09T19:22:20.260Z] TEST_RAVEN_REPO="true"
[2025-01-09T19:22:20.260Z] TEST_RAVENPY_REPO="true"
[2025-01-09T19:22:20.260Z] 
[2025-01-09T19:22:20.260Z] # Raven nbs outputs are not fully up-to-date or regexed escaped properly like
[2025-01-09T19:22:20.260Z] # the other default nbs so need --nbval-lax for the moment.
[2025-01-09T19:22:20.260Z] PYTEST_EXTRA_OPTS="$PYTEST_EXTRA_OPTS --nbval-lax"
[2025-01-09T19:22:20.260Z] 
[2025-01-09T19:22:20.260Z] # Set different test branch if required.
[2025-01-09T19:22:20.260Z] #RAVEN_BRANCH=""
[2025-01-09T19:22:20.260Z] #RAVENPY_BRANCH=""
[2025-01-09T19:22:20.260Z] 
[2025-01-09T19:22:20.260Z] ######################
[2025-01-09T19:22:20.260Z] 
[2025-01-09T19:22:20.260Z] SAVE_RESULTING_NOTEBOOK_TIMEOUT="600"+ . /tmp/jenkins_params_override
[2025-01-09T19:22:20.260Z] + TEST_PAVICS_SDI_REPO=false
[2025-01-09T19:22:20.260Z] + TEST_FINCH_REPO=false
[2025-01-09T19:22:20.260Z] + TEST_PAVICS_LANDING_REPO=false
[2025-01-09T19:22:20.260Z] + TEST_LOCAL_NOTEBOOKS=false
[2025-01-09T19:22:20.260Z] + TEST_RAVEN_REPO=true
[2025-01-09T19:22:20.260Z] + TEST_RAVENPY_REPO=true
[2025-01-09T19:22:20.260Z] + PYTEST_EXTRA_OPTS=--dist=loadscope --numprocesses=0 --nbval-lax
[2025-01-09T19:22:20.260Z] + SAVE_RESULTING_NOTEBOOK_TIMEOUT=600
[2025-01-09T19:22:20.260Z] + git clean -fdx
[2025-01-09T19:22:20.260Z] Removing .pytest_cache/
[2025-01-09T19:22:20.260Z] Removing PAVICS-landing-master/
[2025-01-09T19:22:20.260Z] Removing RavenPy-master/
[2025-01-09T19:22:20.260Z] Removing __pycache__/
[2025-01-09T19:22:20.260Z] Removing buildout/
[2025-01-09T19:22:20.260Z] Removing esgf-compute-api-devel/
[2025-01-09T19:22:20.260Z] Removing finch-master/
[2025-01-09T19:22:20.260Z] Removing pavics-sdi-master/
[2025-01-09T19:22:20.260Z] Removing raven-main/
[2025-01-09T19:22:20.260Z] + ./downloadrepos
[2025-01-09T19:22:20.260Z] TEST_PAVICS_SDI_REPO has been set to 'false'
[2025-01-09T19:22:20.260Z] PAVICS_SDI_BRANCH has been set to 'master'
[2025-01-09T19:22:20.260Z] PAVICS_SDI_REPO has been set to 'Ouranosinc/pavics-sdi'
[2025-01-09T19:22:20.260Z] TEST_FINCH_REPO has been set to 'false'
[2025-01-09T19:22:20.260Z] FINCH_BRANCH has been set to 'master'
[2025-01-09T19:22:20.260Z] FINCH_REPO has been set to 'bird-house/finch'
[2025-01-09T19:22:20.260Z] TEST_PAVICS_LANDING_REPO has been set to 'false'
[2025-01-09T19:22:20.260Z] PAVICS_LANDING_BRANCH has been set to 'master'
[2025-01-09T19:22:20.260Z] PAVICS_LANDING_REPO has been set to 'Ouranosinc/PAVICS-landing'
[2025-01-09T19:22:20.260Z] TEST_RAVEN_REPO has been set to 'true'
[2025-01-09T19:22:20.260Z] RAVEN_BRANCH has been set to 'main'
[2025-01-09T19:22:20.260Z] RAVEN_REPO has been set to 'Ouranosinc/raven'
[2025-01-09T19:22:20.260Z] TEST_RAVENPY_REPO has been set to 'true'
[2025-01-09T19:22:20.260Z] RAVENPY_BRANCH has been set to 'master'
[2025-01-09T19:22:20.260Z] RAVENPY_REPO has been set to 'CSHS-CWRA/RavenPy'
[2025-01-09T19:22:20.260Z] TEST_ESGF_COMPUTE_API_REPO has been set to 'false'
[2025-01-09T19:22:20.260Z] ESGF_COMPUTE_API_BRANCH has been set to 'devel'
[2025-01-09T19:22:20.260Z] ESGF_COMPUTE_API_REPO has been set to 'ESGF/esgf-compute-api'
[2025-01-09T19:22:20.260Z] TEST_LOCAL_NOTEBOOKS has been set to 'false'
[2025-01-09T19:22:20.260Z] + rm -rf pavics-sdi-*
[2025-01-09T19:22:20.260Z] + ls
[2025-01-09T19:22:20.260Z] + grep pavics-sdi
[2025-01-09T19:22:20.260Z] + downloadrepos https://github.com/Ouranosinc/pavics-sdi master
[2025-01-09T19:22:20.260Z] + github_repo=https://github.com/Ouranosinc/pavics-sdi
[2025-01-09T19:22:20.260Z] + shift
[2025-01-09T19:22:20.260Z] + branch=master
[2025-01-09T19:22:20.260Z] + shift
[2025-01-09T19:22:20.260Z] + wget --quiet --output-document - https://github.com/Ouranosinc/pavics-sdi/archive/master.tar.gz
[2025-01-09T19:22:20.260Z] + tar xz
[2025-01-09T19:22:22.774Z] + ls
[2025-01-09T19:22:22.774Z] + grep pavics-sdi
[2025-01-09T19:22:22.774Z] pavics-sdi-master
[2025-01-09T19:22:22.774Z] + set +x
[2025-01-09T19:22:22.774Z] + rm -rf finch-*
[2025-01-09T19:22:22.774Z] + ls
[2025-01-09T19:22:22.774Z] + grep finch
[2025-01-09T19:22:22.774Z] + downloadrepos https://github.com/bird-house/finch master
[2025-01-09T19:22:22.774Z] + github_repo=https://github.com/bird-house/finch
[2025-01-09T19:22:22.774Z] + shift
[2025-01-09T19:22:22.774Z] + branch=master
[2025-01-09T19:22:22.774Z] + shift
[2025-01-09T19:22:22.774Z] + wget --quiet --output-document - https://github.com/bird-house/finch/archive/master.tar.gz+ 
[2025-01-09T19:22:22.774Z] tar xz
[2025-01-09T19:22:24.663Z] + ls
[2025-01-09T19:22:24.663Z] + grep finch
[2025-01-09T19:22:24.663Z] finch-master
[2025-01-09T19:22:24.663Z] + set +x
[2025-01-09T19:22:24.663Z] + rm -rf PAVICS-landing-*
[2025-01-09T19:22:24.663Z] + ls
[2025-01-09T19:22:24.663Z] + grep PAVICS-landing
[2025-01-09T19:22:24.664Z] + downloadrepos https://github.com/Ouranosinc/PAVICS-landing master
[2025-01-09T19:22:24.664Z] + github_repo=https://github.com/Ouranosinc/PAVICS-landing
[2025-01-09T19:22:24.664Z] + shift
[2025-01-09T19:22:24.664Z] + branch=master
[2025-01-09T19:22:24.664Z] + shift
[2025-01-09T19:22:24.664Z] + wget --quiet --output-document - https://github.com/Ouranosinc/PAVICS-landing/archive/master.tar.gz
[2025-01-09T19:22:24.664Z] + tar xz
[2025-01-09T19:22:36.821Z] + + ls
[2025-01-09T19:22:36.821Z] grep PAVICS-landing
[2025-01-09T19:22:36.821Z] PAVICS-landing-master
[2025-01-09T19:22:36.821Z] + set +x
[2025-01-09T19:22:36.821Z] + rm -rf raven-*
[2025-01-09T19:22:36.821Z] + ls
[2025-01-09T19:22:36.821Z] + grep raven
[2025-01-09T19:22:36.821Z] + downloadrepos https://github.com/Ouranosinc/raven main
[2025-01-09T19:22:36.821Z] + github_repo=https://github.com/Ouranosinc/raven
[2025-01-09T19:22:36.821Z] + shift
[2025-01-09T19:22:36.821Z] + branch=main
[2025-01-09T19:22:36.821Z] + shift
[2025-01-09T19:22:36.821Z] + wget --quiet --output-document - https://github.com/Ouranosinc/raven/archive/main.tar.gz
[2025-01-09T19:22:36.821Z] + tar xz
[2025-01-09T19:22:37.747Z] + ls
[2025-01-09T19:22:37.747Z] + grep raven
[2025-01-09T19:22:37.747Z] raven-main
[2025-01-09T19:22:37.747Z] + set +x
[2025-01-09T19:22:37.747Z] + rm -rf RavenPy-*
[2025-01-09T19:22:37.747Z] + ls
[2025-01-09T19:22:37.747Z] + grep RavenPy
[2025-01-09T19:22:37.747Z] + downloadrepos https://github.com/CSHS-CWRA/RavenPy master
[2025-01-09T19:22:37.747Z] + github_repo=https://github.com/CSHS-CWRA/RavenPy
[2025-01-09T19:22:37.747Z] + shift
[2025-01-09T19:22:37.747Z] + branch=master
[2025-01-09T19:22:37.747Z] + shift
[2025-01-09T19:22:37.747Z] + wget --quiet --output-document - https://github.com/CSHS-CWRA/RavenPy/archive/master.tar.gz
[2025-01-09T19:22:37.747Z] + tar xz
[2025-01-09T19:22:39.680Z] + ls
[2025-01-09T19:22:39.680Z] + grep RavenPy
[2025-01-09T19:22:39.680Z] RavenPy-master
[2025-01-09T19:22:39.680Z] + set +x
[2025-01-09T19:22:39.680Z] + rm -rf esgf-compute-api-*
[2025-01-09T19:22:39.680Z] + ls
[2025-01-09T19:22:39.680Z] + grep esgf-compute-api
[2025-01-09T19:22:39.680Z] + downloadrepos https://github.com/ESGF/esgf-compute-api devel
[2025-01-09T19:22:39.681Z] + github_repo=https://github.com/ESGF/esgf-compute-api
[2025-01-09T19:22:39.681Z] + shift
[2025-01-09T19:22:39.681Z] + branch=devel
[2025-01-09T19:22:39.681Z] + shift
[2025-01-09T19:22:39.681Z] + wget --quiet --output-document - https://github.com/ESGF/esgf-compute-api/archive/devel.tar.gz
[2025-01-09T19:22:39.681Z] + tar xz
[2025-01-09T19:22:40.604Z] + + ls
[2025-01-09T19:22:40.604Z] grep esgf-compute-api
[2025-01-09T19:22:40.604Z] esgf-compute-api-devel
[2025-01-09T19:22:40.604Z] + set +x
[2025-01-09T19:22:40.604Z] + echo master
[2025-01-09T19:22:40.604Z] + sed s@/@-@g
[2025-01-09T19:22:40.604Z] + export PAVICS_SDI_BRANCH=master
[2025-01-09T19:22:40.604Z] + echo Ouranosinc/pavics-sdi
[2025-01-09T19:22:40.604Z] + sed s@^.*/@@g
[2025-01-09T19:22:40.604Z] + export PAVICS_SDI_REPO_NAME=pavics-sdi
[2025-01-09T19:22:40.604Z] + echo master
[2025-01-09T19:22:40.604Z] + sed s@/@-@g
[2025-01-09T19:22:40.604Z] + export FINCH_BRANCH=master
[2025-01-09T19:22:40.604Z] + echo bird-house/finch
[2025-01-09T19:22:40.604Z] + sed s@^.*/@@g
[2025-01-09T19:22:40.604Z] + export FINCH_REPO_NAME=finch
[2025-01-09T19:22:40.604Z] + echo master
[2025-01-09T19:22:40.604Z] + sed s@/@-@g
[2025-01-09T19:22:40.604Z] + export PAVICS_LANDING_BRANCH=master
[2025-01-09T19:22:40.604Z] + echo Ouranosinc/PAVICS-landing
[2025-01-09T19:22:40.604Z] + sed s@^.*/@@g
[2025-01-09T19:22:40.604Z] + export PAVICS_LANDING_REPO_NAME=PAVICS-landing
[2025-01-09T19:22:40.604Z] + echo main
[2025-01-09T19:22:40.604Z] + sed s@/@-@g
[2025-01-09T19:22:40.604Z] + export RAVEN_BRANCH=main
[2025-01-09T19:22:40.604Z] + echo Ouranosinc/raven
[2025-01-09T19:22:40.604Z] + sed s@^.*/@@g
[2025-01-09T19:22:40.604Z] + export RAVEN_REPO_NAME=raven
[2025-01-09T19:22:40.604Z] + echo master
[2025-01-09T19:22:40.604Z] + sed s@/@-@g
[2025-01-09T19:22:40.604Z] + export RAVENPY_BRANCH=master
[2025-01-09T19:22:40.604Z] + echo CSHS-CWRA/RavenPy
[2025-01-09T19:22:40.604Z] + sed s@^.*/@@g
[2025-01-09T19:22:40.604Z] + export RAVENPY_REPO_NAME=RavenPy
[2025-01-09T19:22:40.604Z] + echo devel
[2025-01-09T19:22:40.604Z] + sed s@/@-@g
[2025-01-09T19:22:40.604Z] + export ESGF_COMPUTE_API_BRANCH=devel
[2025-01-09T19:22:40.604Z] + echo ESGF/esgf-compute-api
[2025-01-09T19:22:40.604Z] + sed s@^.*/@@g
[2025-01-09T19:22:40.604Z] + export ESGF_COMPUTE_API_REPO_NAME=esgf-compute-api
[2025-01-09T19:22:40.604Z] + echo pavics-sdi-master
[2025-01-09T19:22:40.604Z] + sed s@[^a-zA-Z0-9_\-\.]@-@g
[2025-01-09T19:22:40.604Z] + export PAVICS_SDI_DIR=pavics-sdi-master
[2025-01-09T19:22:40.604Z] + echo finch-master
[2025-01-09T19:22:40.604Z] + sed s@[^a-zA-Z0-9_\-\.]@-@g
[2025-01-09T19:22:40.604Z] + export FINCH_DIR=finch-master
[2025-01-09T19:22:40.604Z] + echo PAVICS-landing-master
[2025-01-09T19:22:40.604Z] + sed s@[^a-zA-Z0-9_\-\.]@-@g
[2025-01-09T19:22:40.604Z] + export PAVICS_LANDING_DIR=PAVICS-landing-master
[2025-01-09T19:22:40.604Z] + echo raven-main
[2025-01-09T19:22:40.604Z] + sed s@[^a-zA-Z0-9_\-\.]@-@g
[2025-01-09T19:22:40.604Z] + export RAVEN_DIR=raven-main
[2025-01-09T19:22:40.604Z] + echo RavenPy-master
[2025-01-09T19:22:40.604Z] + sed s@[^a-zA-Z0-9_\-\.]@-@g
[2025-01-09T19:22:40.604Z] + export RAVENPY_DIR=RavenPy-master
[2025-01-09T19:22:40.604Z] + echo esgf-compute-api-devel
[2025-01-09T19:22:40.604Z] + sed s@[^a-zA-Z0-9_\-\.]@-@g
[2025-01-09T19:22:40.604Z] + export ESGF_COMPUTE_API_DIR=esgf-compute-api-devel
[2025-01-09T19:22:40.604Z] + echo true
[2025-01-09T19:22:40.604Z] + tr [:upper:] [:lower:]
[2025-01-09T19:22:40.604Z] + VERIFY_SSL=true
[2025-01-09T19:22:40.604Z] + [ xtrue = xfalse ]
[2025-01-09T19:22:40.604Z] + rm -v finch-master/setup.cfg
[2025-01-09T19:22:40.604Z] removed 'finch-master/setup.cfg'
[2025-01-09T19:22:40.604Z] + rm -v raven-main/setup.cfg
[2025-01-09T19:22:40.604Z] removed 'raven-main/setup.cfg'
[2025-01-09T19:22:40.604Z] + rm -v raven-main/pyproject.toml
[2025-01-09T19:22:40.604Z] removed 'raven-main/pyproject.toml'
[2025-01-09T19:22:40.604Z] + rm -v RavenPy-master/setup.cfg
[2025-01-09T19:22:40.604Z] rm: cannot remove 'RavenPy-master/setup.cfg': No such file or directory
[2025-01-09T19:22:40.604Z] + rm -v RavenPy-master/tox.ini
[2025-01-09T19:22:40.604Z] removed 'RavenPy-master/tox.ini'
[2025-01-09T19:22:40.604Z] + rm -v RavenPy-master/pyproject.toml
[2025-01-09T19:22:40.604Z] removed 'RavenPy-master/pyproject.toml'
[2025-01-09T19:22:40.604Z] + rm -v esgf-compute-api-devel/setup.cfg
[2025-01-09T19:22:40.604Z] rm: cannot remove 'esgf-compute-api-devel/setup.cfg': No such file or directory
[2025-01-09T19:22:40.604Z] + rm -v esgf-compute-api-devel/tox.ini
[2025-01-09T19:22:40.604Z] rm: cannot remove 'esgf-compute-api-devel/tox.ini': No such file or directory
[2025-01-09T19:22:40.604Z] + echo false
[2025-01-09T19:22:40.604Z] + tr [:upper:] [:lower:]
[2025-01-09T19:22:40.604Z] + TEST_MAGPIE_AUTH=false
[2025-01-09T19:22:40.604Z] + tr [:upper:] [:lower:]
[2025-01-09T19:22:40.604Z] + echo false
[2025-01-09T19:22:40.604Z] + TEST_PAVICS_SDI_REPO=false
[2025-01-09T19:22:40.604Z] + echo false
[2025-01-09T19:22:40.604Z] + tr [:upper:] [:lower:]
[2025-01-09T19:22:40.605Z] + TEST_PAVICS_SDI_WEAVER=false
[2025-01-09T19:22:40.605Z] + tr [:upper:] [:lower:]
[2025-01-09T19:22:40.605Z] + echo false
[2025-01-09T19:22:40.605Z] + TEST_FINCH_REPO=false
[2025-01-09T19:22:40.605Z] + echo false
[2025-01-09T19:22:40.605Z] + tr [:upper:] [:lower:]
[2025-01-09T19:22:40.605Z] + TEST_PAVICS_LANDING_REPO=false
[2025-01-09T19:22:40.605Z] + echo true
[2025-01-09T19:22:40.605Z] + tr [:upper:] [:lower:]
[2025-01-09T19:22:40.605Z] + TEST_RAVEN_REPO=true
[2025-01-09T19:22:40.605Z] + echo true
[2025-01-09T19:22:40.605Z] + tr [:upper:] [:lower:]
[2025-01-09T19:22:40.605Z] + TEST_RAVENPY_REPO=true
[2025-01-09T19:22:40.605Z] + echo false
[2025-01-09T19:22:40.605Z] + tr [:upper:] [:lower:]
[2025-01-09T19:22:40.605Z] + TEST_ESGF_COMPUTE_API_REPO=false
[2025-01-09T19:22:40.605Z] + echo false
[2025-01-09T19:22:40.605Z] + tr [:upper:] [:lower:]
[2025-01-09T19:22:40.605Z] + TEST_LOCAL_NOTEBOOKS=false
[2025-01-09T19:22:40.605Z] + NOTEBOOKS_TO_TEST=
[2025-01-09T19:22:40.605Z] + [ xfalse = xtrue ]
[2025-01-09T19:22:40.605Z] + [ xfalse = xtrue ]
[2025-01-09T19:22:40.605Z] + [ xfalse = xtrue ]
[2025-01-09T19:22:40.605Z] + [ xfalse = xtrue ]
[2025-01-09T19:22:40.605Z] + [ xtrue = xtrue ]
[2025-01-09T19:22:40.605Z] + NOTEBOOKS_TO_TEST= raven-main/docs/source/notebooks/*.ipynb
[2025-01-09T19:22:40.605Z] + [ xtrue = xtrue ]
[2025-01-09T19:22:40.605Z] + NOTEBOOKS_TO_TEST= raven-main/docs/source/notebooks/*.ipynb RavenPy-master/docs/notebooks/*.ipynb
[2025-01-09T19:22:40.605Z] + NOTEBOOKS_TO_TEST= raven-main/docs/source/notebooks/*.ipynb RavenPy-master/docs/notebooks/*.ipynb RavenPy-master/docs/notebooks/paper/*.ipynb
[2025-01-09T19:22:40.605Z] + [ xfalse = xtrue ]
[2025-01-09T19:22:40.605Z] + [ xfalse = xtrue ]
[2025-01-09T19:22:40.605Z] + ./runtest  raven-main/docs/source/notebooks/*.ipynb RavenPy-master/docs/notebooks/*.ipynb RavenPy-master/docs/notebooks/paper/*.ipynb
[2025-01-09T19:22:40.605Z] + [ -n  ]
[2025-01-09T19:22:40.605Z] + [ ! -z pavics.ouranos.ca ]
[2025-01-09T19:22:40.605Z] + echo Will run notebooks against pavics.ouranos.ca
[2025-01-09T19:22:40.605Z] Will run notebooks against pavics.ouranos.ca
[2025-01-09T19:22:40.605Z] + [ -z  ]
[2025-01-09T19:22:40.605Z] + sed -i /\(\.ncml\|TEST_USE_PROD_DATA\)/!s/pavics.ouranos.ca/pavics.ouranos.ca/g raven-main/docs/source/notebooks/Region_selection.ipynb raven-main/docs/source/notebooks/Subset_climate_data_over_watershed.ipynb RavenPy-master/docs/notebooks/00_Introduction_to_JupyterLab.ipynb RavenPy-master/docs/notebooks/01_Getting_watershed_boundaries.ipynb RavenPy-master/docs/notebooks/02_Extract_geographical_watershed_properties.ipynb RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb RavenPy-master/docs/notebooks/04_Emulating_hydrological_models.ipynb RavenPy-master/docs/notebooks/05_Advanced_RavenPy_configuration.ipynb RavenPy-master/docs/notebooks/06_Raven_calibration.ipynb RavenPy-master/docs/notebooks/07_Making_and_using_hotstart_files.ipynb RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb RavenPy-master/docs/notebooks/09_Hydrological_impacts_of_climate_change.ipynb RavenPy-master/docs/notebooks/10_Data_assimilation.ipynb RavenPy-master/docs/notebooks/11_Climatological_ESP_forecasting.ipynb RavenPy-master/docs/notebooks/12_Performing_hindcasting_experiments.ipynb RavenPy-master/docs/notebooks/Assess_probabilistic_flood_risk.ipynb RavenPy-master/docs/notebooks/Comparing_hindcasts_and_ESP_forecasts.ipynb RavenPy-master/docs/notebooks/Distributed_hydrological_modelling.ipynb RavenPy-master/docs/notebooks/HydroShare_integration.ipynb RavenPy-master/docs/notebooks/Hydrological_realtime_forecasting.ipynb RavenPy-master/docs/notebooks/Managing_Jupyter_Environments.ipynb RavenPy-master/docs/notebooks/Perform_Regionalization.ipynb RavenPy-master/docs/notebooks/Running_HMETS_with_CANOPEX_dataset.ipynb RavenPy-master/docs/notebooks/Sensitivity_analysis.ipynb RavenPy-master/docs/notebooks/time_series_analysis.ipynb RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb
[2025-01-09T19:22:40.605Z] + git diff
[2025-01-09T19:22:40.605Z] + export PYTHONWARNINGS=ignore:Unverified HTTPS request
[2025-01-09T19:22:40.605Z] + [ -n  ]
[2025-01-09T19:22:40.605Z] + py.test --nbval raven-main/docs/source/notebooks/Region_selection.ipynb raven-main/docs/source/notebooks/Subset_climate_data_over_watershed.ipynb RavenPy-master/docs/notebooks/00_Introduction_to_JupyterLab.ipynb RavenPy-master/docs/notebooks/01_Getting_watershed_boundaries.ipynb RavenPy-master/docs/notebooks/02_Extract_geographical_watershed_properties.ipynb RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb RavenPy-master/docs/notebooks/04_Emulating_hydrological_models.ipynb RavenPy-master/docs/notebooks/05_Advanced_RavenPy_configuration.ipynb RavenPy-master/docs/notebooks/06_Raven_calibration.ipynb RavenPy-master/docs/notebooks/07_Making_and_using_hotstart_files.ipynb RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb RavenPy-master/docs/notebooks/09_Hydrological_impacts_of_climate_change.ipynb RavenPy-master/docs/notebooks/10_Data_assimilation.ipynb RavenPy-master/docs/notebooks/11_Climatological_ESP_forecasting.ipynb RavenPy-master/docs/notebooks/12_Performing_hindcasting_experiments.ipynb RavenPy-master/docs/notebooks/Assess_probabilistic_flood_risk.ipynb RavenPy-master/docs/notebooks/Comparing_hindcasts_and_ESP_forecasts.ipynb RavenPy-master/docs/notebooks/Distributed_hydrological_modelling.ipynb RavenPy-master/docs/notebooks/HydroShare_integration.ipynb RavenPy-master/docs/notebooks/Hydrological_realtime_forecasting.ipynb RavenPy-master/docs/notebooks/Managing_Jupyter_Environments.ipynb RavenPy-master/docs/notebooks/Perform_Regionalization.ipynb RavenPy-master/docs/notebooks/Running_HMETS_with_CANOPEX_dataset.ipynb RavenPy-master/docs/notebooks/Sensitivity_analysis.ipynb RavenPy-master/docs/notebooks/time_series_analysis.ipynb RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb --nbval-sanitize-with notebooks/output-sanitize.cfg --dist=loadscope --numprocesses=0 --nbval-lax
[2025-01-09T19:22:43.872Z] ============================= test session starts ==============================
[2025-01-09T19:22:43.872Z] platform linux -- Python 3.11.11, pytest-8.3.4, pluggy-1.5.0
[2025-01-09T19:22:43.873Z] rootdir: /home/jenkins/agent/workspace/_workflow-tests_new-docker-build@2
[2025-01-09T19:22:43.873Z] plugins: anyio-4.8.0, dash-2.18.2, nbval-0.11.0, tornasync-0.6.0.post2, xdist-3.6.1
[2025-01-09T19:22:43.873Z] collected 242 items
[2025-01-09T19:22:43.873Z] 
[2025-01-09T19:22:57.072Z] raven-main/docs/source/notebooks/Region_selection.ipynb .........        [  3%]
[2025-01-09T19:22:58.956Z] raven-main/docs/source/notebooks/Subset_climate_data_over_watershed.ipynb . [  4%]
[2025-01-09T19:23:15.392Z] ......                                                                   [  6%]
[2025-01-09T19:23:17.280Z] RavenPy-master/docs/notebooks/00_Introduction_to_JupyterLab.ipynb ...... [  9%]
[2025-01-09T19:23:17.280Z]                                                                          [  9%]
[2025-01-09T19:23:20.084Z] RavenPy-master/docs/notebooks/01_Getting_watershed_boundaries.ipynb .... [ 10%]
[2025-01-09T19:23:32.239Z] ....                                                                     [ 12%]
[2025-01-09T19:23:38.768Z] RavenPy-master/docs/notebooks/02_Extract_geographical_watershed_properties.ipynb . [ 12%]
[2025-01-09T19:23:48.548Z] ..............                                                           [ 18%]
[2025-01-09T19:24:02.174Z] RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb ...FFFFFF [ 22%]
[2025-01-09T19:24:02.174Z] FF                                                                       [ 23%]
[2025-01-09T19:24:06.058Z] RavenPy-master/docs/notebooks/04_Emulating_hydrological_models.ipynb ... [ 24%]
[2025-01-09T19:24:15.812Z] .................                                                        [ 31%]
[2025-01-09T19:24:22.499Z] RavenPy-master/docs/notebooks/05_Advanced_RavenPy_configuration.ipynb .. [ 32%]
[2025-01-09T19:24:31.357Z] ...........                                                              [ 36%]
[2025-01-09T19:24:41.977Z] RavenPy-master/docs/notebooks/06_Raven_calibration.ipynb ......          [ 39%]
[2025-01-09T19:24:47.211Z] RavenPy-master/docs/notebooks/07_Making_and_using_hotstart_files.ipynb . [ 39%]
[2025-01-09T19:24:51.766Z] .....                                                                    [ 41%]
[2025-01-09T19:24:53.135Z] RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb . [ 42%]
[2025-01-09T19:25:57.490Z] ......F.F..FFFFF                                                         [ 48%]
[2025-01-09T19:26:01.652Z] RavenPy-master/docs/notebooks/09_Hydrological_impacts_of_climate_change.ipynb . [ 49%]
[2025-01-09T19:26:10.156Z] ....                                                                     [ 50%]
[2025-01-09T19:26:51.026Z] RavenPy-master/docs/notebooks/10_Data_assimilation.ipynb ........        [ 54%]
[2025-01-09T19:27:12.929Z] RavenPy-master/docs/notebooks/11_Climatological_ESP_forecasting.ipynb .. [ 54%]
[2025-01-09T19:27:35.866Z] ......                                                                   [ 57%]
[2025-01-09T19:27:53.912Z] RavenPy-master/docs/notebooks/12_Performing_hindcasting_experiments.ipynb . [ 57%]
[2025-01-09T19:28:03.644Z] .......                                                                  [ 60%]
[2025-01-09T19:28:10.352Z] RavenPy-master/docs/notebooks/Assess_probabilistic_flood_risk.ipynb .... [ 62%]
[2025-01-09T19:28:35.098Z] ....                                                                     [ 64%]
[2025-01-09T19:28:53.146Z] RavenPy-master/docs/notebooks/Comparing_hindcasts_and_ESP_forecasts.ipynb . [ 64%]
[2025-01-09T19:29:11.640Z] .......                                                                  [ 67%]
[2025-01-09T19:29:14.156Z] RavenPy-master/docs/notebooks/Distributed_hydrological_modelling.ipynb . [ 67%]
[2025-01-09T19:29:38.824Z] .......                                                                  [ 70%]
[2025-01-09T19:29:40.004Z] RavenPy-master/docs/notebooks/HydroShare_integration.ipynb FFFF          [ 72%]
[2025-01-09T19:30:06.097Z] RavenPy-master/docs/notebooks/Hydrological_realtime_forecasting.ipynb .. [ 73%]
[2025-01-09T19:30:13.516Z] ....                                                                     [ 74%]
[2025-01-09T19:30:29.118Z] RavenPy-master/docs/notebooks/Managing_Jupyter_Environments.ipynb ...    [ 76%]
[2025-01-09T19:31:03.421Z] RavenPy-master/docs/notebooks/Perform_Regionalization.ipynb .......      [ 78%]
[2025-01-09T19:31:03.421Z] RavenPy-master/docs/notebooks/Running_HMETS_with_CANOPEX_dataset.ipynb . [ 79%]
[2025-01-09T19:31:14.732Z] .............                                                            [ 84%]
[2025-01-09T19:31:32.199Z] RavenPy-master/docs/notebooks/Sensitivity_analysis.ipynb .....           [ 86%]
[2025-01-09T19:31:39.821Z] RavenPy-master/docs/notebooks/time_series_analysis.ipynb ...........     [ 91%]
[2025-01-09T19:32:06.309Z] RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb . [ 91%]
[2025-01-09T19:33:35.978Z] ..........FFFF...FFF                                                     [100%]
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] =================================== FAILURES ===================================
[2025-01-09T19:33:35.978Z] ____ RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 3 ____
[2025-01-09T19:33:35.978Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.978Z] [94mCell 3: Cell execution caused an exception
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] Input:
[2025-01-09T19:33:35.978Z] [0m# We will add a wrapper to ensure that the following operations will preserve the original data attributes, such as units and variable names.
[2025-01-09T19:33:35.978Z] with xr.set_options(keep_attrs=True):
[2025-01-09T19:33:35.978Z]     ERA5_reference = subset.subset_shape(
[2025-01-09T19:33:35.978Z]         ds.sel(time=slice(reference_start_day, reference_stop_day)), basin_contour
[2025-01-09T19:33:35.978Z]     )
[2025-01-09T19:33:35.978Z]     ERA5_tas = ERA5_reference["t2m"].resample(time="1D")
[2025-01-09T19:33:35.978Z]     ERA5_tmin = ERA5_tas.min().chunk(-1, -1, -1)
[2025-01-09T19:33:35.978Z]     ERA5_tmax = ERA5_tas.max().chunk(-1, -1, -1)
[2025-01-09T19:33:35.978Z]     ERA5_pr = ERA5_reference["tp"].resample(time="1D").sum().chunk(-1, -1, -1)
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] ERA5_pr
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] [94mTraceback:[0m
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.978Z] [0;31mTypeError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.978Z] Cell [0;32mIn[1], line 7[0m
[2025-01-09T19:33:35.978Z] [1;32m      3[0m ERA5_reference [38;5;241m=[39m subset[38;5;241m.[39msubset_shape(
[2025-01-09T19:33:35.978Z] [1;32m      4[0m     ds[38;5;241m.[39msel(time[38;5;241m=[39m[38;5;28mslice[39m(reference_start_day, reference_stop_day)), basin_contour
[2025-01-09T19:33:35.978Z] [1;32m      5[0m )
[2025-01-09T19:33:35.978Z] [1;32m      6[0m ERA5_tas [38;5;241m=[39m ERA5_reference[[38;5;124m"[39m[38;5;124mt2m[39m[38;5;124m"[39m][38;5;241m.[39mresample(time[38;5;241m=[39m[38;5;124m"[39m[38;5;124m1D[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.978Z] [0;32m----> 7[0m ERA5_tmin [38;5;241m=[39m [43mERA5_tas[49m[38;5;241;43m.[39;49m[43mmin[49m[43m([49m[43m)[49m[38;5;241;43m.[39;49m[43mchunk[49m[43m([49m[38;5;241;43m-[39;49m[38;5;241;43m1[39;49m[43m,[49m[43m [49m[38;5;241;43m-[39;49m[38;5;241;43m1[39;49m[43m,[49m[43m [49m[38;5;241;43m-[39;49m[38;5;241;43m1[39;49m[43m)[49m
[2025-01-09T19:33:35.978Z] [1;32m      8[0m ERA5_tmax [38;5;241m=[39m ERA5_tas[38;5;241m.[39mmax()[38;5;241m.[39mchunk([38;5;241m-[39m[38;5;241m1[39m, [38;5;241m-[39m[38;5;241m1[39m, [38;5;241m-[39m[38;5;241m1[39m)
[2025-01-09T19:33:35.978Z] [1;32m      9[0m ERA5_pr [38;5;241m=[39m ERA5_reference[[38;5;124m"[39m[38;5;124mtp[39m[38;5;124m"[39m][38;5;241m.[39mresample(time[38;5;241m=[39m[38;5;124m"[39m[38;5;124m1D[39m[38;5;124m"[39m)[38;5;241m.[39msum()[38;5;241m.[39mchunk([38;5;241m-[39m[38;5;241m1[39m, [38;5;241m-[39m[38;5;241m1[39m, [38;5;241m-[39m[38;5;241m1[39m)
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] [0;31mTypeError[0m: DataArray.chunk() takes from 1 to 2 positional arguments but 4 were given
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] ____ RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 4 ____
[2025-01-09T19:33:35.978Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.978Z] [94mCell 4: Cell execution caused an exception
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] Input:
[2025-01-09T19:33:35.978Z] [0mprint(f"Tmin units: {ERA5_tmin.units}")
[2025-01-09T19:33:35.978Z] print(f"Tmax units: {ERA5_tmax.units}")
[2025-01-09T19:33:35.978Z] print(f"Precipitation units: {ERA5_pr.units}")
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] [94mTraceback:[0m
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.978Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.978Z] Cell [0;32mIn[1], line 1[0m
[2025-01-09T19:33:35.978Z] [0;32m----> 1[0m [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mTmin units: [39m[38;5;132;01m{[39;00m[43mERA5_tmin[49m[38;5;241m.[39munits[38;5;132;01m}[39;00m[38;5;124m"[39m)
[2025-01-09T19:33:35.978Z] [1;32m      2[0m [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mTmax units: [39m[38;5;132;01m{[39;00mERA5_tmax[38;5;241m.[39munits[38;5;132;01m}[39;00m[38;5;124m"[39m)
[2025-01-09T19:33:35.978Z] [1;32m      3[0m [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mPrecipitation units: [39m[38;5;132;01m{[39;00mERA5_pr[38;5;241m.[39munits[38;5;132;01m}[39;00m[38;5;124m"[39m)
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] [0;31mNameError[0m: name 'ERA5_tmin' is not defined
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] ____ RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 5 ____
[2025-01-09T19:33:35.978Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.978Z] [94mCell 5: Cell execution caused an exception
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] Input:
[2025-01-09T19:33:35.978Z] [0mwith xr.set_options(keep_attrs=True):
[2025-01-09T19:33:35.978Z]     ERA5_tmin = ERA5_tmin - 273.15  # K to ��C
[2025-01-09T19:33:35.978Z]     ERA5_tmin.attrs["units"] = "degC"
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z]     ERA5_tmax = ERA5_tmax - 273.15  # K to ��C
[2025-01-09T19:33:35.978Z]     ERA5_tmax.attrs["units"] = "degC"
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z]     ERA5_pr = ERA5_pr * 1000  # m to mm
[2025-01-09T19:33:35.978Z]     ERA5_pr.attrs["units"] = "mm"
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] [94mTraceback:[0m
[2025-01-09T19:33:35.978Z] 
[2025-01-09T19:33:35.978Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.978Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.978Z] Cell [0;32mIn[1], line 2[0m
[2025-01-09T19:33:35.978Z] [1;32m      1[0m [38;5;28;01mwith[39;00m xr[38;5;241m.[39mset_options(keep_attrs[38;5;241m=[39m[38;5;28;01mTrue[39;00m):
[2025-01-09T19:33:35.978Z] [0;32m----> 2[0m     ERA5_tmin [38;5;241m=[39m [43mERA5_tmin[49m [38;5;241m-[39m [38;5;241m273.15[39m  [38;5;66;03m# K to ��C[39;00m
[2025-01-09T19:33:35.978Z] [1;32m      3[0m     ERA5_tmin[38;5;241m.[39mattrs[[38;5;124m"[39m[38;5;124munits[39m[38;5;124m"[39m] [38;5;241m=[39m [38;5;124m"[39m[38;5;124mdegC[39m[38;5;124m"[39m
[2025-01-09T19:33:35.979Z] [1;32m      5[0m     ERA5_tmax [38;5;241m=[39m ERA5_tmax [38;5;241m-[39m [38;5;241m273.15[39m  [38;5;66;03m# K to ��C[39;00m
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [0;31mNameError[0m: name 'ERA5_tmin' is not defined
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] ____ RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 6 ____
[2025-01-09T19:33:35.979Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.979Z] [94mCell 6: Cell execution caused an exception
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] Input:
[2025-01-09T19:33:35.979Z] [0mprint(f"Tmin units: {ERA5_tmin.units}")
[2025-01-09T19:33:35.979Z] print(f"Tmax units: {ERA5_tmax.units}")
[2025-01-09T19:33:35.979Z] print(f"Precipitation units: {ERA5_pr.units}")
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [94mTraceback:[0m
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.979Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.979Z] Cell [0;32mIn[1], line 1[0m
[2025-01-09T19:33:35.979Z] [0;32m----> 1[0m [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mTmin units: [39m[38;5;132;01m{[39;00m[43mERA5_tmin[49m[38;5;241m.[39munits[38;5;132;01m}[39;00m[38;5;124m"[39m)
[2025-01-09T19:33:35.979Z] [1;32m      2[0m [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mTmax units: [39m[38;5;132;01m{[39;00mERA5_tmax[38;5;241m.[39munits[38;5;132;01m}[39;00m[38;5;124m"[39m)
[2025-01-09T19:33:35.979Z] [1;32m      3[0m [38;5;28mprint[39m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mPrecipitation units: [39m[38;5;132;01m{[39;00mERA5_pr[38;5;241m.[39munits[38;5;132;01m}[39;00m[38;5;124m"[39m)
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [0;31mNameError[0m: name 'ERA5_tmin' is not defined
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] ____ RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 7 ____
[2025-01-09T19:33:35.979Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.979Z] [94mCell 7: Cell execution caused an exception
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] Input:
[2025-01-09T19:33:35.979Z] [0mwith xr.set_options(keep_attrs=True):
[2025-01-09T19:33:35.979Z]     # Average the variables
[2025-01-09T19:33:35.979Z]     ERA5_tmin = ERA5_tmin.mean({"latitude", "longitude"})
[2025-01-09T19:33:35.979Z]     ERA5_tmax = ERA5_tmax.mean({"latitude", "longitude"})
[2025-01-09T19:33:35.979Z]     ERA5_pr = ERA5_pr.mean({"latitude", "longitude"})
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z]     # Ensure that the precipitation is non-negative, which can happen with some reanalysis models.
[2025-01-09T19:33:35.979Z]     ERA5_pr = np.maximum(ERA5_pr, 0)
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z]     # Transform them to a dataset such that they can be written with attributes to netcdf
[2025-01-09T19:33:35.979Z]     ERA5_tmin = ERA5_tmin.to_dataset(name="tmin", promote_attrs=True)
[2025-01-09T19:33:35.979Z]     ERA5_tmax = ERA5_tmax.to_dataset(name="tmax", promote_attrs=True)
[2025-01-09T19:33:35.979Z]     ERA5_pr = ERA5_pr.to_dataset(name="pr", promote_attrs=True)
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [94mTraceback:[0m
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.979Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.979Z] Cell [0;32mIn[1], line 3[0m
[2025-01-09T19:33:35.979Z] [1;32m      1[0m [38;5;28;01mwith[39;00m xr[38;5;241m.[39mset_options(keep_attrs[38;5;241m=[39m[38;5;28;01mTrue[39;00m):
[2025-01-09T19:33:35.979Z] [1;32m      2[0m     [38;5;66;03m# Average the variables[39;00m
[2025-01-09T19:33:35.979Z] [0;32m----> 3[0m     ERA5_tmin [38;5;241m=[39m [43mERA5_tmin[49m[38;5;241m.[39mmean({[38;5;124m"[39m[38;5;124mlatitude[39m[38;5;124m"[39m, [38;5;124m"[39m[38;5;124mlongitude[39m[38;5;124m"[39m})
[2025-01-09T19:33:35.979Z] [1;32m      4[0m     ERA5_tmax [38;5;241m=[39m ERA5_tmax[38;5;241m.[39mmean({[38;5;124m"[39m[38;5;124mlatitude[39m[38;5;124m"[39m, [38;5;124m"[39m[38;5;124mlongitude[39m[38;5;124m"[39m})
[2025-01-09T19:33:35.979Z] [1;32m      5[0m     ERA5_pr [38;5;241m=[39m ERA5_pr[38;5;241m.[39mmean({[38;5;124m"[39m[38;5;124mlatitude[39m[38;5;124m"[39m, [38;5;124m"[39m[38;5;124mlongitude[39m[38;5;124m"[39m})
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [0;31mNameError[0m: name 'ERA5_tmin' is not defined
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] ____ RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 8 ____
[2025-01-09T19:33:35.979Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.979Z] [94mCell 8: Cell execution caused an exception
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] Input:
[2025-01-09T19:33:35.979Z] [0m# Check and see if the precipitation makes sense:
[2025-01-09T19:33:35.979Z] ERA5_pr.pr.plot()
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [94mTraceback:[0m
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.979Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.979Z] Cell [0;32mIn[1], line 2[0m
[2025-01-09T19:33:35.979Z] [1;32m      1[0m [38;5;66;03m# Check and see if the precipitation makes sense:[39;00m
[2025-01-09T19:33:35.979Z] [0;32m----> 2[0m [43mERA5_pr[49m[38;5;241m.[39mpr[38;5;241m.[39mplot()
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [0;31mNameError[0m: name 'ERA5_pr' is not defined
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] ____ RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 9 ____
[2025-01-09T19:33:35.979Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.979Z] [94mCell 9: Cell execution caused an exception
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] Input:
[2025-01-09T19:33:35.979Z] [0m# Option 1, which is not recommended to use in other notebooks but can be really useful in various other workflows:
[2025-01-09T19:33:35.979Z] with xr.set_options(keep_attrs=True):
[2025-01-09T19:33:35.979Z]     # Write to disk.
[2025-01-09T19:33:35.979Z]     tmp = Path(tempfile.mkdtemp())
[2025-01-09T19:33:35.979Z]     ERA5_tmin.to_netcdf(tmp / "ERA5_tmin.nc")
[2025-01-09T19:33:35.979Z]     ERA5_tmax.to_netcdf(tmp / "ERA5_tmax.nc")
[2025-01-09T19:33:35.979Z]     ERA5_pr.to_netcdf(tmp / "ERA5_pr.nc")
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [94mTraceback:[0m
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.979Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.979Z] Cell [0;32mIn[1], line 5[0m
[2025-01-09T19:33:35.979Z] [1;32m      2[0m [38;5;28;01mwith[39;00m xr[38;5;241m.[39mset_options(keep_attrs[38;5;241m=[39m[38;5;28;01mTrue[39;00m):
[2025-01-09T19:33:35.979Z] [1;32m      3[0m     [38;5;66;03m# Write to disk.[39;00m
[2025-01-09T19:33:35.979Z] [1;32m      4[0m     tmp [38;5;241m=[39m Path(tempfile[38;5;241m.[39mmkdtemp())
[2025-01-09T19:33:35.979Z] [0;32m----> 5[0m     [43mERA5_tmin[49m[38;5;241m.[39mto_netcdf(tmp [38;5;241m/[39m [38;5;124m"[39m[38;5;124mERA5_tmin.nc[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.979Z] [1;32m      6[0m     ERA5_tmax[38;5;241m.[39mto_netcdf(tmp [38;5;241m/[39m [38;5;124m"[39m[38;5;124mERA5_tmax.nc[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.979Z] [1;32m      7[0m     ERA5_pr[38;5;241m.[39mto_netcdf(tmp [38;5;241m/[39m [38;5;124m"[39m[38;5;124mERA5_pr.nc[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [0;31mNameError[0m: name 'ERA5_tmin' is not defined
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] ___ RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 10 ____
[2025-01-09T19:33:35.979Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.979Z] [94mCell 10: Cell execution caused an exception
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] Input:
[2025-01-09T19:33:35.979Z] [0m# Option 2, which is recommended, in which we prepare a single file that merges all three variables into one netcdf file:
[2025-01-09T19:33:35.979Z] with xr.set_options(keep_attrs=True):
[2025-01-09T19:33:35.979Z]     xr.merge([ERA5_tmin, ERA5_tmax, ERA5_pr]).to_netcdf(tmp / "ERA5_weather_data.nc")
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [94mTraceback:[0m
[2025-01-09T19:33:35.979Z] 
[2025-01-09T19:33:35.979Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.980Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.980Z] Cell [0;32mIn[1], line 3[0m
[2025-01-09T19:33:35.980Z] [1;32m      1[0m [38;5;66;03m# Option 2, which is recommended, in which we prepare a single file that merges all three variables into one netcdf file:[39;00m
[2025-01-09T19:33:35.980Z] [1;32m      2[0m [38;5;28;01mwith[39;00m xr[38;5;241m.[39mset_options(keep_attrs[38;5;241m=[39m[38;5;28;01mTrue[39;00m):
[2025-01-09T19:33:35.980Z] [0;32m----> 3[0m     xr[38;5;241m.[39mmerge([[43mERA5_tmin[49m, ERA5_tmax, ERA5_pr])[38;5;241m.[39mto_netcdf(tmp [38;5;241m/[39m [38;5;124m"[39m[38;5;124mERA5_weather_data.nc[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] [0;31mNameError[0m: name 'ERA5_tmin' is not defined
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] _ RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 7 _
[2025-01-09T19:33:35.980Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.980Z] [94mCell 7: Cell execution caused an exception
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] Input:
[2025-01-09T19:33:35.980Z] [0m# Get the CMIP6 data from Google Cloud and read it in memory using xarray.
[2025-01-09T19:33:35.980Z] # This is done via "lazy loading" and is not actually reading the data in memory yet, but is keeping track of what it will need to get, eventually.
[2025-01-09T19:33:35.980Z] ds = xr.open_zarr(mapper, consolidated=True)
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] # Convert to numpy.datetime64 object for compatibility.
[2025-01-09T19:33:35.980Z] ds = ds.convert_calendar("standard")
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] # Extract only the dates that we really want.
[2025-01-09T19:33:35.980Z] # Again, this is done via lazy loading, and is not actually using memory at this point.
[2025-01-09T19:33:35.980Z] ds = ds.sel(time=slice(reference_start_day, reference_end_day))
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] # Set the date to the midnight of the given day.
[2025-01-09T19:33:35.980Z] ds = ds.assign_coords(time=ds.time.dt.floor("D"))
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] # Use the clisops subsetting tools to extract the data for the watershed boundaries and take the spatial average
[2025-01-09T19:33:35.980Z] ds = average.average_shape(ds, basin_contour)
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] # Correct the coordinates that are unnecessary for our variable
[2025-01-09T19:33:35.980Z] ds = ds.reset_coords("height", drop=True)
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] # Rechunk the data so it is much faster to read (single chunk rather than 1 chunk per day)
[2025-01-09T19:33:35.980Z] historical_tasmin = ds["tasmin"].chunk(-1)
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] # Show the end result!
[2025-01-09T19:33:35.980Z] display(historical_tasmin)
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] [94mTraceback:[0m
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.980Z] [0;31mTypeError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.980Z] Cell [0;32mIn[1], line 3[0m
[2025-01-09T19:33:35.980Z] [1;32m      1[0m [38;5;66;03m# Get the CMIP6 data from Google Cloud and read it in memory using xarray.[39;00m
[2025-01-09T19:33:35.980Z] [1;32m      2[0m [38;5;66;03m# This is done via "lazy loading" and is not actually reading the data in memory yet, but is keeping track of what it will need to get, eventually.[39;00m
[2025-01-09T19:33:35.980Z] [0;32m----> 3[0m ds [38;5;241m=[39m [43mxr[49m[38;5;241;43m.[39;49m[43mopen_zarr[49m[43m([49m[43mmapper[49m[43m,[49m[43m [49m[43mconsolidated[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m)[49m
[2025-01-09T19:33:35.980Z] [1;32m      5[0m [38;5;66;03m# Convert to numpy.datetime64 object for compatibility.[39;00m
[2025-01-09T19:33:35.980Z] [1;32m      6[0m ds [38;5;241m=[39m ds[38;5;241m.[39mconvert_calendar([38;5;124m"[39m[38;5;124mstandard[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.980Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:1491[0m, in [0;36mopen_zarr[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, zarr_format, use_zarr_fill_value_as_mask, chunked_array_type, from_array_kwargs, **kwargs)[0m
[2025-01-09T19:33:35.980Z] [1;32m   1477[0m     [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(
[2025-01-09T19:33:35.980Z] [1;32m   1478[0m         [38;5;124m"[39m[38;5;124mopen_zarr() got unexpected keyword arguments [39m[38;5;124m"[39m [38;5;241m+[39m [38;5;124m"[39m[38;5;124m,[39m[38;5;124m"[39m[38;5;241m.[39mjoin(kwargs[38;5;241m.[39mkeys())
[2025-01-09T19:33:35.980Z] [1;32m   1479[0m     )
[2025-01-09T19:33:35.980Z] [1;32m   1481[0m backend_kwargs [38;5;241m=[39m {
[2025-01-09T19:33:35.980Z] [1;32m   1482[0m     [38;5;124m"[39m[38;5;124msynchronizer[39m[38;5;124m"[39m: synchronizer,
[2025-01-09T19:33:35.980Z] [1;32m   1483[0m     [38;5;124m"[39m[38;5;124mconsolidated[39m[38;5;124m"[39m: consolidated,
[2025-01-09T19:33:35.980Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.980Z] [1;32m   1488[0m     [38;5;124m"[39m[38;5;124mzarr_format[39m[38;5;124m"[39m: zarr_format,
[2025-01-09T19:33:35.980Z] [1;32m   1489[0m }
[2025-01-09T19:33:35.980Z] [0;32m-> 1491[0m ds [38;5;241m=[39m [43mopen_dataset[49m[43m([49m
[2025-01-09T19:33:35.980Z] [1;32m   1492[0m [43m    [49m[43mfilename_or_obj[49m[38;5;241;43m=[39;49m[43mstore[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1493[0m [43m    [49m[43mgroup[49m[38;5;241;43m=[39;49m[43mgroup[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1494[0m [43m    [49m[43mdecode_cf[49m[38;5;241;43m=[39;49m[43mdecode_cf[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1495[0m [43m    [49m[43mmask_and_scale[49m[38;5;241;43m=[39;49m[43mmask_and_scale[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1496[0m [43m    [49m[43mdecode_times[49m[38;5;241;43m=[39;49m[43mdecode_times[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1497[0m [43m    [49m[43mconcat_characters[49m[38;5;241;43m=[39;49m[43mconcat_characters[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1498[0m [43m    [49m[43mdecode_coords[49m[38;5;241;43m=[39;49m[43mdecode_coords[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1499[0m [43m    [49m[43mengine[49m[38;5;241;43m=[39;49m[38;5;124;43m"[39;49m[38;5;124;43mzarr[39;49m[38;5;124;43m"[39;49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1500[0m [43m    [49m[43mchunks[49m[38;5;241;43m=[39;49m[43mchunks[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1501[0m [43m    [49m[43mdrop_variables[49m[38;5;241;43m=[39;49m[43mdrop_variables[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1502[0m [43m    [49m[43mchunked_array_type[49m[38;5;241;43m=[39;49m[43mchunked_array_type[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1503[0m [43m    [49m[43mfrom_array_kwargs[49m[38;5;241;43m=[39;49m[43mfrom_array_kwargs[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1504[0m [43m    [49m[43mbackend_kwargs[49m[38;5;241;43m=[39;49m[43mbackend_kwargs[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1505[0m [43m    [49m[43mdecode_timedelta[49m[38;5;241;43m=[39;49m[43mdecode_timedelta[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1506[0m [43m    [49m[43muse_cftime[49m[38;5;241;43m=[39;49m[43muse_cftime[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1507[0m [43m    [49m[43mzarr_version[49m[38;5;241;43m=[39;49m[43mzarr_version[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1508[0m [43m    [49m[43muse_zarr_fill_value_as_mask[49m[38;5;241;43m=[39;49m[43muse_zarr_fill_value_as_mask[49m[43m,[49m
[2025-01-09T19:33:35.980Z] [1;32m   1509[0m [43m[49m[43m)[49m
[2025-01-09T19:33:35.980Z] [1;32m   1510[0m [38;5;28;01mreturn[39;00m ds
[2025-01-09T19:33:35.980Z] 
[2025-01-09T19:33:35.981Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/api.py:679[0m, in [0;36mopen_dataset[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)[0m
[2025-01-09T19:33:35.981Z] [1;32m    667[0m decoders [38;5;241m=[39m _resolve_decoders_kwargs(
[2025-01-09T19:33:35.981Z] [1;32m    668[0m     decode_cf,
[2025-01-09T19:33:35.981Z] [1;32m    669[0m     open_backend_dataset_parameters[38;5;241m=[39mbackend[38;5;241m.[39mopen_dataset_parameters,
[2025-01-09T19:33:35.981Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.981Z] [1;32m    675[0m     decode_coords[38;5;241m=[39mdecode_coords,
[2025-01-09T19:33:35.981Z] [1;32m    676[0m )
[2025-01-09T19:33:35.981Z] [1;32m    678[0m overwrite_encoded_chunks [38;5;241m=[39m kwargs[38;5;241m.[39mpop([38;5;124m"[39m[38;5;124moverwrite_encoded_chunks[39m[38;5;124m"[39m, [38;5;28;01mNone[39;00m)
[2025-01-09T19:33:35.981Z] [0;32m--> 679[0m backend_ds [38;5;241m=[39m [43mbackend[49m[38;5;241;43m.[39;49m[43mopen_dataset[49m[43m([49m
[2025-01-09T19:33:35.981Z] [1;32m    680[0m [43m    [49m[43mfilename_or_obj[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    681[0m [43m    [49m[43mdrop_variables[49m[38;5;241;43m=[39;49m[43mdrop_variables[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    682[0m [43m    [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mdecoders[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    683[0m [43m    [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    684[0m [43m[49m[43m)[49m
[2025-01-09T19:33:35.981Z] [1;32m    685[0m ds [38;5;241m=[39m _dataset_from_backend_dataset(
[2025-01-09T19:33:35.981Z] [1;32m    686[0m     backend_ds,
[2025-01-09T19:33:35.981Z] [1;32m    687[0m     filename_or_obj,
[2025-01-09T19:33:35.981Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.981Z] [1;32m    697[0m     [38;5;241m*[39m[38;5;241m*[39mkwargs,
[2025-01-09T19:33:35.981Z] [1;32m    698[0m )
[2025-01-09T19:33:35.981Z] [1;32m    699[0m [38;5;28;01mreturn[39;00m ds
[2025-01-09T19:33:35.981Z] 
[2025-01-09T19:33:35.981Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:1564[0m, in [0;36mZarrBackendEntrypoint.open_dataset[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, zarr_version, zarr_format, store, engine, use_zarr_fill_value_as_mask, cache_members)[0m
[2025-01-09T19:33:35.981Z] [1;32m   1562[0m filename_or_obj [38;5;241m=[39m _normalize_path(filename_or_obj)
[2025-01-09T19:33:35.981Z] [1;32m   1563[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m store:
[2025-01-09T19:33:35.981Z] [0;32m-> 1564[0m     store [38;5;241m=[39m [43mZarrStore[49m[38;5;241;43m.[39;49m[43mopen_group[49m[43m([49m
[2025-01-09T19:33:35.981Z] [1;32m   1565[0m [43m        [49m[43mfilename_or_obj[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1566[0m [43m        [49m[43mgroup[49m[38;5;241;43m=[39;49m[43mgroup[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1567[0m [43m        [49m[43mmode[49m[38;5;241;43m=[39;49m[43mmode[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1568[0m [43m        [49m[43msynchronizer[49m[38;5;241;43m=[39;49m[43msynchronizer[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1569[0m [43m        [49m[43mconsolidated[49m[38;5;241;43m=[39;49m[43mconsolidated[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1570[0m [43m        [49m[43mconsolidate_on_close[49m[38;5;241;43m=[39;49m[38;5;28;43;01mFalse[39;49;00m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1571[0m [43m        [49m[43mchunk_store[49m[38;5;241;43m=[39;49m[43mchunk_store[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1572[0m [43m        [49m[43mstorage_options[49m[38;5;241;43m=[39;49m[43mstorage_options[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1573[0m [43m        [49m[43mzarr_version[49m[38;5;241;43m=[39;49m[43mzarr_version[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1574[0m [43m        [49m[43muse_zarr_fill_value_as_mask[49m[38;5;241;43m=[39;49m[38;5;28;43;01mNone[39;49;00m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1575[0m [43m        [49m[43mzarr_format[49m[38;5;241;43m=[39;49m[43mzarr_format[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1576[0m [43m        [49m[43mcache_members[49m[38;5;241;43m=[39;49m[43mcache_members[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m   1577[0m [43m    [49m[43m)[49m
[2025-01-09T19:33:35.981Z] [1;32m   1579[0m store_entrypoint [38;5;241m=[39m StoreBackendEntrypoint()
[2025-01-09T19:33:35.981Z] [1;32m   1580[0m [38;5;28;01mwith[39;00m close_on_error(store):
[2025-01-09T19:33:35.981Z] 
[2025-01-09T19:33:35.981Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:703[0m, in [0;36mZarrStore.open_group[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, zarr_version, zarr_format, use_zarr_fill_value_as_mask, write_empty, cache_members)[0m
[2025-01-09T19:33:35.981Z] [1;32m    678[0m [38;5;129m@classmethod[39m
[2025-01-09T19:33:35.981Z] [1;32m    679[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21mopen_group[39m(
[2025-01-09T19:33:35.981Z] [1;32m    680[0m     [38;5;28mcls[39m,
[2025-01-09T19:33:35.981Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.981Z] [1;32m    696[0m     cache_members: [38;5;28mbool[39m [38;5;241m=[39m [38;5;28;01mTrue[39;00m,
[2025-01-09T19:33:35.981Z] [1;32m    697[0m ):
[2025-01-09T19:33:35.981Z] [1;32m    698[0m     (
[2025-01-09T19:33:35.981Z] [1;32m    699[0m         zarr_group,
[2025-01-09T19:33:35.981Z] [1;32m    700[0m         consolidate_on_close,
[2025-01-09T19:33:35.981Z] [1;32m    701[0m         close_store_on_close,
[2025-01-09T19:33:35.981Z] [1;32m    702[0m         use_zarr_fill_value_as_mask,
[2025-01-09T19:33:35.981Z] [0;32m--> 703[0m     ) [38;5;241m=[39m [43m_get_open_params[49m[43m([49m
[2025-01-09T19:33:35.981Z] [1;32m    704[0m [43m        [49m[43mstore[49m[38;5;241;43m=[39;49m[43mstore[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    705[0m [43m        [49m[43mmode[49m[38;5;241;43m=[39;49m[43mmode[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    706[0m [43m        [49m[43msynchronizer[49m[38;5;241;43m=[39;49m[43msynchronizer[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    707[0m [43m        [49m[43mgroup[49m[38;5;241;43m=[39;49m[43mgroup[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    708[0m [43m        [49m[43mconsolidated[49m[38;5;241;43m=[39;49m[43mconsolidated[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    709[0m [43m        [49m[43mconsolidate_on_close[49m[38;5;241;43m=[39;49m[43mconsolidate_on_close[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    710[0m [43m        [49m[43mchunk_store[49m[38;5;241;43m=[39;49m[43mchunk_store[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    711[0m [43m        [49m[43mstorage_options[49m[38;5;241;43m=[39;49m[43mstorage_options[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    712[0m [43m        [49m[43mzarr_version[49m[38;5;241;43m=[39;49m[43mzarr_version[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    713[0m [43m        [49m[43muse_zarr_fill_value_as_mask[49m[38;5;241;43m=[39;49m[43muse_zarr_fill_value_as_mask[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    714[0m [43m        [49m[43mzarr_format[49m[38;5;241;43m=[39;49m[43mzarr_format[49m[43m,[49m
[2025-01-09T19:33:35.981Z] [1;32m    715[0m [43m    [49m[43m)[49m
[2025-01-09T19:33:35.981Z] [1;32m    717[0m     [38;5;28;01mreturn[39;00m [38;5;28mcls[39m(
[2025-01-09T19:33:35.981Z] [1;32m    718[0m         zarr_group,
[2025-01-09T19:33:35.981Z] [1;32m    719[0m         mode,
[2025-01-09T19:33:35.981Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.981Z] [1;32m    727[0m         cache_members,
[2025-01-09T19:33:35.981Z] [1;32m    728[0m     )
[2025-01-09T19:33:35.981Z] 
[2025-01-09T19:33:35.981Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:1786[0m, in [0;36m_get_open_params[0;34m(store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, zarr_version, use_zarr_fill_value_as_mask, zarr_format)[0m
[2025-01-09T19:33:35.982Z] [1;32m   1781[0m             [38;5;28;01mraise[39;00m [38;5;167;01mFileNotFoundError[39;00m(
[2025-01-09T19:33:35.982Z] [1;32m   1782[0m                 [38;5;124mf[39m[38;5;124m"[39m[38;5;124mNo such file or directory: [39m[38;5;124m'[39m[38;5;132;01m{[39;00mstore[38;5;132;01m}[39;00m[38;5;124m'[39m[38;5;124m"[39m
[2025-01-09T19:33:35.982Z] [1;32m   1783[0m             ) [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;21;01merr[39;00m
[2025-01-09T19:33:35.982Z] [1;32m   1784[0m [38;5;28;01melif[39;00m consolidated:
[2025-01-09T19:33:35.982Z] [1;32m   1785[0m     [38;5;66;03m# TODO: an option to pass the metadata_key keyword[39;00m
[2025-01-09T19:33:35.982Z] [0;32m-> 1786[0m     zarr_group [38;5;241m=[39m [43mzarr[49m[38;5;241;43m.[39;49m[43mopen_consolidated[49m[43m([49m[43mstore[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mopen_kwargs[49m[43m)[49m
[2025-01-09T19:33:35.982Z] [1;32m   1787[0m [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.982Z] [1;32m   1788[0m     [38;5;28;01mif[39;00m _zarr_v3():
[2025-01-09T19:33:35.982Z] [1;32m   1789[0m         [38;5;66;03m# we have determined that we don't want to use consolidated metadata[39;00m
[2025-01-09T19:33:35.982Z] [1;32m   1790[0m         [38;5;66;03m# so we set that to False to avoid trying to read it[39;00m
[2025-01-09T19:33:35.982Z] 
[2025-01-09T19:33:35.982Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/api/synchronous.py:212[0m, in [0;36mopen_consolidated[0;34m(use_consolidated, *args, **kwargs)[0m
[2025-01-09T19:33:35.982Z] [1;32m    207[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21mopen_consolidated[39m([38;5;241m*[39margs: Any, use_consolidated: Literal[[38;5;28;01mTrue[39;00m] [38;5;241m=[39m [38;5;28;01mTrue[39;00m, [38;5;241m*[39m[38;5;241m*[39mkwargs: Any) [38;5;241m-[39m[38;5;241m>[39m Group:
[2025-01-09T19:33:35.982Z] [1;32m    208[0m [38;5;250m    [39m[38;5;124;03m"""[39;00m
[2025-01-09T19:33:35.982Z] [1;32m    209[0m [38;5;124;03m    Alias for :func:`open_group` with ``use_consolidated=True``.[39;00m
[2025-01-09T19:33:35.982Z] [1;32m    210[0m [38;5;124;03m    """[39;00m
[2025-01-09T19:33:35.982Z] [1;32m    211[0m     [38;5;28;01mreturn[39;00m Group(
[2025-01-09T19:33:35.982Z] [0;32m--> 212[0m         [43msync[49m[43m([49m[43masync_api[49m[38;5;241;43m.[39;49m[43mopen_consolidated[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[43muse_consolidated[49m[38;5;241;43m=[39;49m[43muse_consolidated[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m[43m)[49m
[2025-01-09T19:33:35.982Z] [1;32m    213[0m     )
[2025-01-09T19:33:35.982Z] 
[2025-01-09T19:33:35.982Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/core/sync.py:142[0m, in [0;36msync[0;34m(coro, loop, timeout)[0m
[2025-01-09T19:33:35.982Z] [1;32m    139[0m return_result [38;5;241m=[39m [38;5;28mnext[39m([38;5;28miter[39m(finished))[38;5;241m.[39mresult()
[2025-01-09T19:33:35.982Z] [1;32m    141[0m [38;5;28;01mif[39;00m [38;5;28misinstance[39m(return_result, [38;5;167;01mBaseException[39;00m):
[2025-01-09T19:33:35.982Z] [0;32m--> 142[0m     [38;5;28;01mraise[39;00m return_result
[2025-01-09T19:33:35.982Z] [1;32m    143[0m [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.982Z] [1;32m    144[0m     [38;5;28;01mreturn[39;00m return_result
[2025-01-09T19:33:35.982Z] 
[2025-01-09T19:33:35.982Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/core/sync.py:98[0m, in [0;36m_runner[0;34m(coro)[0m
[2025-01-09T19:33:35.982Z] [1;32m     93[0m [38;5;250m[39m[38;5;124;03m"""[39;00m
[2025-01-09T19:33:35.982Z] [1;32m     94[0m [38;5;124;03mAwait a coroutine and return the result of running it. If awaiting the coroutine raises an[39;00m
[2025-01-09T19:33:35.982Z] [1;32m     95[0m [38;5;124;03mexception, the exception will be returned.[39;00m
[2025-01-09T19:33:35.982Z] [1;32m     96[0m [38;5;124;03m"""[39;00m
[2025-01-09T19:33:35.982Z] [1;32m     97[0m [38;5;28;01mtry[39;00m:
[2025-01-09T19:33:35.982Z] [0;32m---> 98[0m     [38;5;28;01mreturn[39;00m [38;5;28;01mawait[39;00m coro
[2025-01-09T19:33:35.982Z] [1;32m     99[0m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m [38;5;28;01mas[39;00m ex:
[2025-01-09T19:33:35.982Z] [1;32m    100[0m     [38;5;28;01mreturn[39;00m ex
[2025-01-09T19:33:35.982Z] 
[2025-01-09T19:33:35.982Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/api/asynchronous.py:346[0m, in [0;36mopen_consolidated[0;34m(use_consolidated, *args, **kwargs)[0m
[2025-01-09T19:33:35.982Z] [1;32m    341[0m [38;5;28;01mif[39;00m use_consolidated [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mTrue[39;00m:
[2025-01-09T19:33:35.982Z] [1;32m    342[0m     [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(
[2025-01-09T19:33:35.982Z] [1;32m    343[0m         [38;5;124m"[39m[38;5;124m'[39m[38;5;124muse_consolidated[39m[38;5;124m'[39m[38;5;124m must be [39m[38;5;124m'[39m[38;5;124mTrue[39m[38;5;124m'[39m[38;5;124m in [39m[38;5;124m'[39m[38;5;124mopen_consolidated[39m[38;5;124m'[39m[38;5;124m. Use [39m[38;5;124m'[39m[38;5;124mopen[39m[38;5;124m'[39m[38;5;124m with [39m[38;5;124m"[39m
[2025-01-09T19:33:35.982Z] [1;32m    344[0m         [38;5;124m"[39m[38;5;124m'[39m[38;5;124muse_consolidated=False[39m[38;5;124m'[39m[38;5;124m to bypass consolidated metadata.[39m[38;5;124m"[39m
[2025-01-09T19:33:35.982Z] [1;32m    345[0m     )
[2025-01-09T19:33:35.982Z] [0;32m--> 346[0m [38;5;28;01mreturn[39;00m [38;5;28;01mawait[39;00m open_group([38;5;241m*[39margs, use_consolidated[38;5;241m=[39muse_consolidated, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[2025-01-09T19:33:35.982Z] 
[2025-01-09T19:33:35.982Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/api/asynchronous.py:800[0m, in [0;36mopen_group[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, zarr_format, meta_array, attributes, use_consolidated)[0m
[2025-01-09T19:33:35.982Z] [1;32m    797[0m [38;5;28;01mif[39;00m chunk_store [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:
[2025-01-09T19:33:35.982Z] [1;32m    798[0m     warnings[38;5;241m.[39mwarn([38;5;124m"[39m[38;5;124mchunk_store is not yet implemented[39m[38;5;124m"[39m, [38;5;167;01mRuntimeWarning[39;00m, stacklevel[38;5;241m=[39m[38;5;241m2[39m)
[2025-01-09T19:33:35.982Z] [0;32m--> 800[0m store_path [38;5;241m=[39m [38;5;28;01mawait[39;00m make_store_path(store, mode[38;5;241m=[39mmode, storage_options[38;5;241m=[39mstorage_options, path[38;5;241m=[39mpath)
[2025-01-09T19:33:35.982Z] [1;32m    802[0m [38;5;28;01mif[39;00m attributes [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[2025-01-09T19:33:35.982Z] [1;32m    803[0m     attributes [38;5;241m=[39m {}
[2025-01-09T19:33:35.982Z] 
[2025-01-09T19:33:35.982Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/storage/_common.py:316[0m, in [0;36mmake_store_path[0;34m(store_like, path, mode, storage_options)[0m
[2025-01-09T19:33:35.982Z] [1;32m    314[0m     [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.982Z] [1;32m    315[0m         msg [38;5;241m=[39m [38;5;124mf[39m[38;5;124m"[39m[38;5;124mUnsupported type for store_like: [39m[38;5;124m'[39m[38;5;132;01m{[39;00m[38;5;28mtype[39m(store_like)[38;5;241m.[39m[38;5;18m__name__[39m[38;5;132;01m}[39;00m[38;5;124m'[39m[38;5;124m"[39m  [38;5;66;03m# type: ignore[unreachable][39;00m
[2025-01-09T19:33:35.982Z] [0;32m--> 316[0m         [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(msg)
[2025-01-09T19:33:35.982Z] [1;32m    318[0m     result [38;5;241m=[39m [38;5;28;01mawait[39;00m StorePath[38;5;241m.[39mopen(store, path[38;5;241m=[39mpath_normalized, mode[38;5;241m=[39mmode)
[2025-01-09T19:33:35.983Z] [1;32m    320[0m [38;5;28;01mif[39;00m storage_options [38;5;129;01mand[39;00m [38;5;129;01mnot[39;00m used_storage_options:
[2025-01-09T19:33:35.983Z] 
[2025-01-09T19:33:35.983Z] [0;31mTypeError[0m: Unsupported type for store_like: 'FSMap'
[2025-01-09T19:33:35.983Z] 
[2025-01-09T19:33:35.983Z] _ RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 9 _
[2025-01-09T19:33:35.983Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.983Z] [94mCell 9: Cell execution caused an exception
[2025-01-09T19:33:35.983Z] 
[2025-01-09T19:33:35.983Z] Input:
[2025-01-09T19:33:35.983Z] [0m# We will add a wrapper to ensure that the following operations will preserve the original data attributes, such as units and variable names.
[2025-01-09T19:33:35.983Z] with xr.set_options(keep_attrs=True):
[2025-01-09T19:33:35.983Z]     # Load the files from the PanGEO catalogs, for reference and future variables of temperature and precipitation.
[2025-01-09T19:33:35.983Z]     out = {}
[2025-01-09T19:33:35.983Z]     for exp in ["historical", "ssp585"]:
[2025-01-09T19:33:35.983Z]         if exp == "historical":
[2025-01-09T19:33:35.983Z]             period_start = reference_start_day
[2025-01-09T19:33:35.983Z]             period_end = reference_end_day
[2025-01-09T19:33:35.983Z]         else:
[2025-01-09T19:33:35.983Z]             period_start = future_start_day
[2025-01-09T19:33:35.983Z]             period_end = future_end_day
[2025-01-09T19:33:35.983Z] 
[2025-01-09T19:33:35.983Z]         out[exp] = {}
[2025-01-09T19:33:35.983Z]         for variable in ["tasmin", "tasmax", "pr"]:
[2025-01-09T19:33:35.983Z]             print(exp, variable)
[2025-01-09T19:33:35.983Z]             query = dict(
[2025-01-09T19:33:35.983Z]                 experiment_id=exp,
[2025-01-09T19:33:35.983Z]                 table_id="day",
[2025-01-09T19:33:35.983Z]                 variable_id=variable,
[2025-01-09T19:33:35.983Z]                 member_id="r1i1p1f1",
[2025-01-09T19:33:35.983Z]                 source_id=climate_model,
[2025-01-09T19:33:35.983Z]             )
[2025-01-09T19:33:35.983Z]             col_subset = col.search(require_all_on=["source_id"], **query)
[2025-01-09T19:33:35.983Z]             mapper = fsCMIP.get_mapper(col_subset.df.zstore[0])
[2025-01-09T19:33:35.983Z]             ds = xr.open_zarr(mapper, consolidated=True)
[2025-01-09T19:33:35.983Z] 
[2025-01-09T19:33:35.983Z]             out[exp][variable] = extract_and_average(
[2025-01-09T19:33:35.983Z]                 mapper, period_start, period_end, basin_contour
[2025-01-09T19:33:35.983Z]             )[variable]
[2025-01-09T19:33:35.983Z] 
[2025-01-09T19:33:35.983Z] # We can now extract the variables that we will need later:
[2025-01-09T19:33:35.983Z] historical_tasmax = out["historical"]["tasmax"]
[2025-01-09T19:33:35.983Z] historical_tasmin = out["historical"]["tasmin"]
[2025-01-09T19:33:35.983Z] historical_pr = out["historical"]["pr"]
[2025-01-09T19:33:35.983Z] future_tasmax = out["ssp585"]["tasmax"]
[2025-01-09T19:33:35.983Z] future_tasmin = out["ssp585"]["tasmin"]
[2025-01-09T19:33:35.983Z] future_pr = out["ssp585"]["pr"]
[2025-01-09T19:33:35.983Z] 
[2025-01-09T19:33:35.983Z] [94mTraceback:[0m
[2025-01-09T19:33:35.983Z] 
[2025-01-09T19:33:35.983Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.983Z] [0;31mTypeError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.983Z] Cell [0;32mIn[1], line 25[0m
[2025-01-09T19:33:35.983Z] [1;32m     23[0m             col_subset [38;5;241m=[39m col[38;5;241m.[39msearch(require_all_on[38;5;241m=[39m[[38;5;124m"[39m[38;5;124msource_id[39m[38;5;124m"[39m], [38;5;241m*[39m[38;5;241m*[39mquery)
[2025-01-09T19:33:35.983Z] [1;32m     24[0m             mapper [38;5;241m=[39m fsCMIP[38;5;241m.[39mget_mapper(col_subset[38;5;241m.[39mdf[38;5;241m.[39mzstore[[38;5;241m0[39m])
[2025-01-09T19:33:35.983Z] [0;32m---> 25[0m             ds [38;5;241m=[39m [43mxr[49m[38;5;241;43m.[39;49m[43mopen_zarr[49m[43m([49m[43mmapper[49m[43m,[49m[43m [49m[43mconsolidated[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m)[49m
[2025-01-09T19:33:35.983Z] [1;32m     27[0m             out[exp][variable] [38;5;241m=[39m extract_and_average(
[2025-01-09T19:33:35.983Z] [1;32m     28[0m                 mapper, period_start, period_end, basin_contour
[2025-01-09T19:33:35.983Z] [1;32m     29[0m             )[variable]
[2025-01-09T19:33:35.983Z] [1;32m     31[0m [38;5;66;03m# We can now extract the variables that we will need later:[39;00m
[2025-01-09T19:33:35.983Z] 
[2025-01-09T19:33:35.983Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:1491[0m, in [0;36mopen_zarr[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, zarr_format, use_zarr_fill_value_as_mask, chunked_array_type, from_array_kwargs, **kwargs)[0m
[2025-01-09T19:33:35.983Z] [1;32m   1477[0m     [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(
[2025-01-09T19:33:35.983Z] [1;32m   1478[0m         [38;5;124m"[39m[38;5;124mopen_zarr() got unexpected keyword arguments [39m[38;5;124m"[39m [38;5;241m+[39m [38;5;124m"[39m[38;5;124m,[39m[38;5;124m"[39m[38;5;241m.[39mjoin(kwargs[38;5;241m.[39mkeys())
[2025-01-09T19:33:35.983Z] [1;32m   1479[0m     )
[2025-01-09T19:33:35.983Z] [1;32m   1481[0m backend_kwargs [38;5;241m=[39m {
[2025-01-09T19:33:35.983Z] [1;32m   1482[0m     [38;5;124m"[39m[38;5;124msynchronizer[39m[38;5;124m"[39m: synchronizer,
[2025-01-09T19:33:35.983Z] [1;32m   1483[0m     [38;5;124m"[39m[38;5;124mconsolidated[39m[38;5;124m"[39m: consolidated,
[2025-01-09T19:33:35.983Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.983Z] [1;32m   1488[0m     [38;5;124m"[39m[38;5;124mzarr_format[39m[38;5;124m"[39m: zarr_format,
[2025-01-09T19:33:35.983Z] [1;32m   1489[0m }
[2025-01-09T19:33:35.983Z] [0;32m-> 1491[0m ds [38;5;241m=[39m [43mopen_dataset[49m[43m([49m
[2025-01-09T19:33:35.983Z] [1;32m   1492[0m [43m    [49m[43mfilename_or_obj[49m[38;5;241;43m=[39;49m[43mstore[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1493[0m [43m    [49m[43mgroup[49m[38;5;241;43m=[39;49m[43mgroup[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1494[0m [43m    [49m[43mdecode_cf[49m[38;5;241;43m=[39;49m[43mdecode_cf[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1495[0m [43m    [49m[43mmask_and_scale[49m[38;5;241;43m=[39;49m[43mmask_and_scale[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1496[0m [43m    [49m[43mdecode_times[49m[38;5;241;43m=[39;49m[43mdecode_times[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1497[0m [43m    [49m[43mconcat_characters[49m[38;5;241;43m=[39;49m[43mconcat_characters[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1498[0m [43m    [49m[43mdecode_coords[49m[38;5;241;43m=[39;49m[43mdecode_coords[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1499[0m [43m    [49m[43mengine[49m[38;5;241;43m=[39;49m[38;5;124;43m"[39;49m[38;5;124;43mzarr[39;49m[38;5;124;43m"[39;49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1500[0m [43m    [49m[43mchunks[49m[38;5;241;43m=[39;49m[43mchunks[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1501[0m [43m    [49m[43mdrop_variables[49m[38;5;241;43m=[39;49m[43mdrop_variables[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1502[0m [43m    [49m[43mchunked_array_type[49m[38;5;241;43m=[39;49m[43mchunked_array_type[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1503[0m [43m    [49m[43mfrom_array_kwargs[49m[38;5;241;43m=[39;49m[43mfrom_array_kwargs[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1504[0m [43m    [49m[43mbackend_kwargs[49m[38;5;241;43m=[39;49m[43mbackend_kwargs[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1505[0m [43m    [49m[43mdecode_timedelta[49m[38;5;241;43m=[39;49m[43mdecode_timedelta[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1506[0m [43m    [49m[43muse_cftime[49m[38;5;241;43m=[39;49m[43muse_cftime[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1507[0m [43m    [49m[43mzarr_version[49m[38;5;241;43m=[39;49m[43mzarr_version[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1508[0m [43m    [49m[43muse_zarr_fill_value_as_mask[49m[38;5;241;43m=[39;49m[43muse_zarr_fill_value_as_mask[49m[43m,[49m
[2025-01-09T19:33:35.983Z] [1;32m   1509[0m [43m[49m[43m)[49m
[2025-01-09T19:33:35.983Z] [1;32m   1510[0m [38;5;28;01mreturn[39;00m ds
[2025-01-09T19:33:35.983Z] 
[2025-01-09T19:33:35.984Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/api.py:679[0m, in [0;36mopen_dataset[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)[0m
[2025-01-09T19:33:35.984Z] [1;32m    667[0m decoders [38;5;241m=[39m _resolve_decoders_kwargs(
[2025-01-09T19:33:35.984Z] [1;32m    668[0m     decode_cf,
[2025-01-09T19:33:35.984Z] [1;32m    669[0m     open_backend_dataset_parameters[38;5;241m=[39mbackend[38;5;241m.[39mopen_dataset_parameters,
[2025-01-09T19:33:35.984Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.984Z] [1;32m    675[0m     decode_coords[38;5;241m=[39mdecode_coords,
[2025-01-09T19:33:35.984Z] [1;32m    676[0m )
[2025-01-09T19:33:35.984Z] [1;32m    678[0m overwrite_encoded_chunks [38;5;241m=[39m kwargs[38;5;241m.[39mpop([38;5;124m"[39m[38;5;124moverwrite_encoded_chunks[39m[38;5;124m"[39m, [38;5;28;01mNone[39;00m)
[2025-01-09T19:33:35.984Z] [0;32m--> 679[0m backend_ds [38;5;241m=[39m [43mbackend[49m[38;5;241;43m.[39;49m[43mopen_dataset[49m[43m([49m
[2025-01-09T19:33:35.984Z] [1;32m    680[0m [43m    [49m[43mfilename_or_obj[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    681[0m [43m    [49m[43mdrop_variables[49m[38;5;241;43m=[39;49m[43mdrop_variables[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    682[0m [43m    [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mdecoders[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    683[0m [43m    [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    684[0m [43m[49m[43m)[49m
[2025-01-09T19:33:35.984Z] [1;32m    685[0m ds [38;5;241m=[39m _dataset_from_backend_dataset(
[2025-01-09T19:33:35.984Z] [1;32m    686[0m     backend_ds,
[2025-01-09T19:33:35.984Z] [1;32m    687[0m     filename_or_obj,
[2025-01-09T19:33:35.984Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.984Z] [1;32m    697[0m     [38;5;241m*[39m[38;5;241m*[39mkwargs,
[2025-01-09T19:33:35.984Z] [1;32m    698[0m )
[2025-01-09T19:33:35.984Z] [1;32m    699[0m [38;5;28;01mreturn[39;00m ds
[2025-01-09T19:33:35.984Z] 
[2025-01-09T19:33:35.984Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:1564[0m, in [0;36mZarrBackendEntrypoint.open_dataset[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, zarr_version, zarr_format, store, engine, use_zarr_fill_value_as_mask, cache_members)[0m
[2025-01-09T19:33:35.984Z] [1;32m   1562[0m filename_or_obj [38;5;241m=[39m _normalize_path(filename_or_obj)
[2025-01-09T19:33:35.984Z] [1;32m   1563[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m store:
[2025-01-09T19:33:35.984Z] [0;32m-> 1564[0m     store [38;5;241m=[39m [43mZarrStore[49m[38;5;241;43m.[39;49m[43mopen_group[49m[43m([49m
[2025-01-09T19:33:35.984Z] [1;32m   1565[0m [43m        [49m[43mfilename_or_obj[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1566[0m [43m        [49m[43mgroup[49m[38;5;241;43m=[39;49m[43mgroup[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1567[0m [43m        [49m[43mmode[49m[38;5;241;43m=[39;49m[43mmode[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1568[0m [43m        [49m[43msynchronizer[49m[38;5;241;43m=[39;49m[43msynchronizer[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1569[0m [43m        [49m[43mconsolidated[49m[38;5;241;43m=[39;49m[43mconsolidated[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1570[0m [43m        [49m[43mconsolidate_on_close[49m[38;5;241;43m=[39;49m[38;5;28;43;01mFalse[39;49;00m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1571[0m [43m        [49m[43mchunk_store[49m[38;5;241;43m=[39;49m[43mchunk_store[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1572[0m [43m        [49m[43mstorage_options[49m[38;5;241;43m=[39;49m[43mstorage_options[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1573[0m [43m        [49m[43mzarr_version[49m[38;5;241;43m=[39;49m[43mzarr_version[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1574[0m [43m        [49m[43muse_zarr_fill_value_as_mask[49m[38;5;241;43m=[39;49m[38;5;28;43;01mNone[39;49;00m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1575[0m [43m        [49m[43mzarr_format[49m[38;5;241;43m=[39;49m[43mzarr_format[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1576[0m [43m        [49m[43mcache_members[49m[38;5;241;43m=[39;49m[43mcache_members[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m   1577[0m [43m    [49m[43m)[49m
[2025-01-09T19:33:35.984Z] [1;32m   1579[0m store_entrypoint [38;5;241m=[39m StoreBackendEntrypoint()
[2025-01-09T19:33:35.984Z] [1;32m   1580[0m [38;5;28;01mwith[39;00m close_on_error(store):
[2025-01-09T19:33:35.984Z] 
[2025-01-09T19:33:35.984Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:703[0m, in [0;36mZarrStore.open_group[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, zarr_version, zarr_format, use_zarr_fill_value_as_mask, write_empty, cache_members)[0m
[2025-01-09T19:33:35.984Z] [1;32m    678[0m [38;5;129m@classmethod[39m
[2025-01-09T19:33:35.984Z] [1;32m    679[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21mopen_group[39m(
[2025-01-09T19:33:35.984Z] [1;32m    680[0m     [38;5;28mcls[39m,
[2025-01-09T19:33:35.984Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.984Z] [1;32m    696[0m     cache_members: [38;5;28mbool[39m [38;5;241m=[39m [38;5;28;01mTrue[39;00m,
[2025-01-09T19:33:35.984Z] [1;32m    697[0m ):
[2025-01-09T19:33:35.984Z] [1;32m    698[0m     (
[2025-01-09T19:33:35.984Z] [1;32m    699[0m         zarr_group,
[2025-01-09T19:33:35.984Z] [1;32m    700[0m         consolidate_on_close,
[2025-01-09T19:33:35.984Z] [1;32m    701[0m         close_store_on_close,
[2025-01-09T19:33:35.984Z] [1;32m    702[0m         use_zarr_fill_value_as_mask,
[2025-01-09T19:33:35.984Z] [0;32m--> 703[0m     ) [38;5;241m=[39m [43m_get_open_params[49m[43m([49m
[2025-01-09T19:33:35.984Z] [1;32m    704[0m [43m        [49m[43mstore[49m[38;5;241;43m=[39;49m[43mstore[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    705[0m [43m        [49m[43mmode[49m[38;5;241;43m=[39;49m[43mmode[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    706[0m [43m        [49m[43msynchronizer[49m[38;5;241;43m=[39;49m[43msynchronizer[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    707[0m [43m        [49m[43mgroup[49m[38;5;241;43m=[39;49m[43mgroup[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    708[0m [43m        [49m[43mconsolidated[49m[38;5;241;43m=[39;49m[43mconsolidated[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    709[0m [43m        [49m[43mconsolidate_on_close[49m[38;5;241;43m=[39;49m[43mconsolidate_on_close[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    710[0m [43m        [49m[43mchunk_store[49m[38;5;241;43m=[39;49m[43mchunk_store[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    711[0m [43m        [49m[43mstorage_options[49m[38;5;241;43m=[39;49m[43mstorage_options[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    712[0m [43m        [49m[43mzarr_version[49m[38;5;241;43m=[39;49m[43mzarr_version[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    713[0m [43m        [49m[43muse_zarr_fill_value_as_mask[49m[38;5;241;43m=[39;49m[43muse_zarr_fill_value_as_mask[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    714[0m [43m        [49m[43mzarr_format[49m[38;5;241;43m=[39;49m[43mzarr_format[49m[43m,[49m
[2025-01-09T19:33:35.984Z] [1;32m    715[0m [43m    [49m[43m)[49m
[2025-01-09T19:33:35.984Z] [1;32m    717[0m     [38;5;28;01mreturn[39;00m [38;5;28mcls[39m(
[2025-01-09T19:33:35.984Z] [1;32m    718[0m         zarr_group,
[2025-01-09T19:33:35.984Z] [1;32m    719[0m         mode,
[2025-01-09T19:33:35.984Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.984Z] [1;32m    727[0m         cache_members,
[2025-01-09T19:33:35.984Z] [1;32m    728[0m     )
[2025-01-09T19:33:35.984Z] 
[2025-01-09T19:33:35.985Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:1786[0m, in [0;36m_get_open_params[0;34m(store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, zarr_version, use_zarr_fill_value_as_mask, zarr_format)[0m
[2025-01-09T19:33:35.985Z] [1;32m   1781[0m             [38;5;28;01mraise[39;00m [38;5;167;01mFileNotFoundError[39;00m(
[2025-01-09T19:33:35.985Z] [1;32m   1782[0m                 [38;5;124mf[39m[38;5;124m"[39m[38;5;124mNo such file or directory: [39m[38;5;124m'[39m[38;5;132;01m{[39;00mstore[38;5;132;01m}[39;00m[38;5;124m'[39m[38;5;124m"[39m
[2025-01-09T19:33:35.985Z] [1;32m   1783[0m             ) [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;21;01merr[39;00m
[2025-01-09T19:33:35.985Z] [1;32m   1784[0m [38;5;28;01melif[39;00m consolidated:
[2025-01-09T19:33:35.985Z] [1;32m   1785[0m     [38;5;66;03m# TODO: an option to pass the metadata_key keyword[39;00m
[2025-01-09T19:33:35.985Z] [0;32m-> 1786[0m     zarr_group [38;5;241m=[39m [43mzarr[49m[38;5;241;43m.[39;49m[43mopen_consolidated[49m[43m([49m[43mstore[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mopen_kwargs[49m[43m)[49m
[2025-01-09T19:33:35.985Z] [1;32m   1787[0m [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.985Z] [1;32m   1788[0m     [38;5;28;01mif[39;00m _zarr_v3():
[2025-01-09T19:33:35.985Z] [1;32m   1789[0m         [38;5;66;03m# we have determined that we don't want to use consolidated metadata[39;00m
[2025-01-09T19:33:35.985Z] [1;32m   1790[0m         [38;5;66;03m# so we set that to False to avoid trying to read it[39;00m
[2025-01-09T19:33:35.985Z] 
[2025-01-09T19:33:35.985Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/api/synchronous.py:212[0m, in [0;36mopen_consolidated[0;34m(use_consolidated, *args, **kwargs)[0m
[2025-01-09T19:33:35.985Z] [1;32m    207[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21mopen_consolidated[39m([38;5;241m*[39margs: Any, use_consolidated: Literal[[38;5;28;01mTrue[39;00m] [38;5;241m=[39m [38;5;28;01mTrue[39;00m, [38;5;241m*[39m[38;5;241m*[39mkwargs: Any) [38;5;241m-[39m[38;5;241m>[39m Group:
[2025-01-09T19:33:35.985Z] [1;32m    208[0m [38;5;250m    [39m[38;5;124;03m"""[39;00m
[2025-01-09T19:33:35.985Z] [1;32m    209[0m [38;5;124;03m    Alias for :func:`open_group` with ``use_consolidated=True``.[39;00m
[2025-01-09T19:33:35.985Z] [1;32m    210[0m [38;5;124;03m    """[39;00m
[2025-01-09T19:33:35.985Z] [1;32m    211[0m     [38;5;28;01mreturn[39;00m Group(
[2025-01-09T19:33:35.985Z] [0;32m--> 212[0m         [43msync[49m[43m([49m[43masync_api[49m[38;5;241;43m.[39;49m[43mopen_consolidated[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[43muse_consolidated[49m[38;5;241;43m=[39;49m[43muse_consolidated[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m[43m)[49m
[2025-01-09T19:33:35.985Z] [1;32m    213[0m     )
[2025-01-09T19:33:35.985Z] 
[2025-01-09T19:33:35.985Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/core/sync.py:142[0m, in [0;36msync[0;34m(coro, loop, timeout)[0m
[2025-01-09T19:33:35.985Z] [1;32m    139[0m return_result [38;5;241m=[39m [38;5;28mnext[39m([38;5;28miter[39m(finished))[38;5;241m.[39mresult()
[2025-01-09T19:33:35.985Z] [1;32m    141[0m [38;5;28;01mif[39;00m [38;5;28misinstance[39m(return_result, [38;5;167;01mBaseException[39;00m):
[2025-01-09T19:33:35.985Z] [0;32m--> 142[0m     [38;5;28;01mraise[39;00m return_result
[2025-01-09T19:33:35.985Z] [1;32m    143[0m [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.985Z] [1;32m    144[0m     [38;5;28;01mreturn[39;00m return_result
[2025-01-09T19:33:35.985Z] 
[2025-01-09T19:33:35.985Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/core/sync.py:98[0m, in [0;36m_runner[0;34m(coro)[0m
[2025-01-09T19:33:35.985Z] [1;32m     93[0m [38;5;250m[39m[38;5;124;03m"""[39;00m
[2025-01-09T19:33:35.985Z] [1;32m     94[0m [38;5;124;03mAwait a coroutine and return the result of running it. If awaiting the coroutine raises an[39;00m
[2025-01-09T19:33:35.985Z] [1;32m     95[0m [38;5;124;03mexception, the exception will be returned.[39;00m
[2025-01-09T19:33:35.985Z] [1;32m     96[0m [38;5;124;03m"""[39;00m
[2025-01-09T19:33:35.985Z] [1;32m     97[0m [38;5;28;01mtry[39;00m:
[2025-01-09T19:33:35.985Z] [0;32m---> 98[0m     [38;5;28;01mreturn[39;00m [38;5;28;01mawait[39;00m coro
[2025-01-09T19:33:35.985Z] [1;32m     99[0m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m [38;5;28;01mas[39;00m ex:
[2025-01-09T19:33:35.985Z] [1;32m    100[0m     [38;5;28;01mreturn[39;00m ex
[2025-01-09T19:33:35.985Z] 
[2025-01-09T19:33:35.985Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/api/asynchronous.py:346[0m, in [0;36mopen_consolidated[0;34m(use_consolidated, *args, **kwargs)[0m
[2025-01-09T19:33:35.985Z] [1;32m    341[0m [38;5;28;01mif[39;00m use_consolidated [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mTrue[39;00m:
[2025-01-09T19:33:35.985Z] [1;32m    342[0m     [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(
[2025-01-09T19:33:35.985Z] [1;32m    343[0m         [38;5;124m"[39m[38;5;124m'[39m[38;5;124muse_consolidated[39m[38;5;124m'[39m[38;5;124m must be [39m[38;5;124m'[39m[38;5;124mTrue[39m[38;5;124m'[39m[38;5;124m in [39m[38;5;124m'[39m[38;5;124mopen_consolidated[39m[38;5;124m'[39m[38;5;124m. Use [39m[38;5;124m'[39m[38;5;124mopen[39m[38;5;124m'[39m[38;5;124m with [39m[38;5;124m"[39m
[2025-01-09T19:33:35.985Z] [1;32m    344[0m         [38;5;124m"[39m[38;5;124m'[39m[38;5;124muse_consolidated=False[39m[38;5;124m'[39m[38;5;124m to bypass consolidated metadata.[39m[38;5;124m"[39m
[2025-01-09T19:33:35.985Z] [1;32m    345[0m     )
[2025-01-09T19:33:35.985Z] [0;32m--> 346[0m [38;5;28;01mreturn[39;00m [38;5;28;01mawait[39;00m open_group([38;5;241m*[39margs, use_consolidated[38;5;241m=[39muse_consolidated, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[2025-01-09T19:33:35.985Z] 
[2025-01-09T19:33:35.985Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/api/asynchronous.py:800[0m, in [0;36mopen_group[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, zarr_format, meta_array, attributes, use_consolidated)[0m
[2025-01-09T19:33:35.985Z] [1;32m    797[0m [38;5;28;01mif[39;00m chunk_store [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:
[2025-01-09T19:33:35.985Z] [1;32m    798[0m     warnings[38;5;241m.[39mwarn([38;5;124m"[39m[38;5;124mchunk_store is not yet implemented[39m[38;5;124m"[39m, [38;5;167;01mRuntimeWarning[39;00m, stacklevel[38;5;241m=[39m[38;5;241m2[39m)
[2025-01-09T19:33:35.985Z] [0;32m--> 800[0m store_path [38;5;241m=[39m [38;5;28;01mawait[39;00m make_store_path(store, mode[38;5;241m=[39mmode, storage_options[38;5;241m=[39mstorage_options, path[38;5;241m=[39mpath)
[2025-01-09T19:33:35.985Z] [1;32m    802[0m [38;5;28;01mif[39;00m attributes [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[2025-01-09T19:33:35.985Z] [1;32m    803[0m     attributes [38;5;241m=[39m {}
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/storage/_common.py:316[0m, in [0;36mmake_store_path[0;34m(store_like, path, mode, storage_options)[0m
[2025-01-09T19:33:35.986Z] [1;32m    314[0m     [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.986Z] [1;32m    315[0m         msg [38;5;241m=[39m [38;5;124mf[39m[38;5;124m"[39m[38;5;124mUnsupported type for store_like: [39m[38;5;124m'[39m[38;5;132;01m{[39;00m[38;5;28mtype[39m(store_like)[38;5;241m.[39m[38;5;18m__name__[39m[38;5;132;01m}[39;00m[38;5;124m'[39m[38;5;124m"[39m  [38;5;66;03m# type: ignore[unreachable][39;00m
[2025-01-09T19:33:35.986Z] [0;32m--> 316[0m         [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(msg)
[2025-01-09T19:33:35.986Z] [1;32m    318[0m     result [38;5;241m=[39m [38;5;28;01mawait[39;00m StorePath[38;5;241m.[39mopen(store, path[38;5;241m=[39mpath_normalized, mode[38;5;241m=[39mmode)
[2025-01-09T19:33:35.986Z] [1;32m    320[0m [38;5;28;01mif[39;00m storage_options [38;5;129;01mand[39;00m [38;5;129;01mnot[39;00m used_storage_options:
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] [0;31mTypeError[0m: Unsupported type for store_like: 'FSMap'
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] _ RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 12 _
[2025-01-09T19:33:35.986Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.986Z] [94mCell 12: Cell execution caused an exception
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] Input:
[2025-01-09T19:33:35.986Z] [0m# Here we need to make sure that our units are all in the correct format.
[2025-01-09T19:33:35.986Z] # You can play around with the tools we've seen thus far to explore the units and make sure everything is consistent.
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Let's start with precipitation:
[2025-01-09T19:33:35.986Z] ERA5_pr = xclim.core.units.convert_units_to(ERA5_pr, "mm", context="hydro")
[2025-01-09T19:33:35.986Z] # The CMIP data is a rate rather than an absolute value, so let's get the absolute values:
[2025-01-09T19:33:35.986Z] historical_pr = xclim.core.units.rate2amount(historical_pr)
[2025-01-09T19:33:35.986Z] future_pr = xclim.core.units.rate2amount(future_pr)
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Now we can actually convert units in absolute terms.
[2025-01-09T19:33:35.986Z] historical_pr = xclim.core.units.convert_units_to(historical_pr, "mm", context="hydro")
[2025-01-09T19:33:35.986Z] future_pr = xclim.core.units.convert_units_to(future_pr, "mm", context="hydro")
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Now let's do temperature:
[2025-01-09T19:33:35.986Z] ERA5_tmin = xclim.core.units.convert_units_to(ERA5_tmin, "degC")
[2025-01-09T19:33:35.986Z] ERA5_tmax = xclim.core.units.convert_units_to(ERA5_tmax, "degC")
[2025-01-09T19:33:35.986Z] historical_tasmin = xclim.core.units.convert_units_to(historical_tasmin, "degC")
[2025-01-09T19:33:35.986Z] historical_tasmax = xclim.core.units.convert_units_to(historical_tasmax, "degC")
[2025-01-09T19:33:35.986Z] future_tasmin = xclim.core.units.convert_units_to(future_tasmin, "degC")
[2025-01-09T19:33:35.986Z] future_tasmax = xclim.core.units.convert_units_to(future_tasmax, "degC")
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] [94mTraceback:[0m
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.986Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.986Z] Cell [0;32mIn[1], line 7[0m
[2025-01-09T19:33:35.986Z] [1;32m      5[0m ERA5_pr [38;5;241m=[39m xclim[38;5;241m.[39mcore[38;5;241m.[39munits[38;5;241m.[39mconvert_units_to(ERA5_pr, [38;5;124m"[39m[38;5;124mmm[39m[38;5;124m"[39m, context[38;5;241m=[39m[38;5;124m"[39m[38;5;124mhydro[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.986Z] [1;32m      6[0m [38;5;66;03m# The CMIP data is a rate rather than an absolute value, so let's get the absolute values:[39;00m
[2025-01-09T19:33:35.986Z] [0;32m----> 7[0m historical_pr [38;5;241m=[39m xclim[38;5;241m.[39mcore[38;5;241m.[39munits[38;5;241m.[39mrate2amount([43mhistorical_pr[49m)
[2025-01-09T19:33:35.986Z] [1;32m      8[0m future_pr [38;5;241m=[39m xclim[38;5;241m.[39mcore[38;5;241m.[39munits[38;5;241m.[39mrate2amount(future_pr)
[2025-01-09T19:33:35.986Z] [1;32m     10[0m [38;5;66;03m# Now we can actually convert units in absolute terms.[39;00m
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] [0;31mNameError[0m: name 'historical_pr' is not defined
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] _ RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 13 _
[2025-01-09T19:33:35.986Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.986Z] [94mCell 13: Cell execution caused an exception
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] Input:
[2025-01-09T19:33:35.986Z] [0m# Use xclim utilities (SDBA) to give information on the type of window used for the bias correction.
[2025-01-09T19:33:35.986Z] group_month_window = sdba.utils.Grouper("time.dayofyear", window=15)
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # This is an adjusting function. It builds the tool that will perform the corrections.
[2025-01-09T19:33:35.986Z] Adjustment = sdba.DetrendedQuantileMapping.train(
[2025-01-09T19:33:35.986Z]     ref=ERA5_pr, hist=historical_pr, nquantiles=50, kind="+", group=group_month_window
[2025-01-09T19:33:35.986Z] )
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Apply the correction factors on the reference period.
[2025-01-09T19:33:35.986Z] corrected_ref_precip = Adjustment.adjust(historical_pr, interp="linear")
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Apply the correction factors on the future period.
[2025-01-09T19:33:35.986Z] corrected_fut_precip = Adjustment.adjust(future_pr, interp="linear")
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Ensure that the precipitation is non-negative, which can happen with some climate models.
[2025-01-09T19:33:35.986Z] corrected_ref_precip = corrected_ref_precip.where(corrected_ref_precip > 0, 0)
[2025-01-09T19:33:35.986Z] corrected_fut_precip = corrected_fut_precip.where(corrected_fut_precip > 0, 0)
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Train the model to find the correction factors for the maximum temperature (tasmax) data.
[2025-01-09T19:33:35.986Z] Adjustment = sdba.DetrendedQuantileMapping.train(
[2025-01-09T19:33:35.986Z]     ref=ERA5_tmax,
[2025-01-09T19:33:35.986Z]     hist=historical_tasmax,
[2025-01-09T19:33:35.986Z]     nquantiles=50,
[2025-01-09T19:33:35.986Z]     kind="+",
[2025-01-09T19:33:35.986Z]     group=group_month_window,
[2025-01-09T19:33:35.986Z] )
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Apply the correction factors on the reference period.
[2025-01-09T19:33:35.986Z] corrected_ref_tasmax = Adjustment.adjust(historical_tasmax, interp="linear")
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Apply the correction factors on the future period.
[2025-01-09T19:33:35.986Z] corrected_fut_tasmax = Adjustment.adjust(future_tasmax, interp="linear")
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Train the model to find the correction factors for the minimum temperature (tasmin) data.
[2025-01-09T19:33:35.986Z] Adjustment = sdba.DetrendedQuantileMapping.train(
[2025-01-09T19:33:35.986Z]     ref=ERA5_tmin,
[2025-01-09T19:33:35.986Z]     hist=historical_tasmin,
[2025-01-09T19:33:35.986Z]     nquantiles=50,
[2025-01-09T19:33:35.986Z]     kind="+",
[2025-01-09T19:33:35.986Z]     group=group_month_window,
[2025-01-09T19:33:35.986Z] )
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Apply the correction factors on the reference period
[2025-01-09T19:33:35.986Z] corrected_ref_tasmin = Adjustment.adjust(historical_tasmin, interp="linear")
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] # Apply the correction factors on the future period
[2025-01-09T19:33:35.986Z] corrected_fut_tasmin = Adjustment.adjust(future_tasmin, interp="linear")
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] [94mTraceback:[0m
[2025-01-09T19:33:35.986Z] 
[2025-01-09T19:33:35.986Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.986Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.986Z] Cell [0;32mIn[1], line 6[0m
[2025-01-09T19:33:35.986Z] [1;32m      2[0m group_month_window [38;5;241m=[39m sdba[38;5;241m.[39mutils[38;5;241m.[39mGrouper([38;5;124m"[39m[38;5;124mtime.dayofyear[39m[38;5;124m"[39m, window[38;5;241m=[39m[38;5;241m15[39m)
[2025-01-09T19:33:35.986Z] [1;32m      4[0m [38;5;66;03m# This is an adjusting function. It builds the tool that will perform the corrections.[39;00m
[2025-01-09T19:33:35.986Z] [1;32m      5[0m Adjustment [38;5;241m=[39m sdba[38;5;241m.[39mDetrendedQuantileMapping[38;5;241m.[39mtrain(
[2025-01-09T19:33:35.987Z] [0;32m----> 6[0m     ref[38;5;241m=[39mERA5_pr, hist[38;5;241m=[39m[43mhistorical_pr[49m, nquantiles[38;5;241m=[39m[38;5;241m50[39m, kind[38;5;241m=[39m[38;5;124m"[39m[38;5;124m+[39m[38;5;124m"[39m, group[38;5;241m=[39mgroup_month_window
[2025-01-09T19:33:35.987Z] [1;32m      7[0m )
[2025-01-09T19:33:35.987Z] [1;32m      9[0m [38;5;66;03m# Apply the correction factors on the reference period.[39;00m
[2025-01-09T19:33:35.987Z] [1;32m     10[0m corrected_ref_precip [38;5;241m=[39m Adjustment[38;5;241m.[39madjust(historical_pr, interp[38;5;241m=[39m[38;5;124m"[39m[38;5;124mlinear[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [0;31mNameError[0m: name 'historical_pr' is not defined
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] _ RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 14 _
[2025-01-09T19:33:35.987Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.987Z] [94mCell 14: Cell execution caused an exception
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] Input:
[2025-01-09T19:33:35.987Z] [0m# Convert the reference corrected data into netCDF file.
[2025-01-09T19:33:35.987Z] # We will then apply a special code to remove a dimension in the dataset to make it applicable to the RAVEN models.
[2025-01-09T19:33:35.987Z] ref_dataset = xr.merge(
[2025-01-09T19:33:35.987Z]     [
[2025-01-09T19:33:35.987Z]         corrected_ref_precip.to_dataset(name="pr"),
[2025-01-09T19:33:35.987Z]         corrected_ref_tasmax.to_dataset(name="tasmax"),
[2025-01-09T19:33:35.987Z]         corrected_ref_tasmin.to_dataset(name="tasmin"),
[2025-01-09T19:33:35.987Z]     ]
[2025-01-09T19:33:35.987Z] )
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] # Write to temporary folder.
[2025-01-09T19:33:35.987Z] fn_ref = tmp / "reference_dataset.nc"
[2025-01-09T19:33:35.987Z] ref_dataset.to_netcdf(fn_ref)
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] # Convert the future corrected data into netCDF file.
[2025-01-09T19:33:35.987Z] fut_dataset = xr.merge(
[2025-01-09T19:33:35.987Z]     [
[2025-01-09T19:33:35.987Z]         corrected_fut_precip.to_dataset(name="pr"),
[2025-01-09T19:33:35.987Z]         corrected_fut_tasmax.to_dataset(name="tasmax"),
[2025-01-09T19:33:35.987Z]         corrected_fut_tasmin.to_dataset(name="tasmin"),
[2025-01-09T19:33:35.987Z]     ]
[2025-01-09T19:33:35.987Z] )
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] fn_fut = tmp / "future_dataset.nc"
[2025-01-09T19:33:35.987Z] fut_dataset.to_netcdf(fn_fut)
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [94mTraceback:[0m
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.987Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.987Z] Cell [0;32mIn[1], line 5[0m
[2025-01-09T19:33:35.987Z] [1;32m      1[0m [38;5;66;03m# Convert the reference corrected data into netCDF file.[39;00m
[2025-01-09T19:33:35.987Z] [1;32m      2[0m [38;5;66;03m# We will then apply a special code to remove a dimension in the dataset to make it applicable to the RAVEN models.[39;00m
[2025-01-09T19:33:35.987Z] [1;32m      3[0m ref_dataset [38;5;241m=[39m xr[38;5;241m.[39mmerge(
[2025-01-09T19:33:35.987Z] [1;32m      4[0m     [
[2025-01-09T19:33:35.987Z] [0;32m----> 5[0m         [43mcorrected_ref_precip[49m[38;5;241m.[39mto_dataset(name[38;5;241m=[39m[38;5;124m"[39m[38;5;124mpr[39m[38;5;124m"[39m),
[2025-01-09T19:33:35.987Z] [1;32m      6[0m         corrected_ref_tasmax[38;5;241m.[39mto_dataset(name[38;5;241m=[39m[38;5;124m"[39m[38;5;124mtasmax[39m[38;5;124m"[39m),
[2025-01-09T19:33:35.987Z] [1;32m      7[0m         corrected_ref_tasmin[38;5;241m.[39mto_dataset(name[38;5;241m=[39m[38;5;124m"[39m[38;5;124mtasmin[39m[38;5;124m"[39m),
[2025-01-09T19:33:35.987Z] [1;32m      8[0m     ]
[2025-01-09T19:33:35.987Z] [1;32m      9[0m )
[2025-01-09T19:33:35.987Z] [1;32m     11[0m [38;5;66;03m# Write to temporary folder.[39;00m
[2025-01-09T19:33:35.987Z] [1;32m     12[0m fn_ref [38;5;241m=[39m tmp [38;5;241m/[39m [38;5;124m"[39m[38;5;124mreference_dataset.nc[39m[38;5;124m"[39m
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [0;31mNameError[0m: name 'corrected_ref_precip' is not defined
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] _ RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 15 _
[2025-01-09T19:33:35.987Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.987Z] [94mCell 15: Cell execution caused an exception
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] Input:
[2025-01-09T19:33:35.987Z] [0m# Show the corrected future precipitation.
[2025-01-09T19:33:35.987Z] corrected_fut_precip.plot()
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [94mTraceback:[0m
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.987Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.987Z] Cell [0;32mIn[1], line 2[0m
[2025-01-09T19:33:35.987Z] [1;32m      1[0m [38;5;66;03m# Show the corrected future precipitation.[39;00m
[2025-01-09T19:33:35.987Z] [0;32m----> 2[0m [43mcorrected_fut_precip[49m[38;5;241m.[39mplot()
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [0;31mNameError[0m: name 'corrected_fut_precip' is not defined
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] _ RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 16 _
[2025-01-09T19:33:35.987Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.987Z] [94mCell 16: Cell execution caused an exception
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] Input:
[2025-01-09T19:33:35.987Z] [0m# Compare it to the future precipitation without bias-correction.
[2025-01-09T19:33:35.987Z] future_pr.plot()
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [94mTraceback:[0m
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.987Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.987Z] Cell [0;32mIn[1], line 2[0m
[2025-01-09T19:33:35.987Z] [1;32m      1[0m [38;5;66;03m# Compare it to the future precipitation without bias-correction.[39;00m
[2025-01-09T19:33:35.987Z] [0;32m----> 2[0m [43mfuture_pr[49m[38;5;241m.[39mplot()
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [0;31mNameError[0m: name 'future_pr' is not defined
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] ______ RavenPy-master/docs/notebooks/HydroShare_integration.ipynb::Cell 0 ______
[2025-01-09T19:33:35.987Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.987Z] [94mCell 0: Cell execution caused an exception
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] Input:
[2025-01-09T19:33:35.987Z] [0mimport os
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] from hsclient import HydroShare, Token
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] # Authentication method using username and password
[2025-01-09T19:33:35.987Z] """
[2025-01-09T19:33:35.987Z] username = 'XXXXX'
[2025-01-09T19:33:35.987Z] password = 'XXXXX'
[2025-01-09T19:33:35.987Z] hs = HydroShare(username=username, password=password)
[2025-01-09T19:33:35.987Z] """
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] client_id = os.environ.get("HYDROSHARE_AUTH_CLIENT_ID", "<your_client_id>")
[2025-01-09T19:33:35.987Z] access_token = os.environ.get("HYDROSHARE_AUTH_TOKEN", "<your_auth_token>")
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] token = Token(access_token=access_token, token_type="bearer")
[2025-01-09T19:33:35.987Z] hs = HydroShare(client_id=client_id, token=token)
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [94mTraceback:[0m
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.987Z] [0;31mException[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.987Z] Cell [0;32mIn[1], line 16[0m
[2025-01-09T19:33:35.987Z] [1;32m     13[0m access_token [38;5;241m=[39m os[38;5;241m.[39menviron[38;5;241m.[39mget([38;5;124m"[39m[38;5;124mHYDROSHARE_AUTH_TOKEN[39m[38;5;124m"[39m, [38;5;124m"[39m[38;5;124m<your_auth_token>[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.987Z] [1;32m     15[0m token [38;5;241m=[39m Token(access_token[38;5;241m=[39maccess_token, token_type[38;5;241m=[39m[38;5;124m"[39m[38;5;124mbearer[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.987Z] [0;32m---> 16[0m hs [38;5;241m=[39m [43mHydroShare[49m[43m([49m[43mclient_id[49m[38;5;241;43m=[39;49m[43mclient_id[49m[43m,[49m[43m [49m[43mtoken[49m[38;5;241;43m=[39;49m[43mtoken[49m[43m)[49m
[2025-01-09T19:33:35.987Z] 
[2025-01-09T19:33:35.987Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/hsclient/hydroshare.py:1488[0m, in [0;36mHydroShare.__init__[0;34m(self, username, password, host, protocol, port, client_id, token)[0m
[2025-01-09T19:33:35.987Z] [1;32m   1484[0m     [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.988Z] [1;32m   1485[0m         [38;5;28mself[39m[38;5;241m.[39m_hs_session [38;5;241m=[39m HydroShareSession(
[2025-01-09T19:33:35.988Z] [1;32m   1486[0m             host[38;5;241m=[39mhost, protocol[38;5;241m=[39mprotocol, port[38;5;241m=[39mport, client_id[38;5;241m=[39mclient_id, token[38;5;241m=[39mtoken
[2025-01-09T19:33:35.988Z] [1;32m   1487[0m         )
[2025-01-09T19:33:35.988Z] [0;32m-> 1488[0m         [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mmy_user_info[49m[43m([49m[43m)[49m  [38;5;66;03m# validate credentials[39;00m
[2025-01-09T19:33:35.988Z] [1;32m   1489[0m [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.988Z] [1;32m   1490[0m     [38;5;28mself[39m[38;5;241m.[39m_hs_session [38;5;241m=[39m HydroShareSession(
[2025-01-09T19:33:35.988Z] [1;32m   1491[0m         username[38;5;241m=[39musername, password[38;5;241m=[39mpassword, host[38;5;241m=[39mhost, protocol[38;5;241m=[39mprotocol, port[38;5;241m=[39mport
[2025-01-09T19:33:35.988Z] [1;32m   1492[0m     )
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/hsclient/hydroshare.py:1655[0m, in [0;36mHydroShare.my_user_info[0;34m(self)[0m
[2025-01-09T19:33:35.988Z] [1;32m   1650[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21mmy_user_info[39m([38;5;28mself[39m):
[2025-01-09T19:33:35.988Z] [1;32m   1651[0m [38;5;250m    [39m[38;5;124;03m"""[39;00m
[2025-01-09T19:33:35.988Z] [1;32m   1652[0m [38;5;124;03m    Retrieves the user info of the user's credentials provided[39;00m
[2025-01-09T19:33:35.988Z] [1;32m   1653[0m [38;5;124;03m    :return: JSON object representing the user info[39;00m
[2025-01-09T19:33:35.988Z] [1;32m   1654[0m [38;5;124;03m    """[39;00m
[2025-01-09T19:33:35.988Z] [0;32m-> 1655[0m     response [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_hs_session[49m[38;5;241;43m.[39;49m[43mget[49m[43m([49m[38;5;124;43m'[39;49m[38;5;124;43m/hsapi/userInfo/[39;49m[38;5;124;43m'[39;49m[43m,[49m[43m [49m[43mstatus_code[49m[38;5;241;43m=[39;49m[38;5;241;43m200[39;49m[43m)[49m
[2025-01-09T19:33:35.988Z] [1;32m   1656[0m     [38;5;28;01mreturn[39;00m response[38;5;241m.[39mjson()
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/hsclient/hydroshare.py:1419[0m, in [0;36mHydroShareSession.get[0;34m(self, path, status_code, **kwargs)[0m
[2025-01-09T19:33:35.988Z] [1;32m   1417[0m response [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_session[38;5;241m.[39mget(url, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[2025-01-09T19:33:35.988Z] [1;32m   1418[0m [38;5;28;01mif[39;00m response[38;5;241m.[39mstatus_code [38;5;241m!=[39m status_code:
[2025-01-09T19:33:35.988Z] [0;32m-> 1419[0m     [38;5;28;01mraise[39;00m [38;5;167;01mException[39;00m(
[2025-01-09T19:33:35.988Z] [1;32m   1420[0m         [38;5;124m"[39m[38;5;124mFailed GET [39m[38;5;132;01m{}[39;00m[38;5;124m, status_code [39m[38;5;132;01m{}[39;00m[38;5;124m, message [39m[38;5;132;01m{}[39;00m[38;5;124m"[39m[38;5;241m.[39mformat(url, response[38;5;241m.[39mstatus_code, response[38;5;241m.[39mcontent)
[2025-01-09T19:33:35.988Z] [1;32m   1421[0m     )
[2025-01-09T19:33:35.988Z] [1;32m   1422[0m [38;5;28;01mreturn[39;00m response
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] [0;31mException[0m: Failed GET https://www.hydroshare.org:443/hsapi/userInfo/, status_code 403, message b'{"detail":"Token verification failed"}'
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] ______ RavenPy-master/docs/notebooks/HydroShare_integration.ipynb::Cell 1 ______
[2025-01-09T19:33:35.988Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.988Z] [94mCell 1: Cell execution caused an exception
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] Input:
[2025-01-09T19:33:35.988Z] [0mresults = hs.search(subject=["Harvey"])
[2025-01-09T19:33:35.988Z] for r in results:
[2025-01-09T19:33:35.988Z]     print(r.resource_title, ": ", r.resource_id)
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] [94mTraceback:[0m
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.988Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.988Z] Cell [0;32mIn[1], line 1[0m
[2025-01-09T19:33:35.988Z] [0;32m----> 1[0m results [38;5;241m=[39m [43mhs[49m[38;5;241m.[39msearch(subject[38;5;241m=[39m[[38;5;124m"[39m[38;5;124mHarvey[39m[38;5;124m"[39m])
[2025-01-09T19:33:35.988Z] [1;32m      2[0m [38;5;28;01mfor[39;00m r [38;5;129;01min[39;00m results:
[2025-01-09T19:33:35.988Z] [1;32m      3[0m     [38;5;28mprint[39m(r[38;5;241m.[39mresource_title, [38;5;124m"[39m[38;5;124m: [39m[38;5;124m"[39m, r[38;5;241m.[39mresource_id)
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] [0;31mNameError[0m: name 'hs' is not defined
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] ______ RavenPy-master/docs/notebooks/HydroShare_integration.ipynb::Cell 2 ______
[2025-01-09T19:33:35.988Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.988Z] [94mCell 2: Cell execution caused an exception
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] Input:
[2025-01-09T19:33:35.988Z] [0mres = hs.resource("51d1539bf6e94b15ac33f7631228118c", validate=False)
[2025-01-09T19:33:35.988Z] res.files()
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] [94mTraceback:[0m
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.988Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.988Z] Cell [0;32mIn[1], line 1[0m
[2025-01-09T19:33:35.988Z] [0;32m----> 1[0m res [38;5;241m=[39m [43mhs[49m[38;5;241m.[39mresource([38;5;124m"[39m[38;5;124m51d1539bf6e94b15ac33f7631228118c[39m[38;5;124m"[39m, validate[38;5;241m=[39m[38;5;28;01mFalse[39;00m)
[2025-01-09T19:33:35.988Z] [1;32m      2[0m res[38;5;241m.[39mfiles()
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] [0;31mNameError[0m: name 'hs' is not defined
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] ______ RavenPy-master/docs/notebooks/HydroShare_integration.ipynb::Cell 3 ______
[2025-01-09T19:33:35.988Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.988Z] [94mCell 3: Cell execution caused an exception
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] Input:
[2025-01-09T19:33:35.988Z] [0mres.file_download("USGS_Harvey_gages_TxLaMsAr.csv", save_path="/tmp")
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] [94mTraceback:[0m
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.988Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.988Z] Cell [0;32mIn[1], line 1[0m
[2025-01-09T19:33:35.988Z] [0;32m----> 1[0m [43mres[49m[38;5;241m.[39mfile_download([38;5;124m"[39m[38;5;124mUSGS_Harvey_gages_TxLaMsAr.csv[39m[38;5;124m"[39m, save_path[38;5;241m=[39m[38;5;124m"[39m[38;5;124m/tmp[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] [0;31mNameError[0m: name 'res' is not defined
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] _ RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 11 _
[2025-01-09T19:33:35.988Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.988Z] [94mCell 11: Cell execution caused an exception
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] Input:
[2025-01-09T19:33:35.988Z] [0m# Climate model to use.
[2025-01-09T19:33:35.988Z] climate_model = "MIROC6"
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] # Get the catalog info from the PANGEO dataset, which basically is a list of links to the various products.
[2025-01-09T19:33:35.988Z] fsCMIP = gcsfs.GCSFileSystem(token="anon", access="read_only")
[2025-01-09T19:33:35.988Z] col = intake.open_esm_datastore(
[2025-01-09T19:33:35.988Z]     "https://storage.googleapis.com/cmip6/pangeo-cmip6.json"
[2025-01-09T19:33:35.988Z] )
[2025-01-09T19:33:35.988Z] 
[2025-01-09T19:33:35.988Z] # We will add a wrapper to ensure that the following operations will preserve the original data attributes, such as units and variable names.
[2025-01-09T19:33:35.988Z] with xr.set_options(keep_attrs=True):
[2025-01-09T19:33:35.989Z]     # Load the files from the PanGEO catalogs, for reference and future variables of temperature and precipitation.
[2025-01-09T19:33:35.989Z]     out = {}
[2025-01-09T19:33:35.989Z]     for exp in ["historical", "ssp585"]:
[2025-01-09T19:33:35.989Z]         if exp == "historical":
[2025-01-09T19:33:35.989Z]             period_start = reference_start_day
[2025-01-09T19:33:35.989Z]             period_end = reference_end_day
[2025-01-09T19:33:35.989Z]         else:
[2025-01-09T19:33:35.989Z]             period_start = future_start_day
[2025-01-09T19:33:35.989Z]             period_end = future_end_day
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.989Z]         out[exp] = {}
[2025-01-09T19:33:35.989Z]         for variable in ["tasmin", "tasmax", "pr"]:
[2025-01-09T19:33:35.989Z]             print(exp, variable)
[2025-01-09T19:33:35.989Z]             query = dict(
[2025-01-09T19:33:35.989Z]                 experiment_id=exp,
[2025-01-09T19:33:35.989Z]                 table_id="day",
[2025-01-09T19:33:35.989Z]                 variable_id=variable,
[2025-01-09T19:33:35.989Z]                 member_id="r1i1p1f1",
[2025-01-09T19:33:35.989Z]                 source_id=climate_model,
[2025-01-09T19:33:35.989Z]             )
[2025-01-09T19:33:35.989Z]             col_subset = col.search(require_all_on=["source_id"], **query)
[2025-01-09T19:33:35.989Z]             mapper = fsCMIP.get_mapper(col_subset.df.zstore[0])
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.989Z]             ds = xr.open_zarr(mapper, consolidated=True).sel(
[2025-01-09T19:33:35.989Z]                 time=slice(period_start, period_end)
[2025-01-09T19:33:35.989Z]             )
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.989Z]             if "height" in ds.coords:
[2025-01-09T19:33:35.989Z]                 ds = ds.drop_vars("height")
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.989Z]             # Set the date to the midnight of the given day.
[2025-01-09T19:33:35.989Z]             ds = ds.assign_coords(time=ds.time.dt.floor("D"))
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.989Z]             out[exp][variable] = average.average_shape(
[2025-01-09T19:33:35.989Z]                 ds,
[2025-01-09T19:33:35.989Z]                 basin_contour,
[2025-01-09T19:33:35.989Z]             )[
[2025-01-09T19:33:35.989Z]                 variable
[2025-01-09T19:33:35.989Z]             ].chunk(-1)
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.989Z] # We can now extract the variables that we will need later:
[2025-01-09T19:33:35.989Z] historical_tasmax = out["historical"]["tasmax"]
[2025-01-09T19:33:35.989Z] historical_tasmin = out["historical"]["tasmin"]
[2025-01-09T19:33:35.989Z] historical_pr = out["historical"]["pr"]
[2025-01-09T19:33:35.989Z] future_tasmax = out["ssp585"]["tasmax"]
[2025-01-09T19:33:35.989Z] future_tasmin = out["ssp585"]["tasmin"]
[2025-01-09T19:33:35.989Z] future_pr = out["ssp585"]["pr"]
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.989Z] [94mTraceback:[0m
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.989Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.989Z] [0;31mTypeError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.989Z] Cell [0;32mIn[1], line 35[0m
[2025-01-09T19:33:35.989Z] [1;32m     32[0m col_subset [38;5;241m=[39m col[38;5;241m.[39msearch(require_all_on[38;5;241m=[39m[[38;5;124m"[39m[38;5;124msource_id[39m[38;5;124m"[39m], [38;5;241m*[39m[38;5;241m*[39mquery)
[2025-01-09T19:33:35.989Z] [1;32m     33[0m mapper [38;5;241m=[39m fsCMIP[38;5;241m.[39mget_mapper(col_subset[38;5;241m.[39mdf[38;5;241m.[39mzstore[[38;5;241m0[39m])
[2025-01-09T19:33:35.989Z] [0;32m---> 35[0m ds [38;5;241m=[39m [43mxr[49m[38;5;241;43m.[39;49m[43mopen_zarr[49m[43m([49m[43mmapper[49m[43m,[49m[43m [49m[43mconsolidated[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m)[49m[38;5;241m.[39msel(
[2025-01-09T19:33:35.989Z] [1;32m     36[0m     time[38;5;241m=[39m[38;5;28mslice[39m(period_start, period_end)
[2025-01-09T19:33:35.989Z] [1;32m     37[0m )
[2025-01-09T19:33:35.989Z] [1;32m     39[0m [38;5;28;01mif[39;00m [38;5;124m"[39m[38;5;124mheight[39m[38;5;124m"[39m [38;5;129;01min[39;00m ds[38;5;241m.[39mcoords:
[2025-01-09T19:33:35.989Z] [1;32m     40[0m     ds [38;5;241m=[39m ds[38;5;241m.[39mdrop_vars([38;5;124m"[39m[38;5;124mheight[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.989Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:1491[0m, in [0;36mopen_zarr[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, zarr_format, use_zarr_fill_value_as_mask, chunked_array_type, from_array_kwargs, **kwargs)[0m
[2025-01-09T19:33:35.989Z] [1;32m   1477[0m     [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(
[2025-01-09T19:33:35.989Z] [1;32m   1478[0m         [38;5;124m"[39m[38;5;124mopen_zarr() got unexpected keyword arguments [39m[38;5;124m"[39m [38;5;241m+[39m [38;5;124m"[39m[38;5;124m,[39m[38;5;124m"[39m[38;5;241m.[39mjoin(kwargs[38;5;241m.[39mkeys())
[2025-01-09T19:33:35.989Z] [1;32m   1479[0m     )
[2025-01-09T19:33:35.989Z] [1;32m   1481[0m backend_kwargs [38;5;241m=[39m {
[2025-01-09T19:33:35.989Z] [1;32m   1482[0m     [38;5;124m"[39m[38;5;124msynchronizer[39m[38;5;124m"[39m: synchronizer,
[2025-01-09T19:33:35.989Z] [1;32m   1483[0m     [38;5;124m"[39m[38;5;124mconsolidated[39m[38;5;124m"[39m: consolidated,
[2025-01-09T19:33:35.989Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.989Z] [1;32m   1488[0m     [38;5;124m"[39m[38;5;124mzarr_format[39m[38;5;124m"[39m: zarr_format,
[2025-01-09T19:33:35.989Z] [1;32m   1489[0m }
[2025-01-09T19:33:35.989Z] [0;32m-> 1491[0m ds [38;5;241m=[39m [43mopen_dataset[49m[43m([49m
[2025-01-09T19:33:35.989Z] [1;32m   1492[0m [43m    [49m[43mfilename_or_obj[49m[38;5;241;43m=[39;49m[43mstore[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1493[0m [43m    [49m[43mgroup[49m[38;5;241;43m=[39;49m[43mgroup[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1494[0m [43m    [49m[43mdecode_cf[49m[38;5;241;43m=[39;49m[43mdecode_cf[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1495[0m [43m    [49m[43mmask_and_scale[49m[38;5;241;43m=[39;49m[43mmask_and_scale[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1496[0m [43m    [49m[43mdecode_times[49m[38;5;241;43m=[39;49m[43mdecode_times[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1497[0m [43m    [49m[43mconcat_characters[49m[38;5;241;43m=[39;49m[43mconcat_characters[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1498[0m [43m    [49m[43mdecode_coords[49m[38;5;241;43m=[39;49m[43mdecode_coords[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1499[0m [43m    [49m[43mengine[49m[38;5;241;43m=[39;49m[38;5;124;43m"[39;49m[38;5;124;43mzarr[39;49m[38;5;124;43m"[39;49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1500[0m [43m    [49m[43mchunks[49m[38;5;241;43m=[39;49m[43mchunks[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1501[0m [43m    [49m[43mdrop_variables[49m[38;5;241;43m=[39;49m[43mdrop_variables[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1502[0m [43m    [49m[43mchunked_array_type[49m[38;5;241;43m=[39;49m[43mchunked_array_type[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1503[0m [43m    [49m[43mfrom_array_kwargs[49m[38;5;241;43m=[39;49m[43mfrom_array_kwargs[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1504[0m [43m    [49m[43mbackend_kwargs[49m[38;5;241;43m=[39;49m[43mbackend_kwargs[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1505[0m [43m    [49m[43mdecode_timedelta[49m[38;5;241;43m=[39;49m[43mdecode_timedelta[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1506[0m [43m    [49m[43muse_cftime[49m[38;5;241;43m=[39;49m[43muse_cftime[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1507[0m [43m    [49m[43mzarr_version[49m[38;5;241;43m=[39;49m[43mzarr_version[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1508[0m [43m    [49m[43muse_zarr_fill_value_as_mask[49m[38;5;241;43m=[39;49m[43muse_zarr_fill_value_as_mask[49m[43m,[49m
[2025-01-09T19:33:35.989Z] [1;32m   1509[0m [43m[49m[43m)[49m
[2025-01-09T19:33:35.989Z] [1;32m   1510[0m [38;5;28;01mreturn[39;00m ds
[2025-01-09T19:33:35.989Z] 
[2025-01-09T19:33:35.990Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/api.py:679[0m, in [0;36mopen_dataset[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)[0m
[2025-01-09T19:33:35.990Z] [1;32m    667[0m decoders [38;5;241m=[39m _resolve_decoders_kwargs(
[2025-01-09T19:33:35.990Z] [1;32m    668[0m     decode_cf,
[2025-01-09T19:33:35.990Z] [1;32m    669[0m     open_backend_dataset_parameters[38;5;241m=[39mbackend[38;5;241m.[39mopen_dataset_parameters,
[2025-01-09T19:33:35.990Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.990Z] [1;32m    675[0m     decode_coords[38;5;241m=[39mdecode_coords,
[2025-01-09T19:33:35.990Z] [1;32m    676[0m )
[2025-01-09T19:33:35.990Z] [1;32m    678[0m overwrite_encoded_chunks [38;5;241m=[39m kwargs[38;5;241m.[39mpop([38;5;124m"[39m[38;5;124moverwrite_encoded_chunks[39m[38;5;124m"[39m, [38;5;28;01mNone[39;00m)
[2025-01-09T19:33:35.990Z] [0;32m--> 679[0m backend_ds [38;5;241m=[39m [43mbackend[49m[38;5;241;43m.[39;49m[43mopen_dataset[49m[43m([49m
[2025-01-09T19:33:35.990Z] [1;32m    680[0m [43m    [49m[43mfilename_or_obj[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    681[0m [43m    [49m[43mdrop_variables[49m[38;5;241;43m=[39;49m[43mdrop_variables[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    682[0m [43m    [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mdecoders[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    683[0m [43m    [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    684[0m [43m[49m[43m)[49m
[2025-01-09T19:33:35.990Z] [1;32m    685[0m ds [38;5;241m=[39m _dataset_from_backend_dataset(
[2025-01-09T19:33:35.990Z] [1;32m    686[0m     backend_ds,
[2025-01-09T19:33:35.990Z] [1;32m    687[0m     filename_or_obj,
[2025-01-09T19:33:35.990Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.990Z] [1;32m    697[0m     [38;5;241m*[39m[38;5;241m*[39mkwargs,
[2025-01-09T19:33:35.990Z] [1;32m    698[0m )
[2025-01-09T19:33:35.990Z] [1;32m    699[0m [38;5;28;01mreturn[39;00m ds
[2025-01-09T19:33:35.990Z] 
[2025-01-09T19:33:35.990Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:1564[0m, in [0;36mZarrBackendEntrypoint.open_dataset[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, zarr_version, zarr_format, store, engine, use_zarr_fill_value_as_mask, cache_members)[0m
[2025-01-09T19:33:35.990Z] [1;32m   1562[0m filename_or_obj [38;5;241m=[39m _normalize_path(filename_or_obj)
[2025-01-09T19:33:35.990Z] [1;32m   1563[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m store:
[2025-01-09T19:33:35.990Z] [0;32m-> 1564[0m     store [38;5;241m=[39m [43mZarrStore[49m[38;5;241;43m.[39;49m[43mopen_group[49m[43m([49m
[2025-01-09T19:33:35.990Z] [1;32m   1565[0m [43m        [49m[43mfilename_or_obj[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1566[0m [43m        [49m[43mgroup[49m[38;5;241;43m=[39;49m[43mgroup[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1567[0m [43m        [49m[43mmode[49m[38;5;241;43m=[39;49m[43mmode[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1568[0m [43m        [49m[43msynchronizer[49m[38;5;241;43m=[39;49m[43msynchronizer[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1569[0m [43m        [49m[43mconsolidated[49m[38;5;241;43m=[39;49m[43mconsolidated[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1570[0m [43m        [49m[43mconsolidate_on_close[49m[38;5;241;43m=[39;49m[38;5;28;43;01mFalse[39;49;00m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1571[0m [43m        [49m[43mchunk_store[49m[38;5;241;43m=[39;49m[43mchunk_store[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1572[0m [43m        [49m[43mstorage_options[49m[38;5;241;43m=[39;49m[43mstorage_options[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1573[0m [43m        [49m[43mzarr_version[49m[38;5;241;43m=[39;49m[43mzarr_version[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1574[0m [43m        [49m[43muse_zarr_fill_value_as_mask[49m[38;5;241;43m=[39;49m[38;5;28;43;01mNone[39;49;00m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1575[0m [43m        [49m[43mzarr_format[49m[38;5;241;43m=[39;49m[43mzarr_format[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1576[0m [43m        [49m[43mcache_members[49m[38;5;241;43m=[39;49m[43mcache_members[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m   1577[0m [43m    [49m[43m)[49m
[2025-01-09T19:33:35.990Z] [1;32m   1579[0m store_entrypoint [38;5;241m=[39m StoreBackendEntrypoint()
[2025-01-09T19:33:35.990Z] [1;32m   1580[0m [38;5;28;01mwith[39;00m close_on_error(store):
[2025-01-09T19:33:35.990Z] 
[2025-01-09T19:33:35.990Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:703[0m, in [0;36mZarrStore.open_group[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, zarr_version, zarr_format, use_zarr_fill_value_as_mask, write_empty, cache_members)[0m
[2025-01-09T19:33:35.990Z] [1;32m    678[0m [38;5;129m@classmethod[39m
[2025-01-09T19:33:35.990Z] [1;32m    679[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21mopen_group[39m(
[2025-01-09T19:33:35.990Z] [1;32m    680[0m     [38;5;28mcls[39m,
[2025-01-09T19:33:35.990Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.990Z] [1;32m    696[0m     cache_members: [38;5;28mbool[39m [38;5;241m=[39m [38;5;28;01mTrue[39;00m,
[2025-01-09T19:33:35.990Z] [1;32m    697[0m ):
[2025-01-09T19:33:35.990Z] [1;32m    698[0m     (
[2025-01-09T19:33:35.990Z] [1;32m    699[0m         zarr_group,
[2025-01-09T19:33:35.990Z] [1;32m    700[0m         consolidate_on_close,
[2025-01-09T19:33:35.990Z] [1;32m    701[0m         close_store_on_close,
[2025-01-09T19:33:35.990Z] [1;32m    702[0m         use_zarr_fill_value_as_mask,
[2025-01-09T19:33:35.990Z] [0;32m--> 703[0m     ) [38;5;241m=[39m [43m_get_open_params[49m[43m([49m
[2025-01-09T19:33:35.990Z] [1;32m    704[0m [43m        [49m[43mstore[49m[38;5;241;43m=[39;49m[43mstore[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    705[0m [43m        [49m[43mmode[49m[38;5;241;43m=[39;49m[43mmode[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    706[0m [43m        [49m[43msynchronizer[49m[38;5;241;43m=[39;49m[43msynchronizer[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    707[0m [43m        [49m[43mgroup[49m[38;5;241;43m=[39;49m[43mgroup[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    708[0m [43m        [49m[43mconsolidated[49m[38;5;241;43m=[39;49m[43mconsolidated[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    709[0m [43m        [49m[43mconsolidate_on_close[49m[38;5;241;43m=[39;49m[43mconsolidate_on_close[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    710[0m [43m        [49m[43mchunk_store[49m[38;5;241;43m=[39;49m[43mchunk_store[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    711[0m [43m        [49m[43mstorage_options[49m[38;5;241;43m=[39;49m[43mstorage_options[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    712[0m [43m        [49m[43mzarr_version[49m[38;5;241;43m=[39;49m[43mzarr_version[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    713[0m [43m        [49m[43muse_zarr_fill_value_as_mask[49m[38;5;241;43m=[39;49m[43muse_zarr_fill_value_as_mask[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    714[0m [43m        [49m[43mzarr_format[49m[38;5;241;43m=[39;49m[43mzarr_format[49m[43m,[49m
[2025-01-09T19:33:35.990Z] [1;32m    715[0m [43m    [49m[43m)[49m
[2025-01-09T19:33:35.990Z] [1;32m    717[0m     [38;5;28;01mreturn[39;00m [38;5;28mcls[39m(
[2025-01-09T19:33:35.990Z] [1;32m    718[0m         zarr_group,
[2025-01-09T19:33:35.991Z] [1;32m    719[0m         mode,
[2025-01-09T19:33:35.991Z] [0;32m   (...)[0m
[2025-01-09T19:33:35.991Z] [1;32m    727[0m         cache_members,
[2025-01-09T19:33:35.991Z] [1;32m    728[0m     )
[2025-01-09T19:33:35.991Z] 
[2025-01-09T19:33:35.991Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/xarray/backends/zarr.py:1786[0m, in [0;36m_get_open_params[0;34m(store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, zarr_version, use_zarr_fill_value_as_mask, zarr_format)[0m
[2025-01-09T19:33:35.991Z] [1;32m   1781[0m             [38;5;28;01mraise[39;00m [38;5;167;01mFileNotFoundError[39;00m(
[2025-01-09T19:33:35.991Z] [1;32m   1782[0m                 [38;5;124mf[39m[38;5;124m"[39m[38;5;124mNo such file or directory: [39m[38;5;124m'[39m[38;5;132;01m{[39;00mstore[38;5;132;01m}[39;00m[38;5;124m'[39m[38;5;124m"[39m
[2025-01-09T19:33:35.991Z] [1;32m   1783[0m             ) [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;21;01merr[39;00m
[2025-01-09T19:33:35.991Z] [1;32m   1784[0m [38;5;28;01melif[39;00m consolidated:
[2025-01-09T19:33:35.991Z] [1;32m   1785[0m     [38;5;66;03m# TODO: an option to pass the metadata_key keyword[39;00m
[2025-01-09T19:33:35.991Z] [0;32m-> 1786[0m     zarr_group [38;5;241m=[39m [43mzarr[49m[38;5;241;43m.[39;49m[43mopen_consolidated[49m[43m([49m[43mstore[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mopen_kwargs[49m[43m)[49m
[2025-01-09T19:33:35.991Z] [1;32m   1787[0m [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.991Z] [1;32m   1788[0m     [38;5;28;01mif[39;00m _zarr_v3():
[2025-01-09T19:33:35.991Z] [1;32m   1789[0m         [38;5;66;03m# we have determined that we don't want to use consolidated metadata[39;00m
[2025-01-09T19:33:35.991Z] [1;32m   1790[0m         [38;5;66;03m# so we set that to False to avoid trying to read it[39;00m
[2025-01-09T19:33:35.991Z] 
[2025-01-09T19:33:35.991Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/api/synchronous.py:212[0m, in [0;36mopen_consolidated[0;34m(use_consolidated, *args, **kwargs)[0m
[2025-01-09T19:33:35.991Z] [1;32m    207[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21mopen_consolidated[39m([38;5;241m*[39margs: Any, use_consolidated: Literal[[38;5;28;01mTrue[39;00m] [38;5;241m=[39m [38;5;28;01mTrue[39;00m, [38;5;241m*[39m[38;5;241m*[39mkwargs: Any) [38;5;241m-[39m[38;5;241m>[39m Group:
[2025-01-09T19:33:35.991Z] [1;32m    208[0m [38;5;250m    [39m[38;5;124;03m"""[39;00m
[2025-01-09T19:33:35.991Z] [1;32m    209[0m [38;5;124;03m    Alias for :func:`open_group` with ``use_consolidated=True``.[39;00m
[2025-01-09T19:33:35.991Z] [1;32m    210[0m [38;5;124;03m    """[39;00m
[2025-01-09T19:33:35.991Z] [1;32m    211[0m     [38;5;28;01mreturn[39;00m Group(
[2025-01-09T19:33:35.991Z] [0;32m--> 212[0m         [43msync[49m[43m([49m[43masync_api[49m[38;5;241;43m.[39;49m[43mopen_consolidated[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[43muse_consolidated[49m[38;5;241;43m=[39;49m[43muse_consolidated[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m[43m)[49m
[2025-01-09T19:33:35.991Z] [1;32m    213[0m     )
[2025-01-09T19:33:35.991Z] 
[2025-01-09T19:33:35.991Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/core/sync.py:142[0m, in [0;36msync[0;34m(coro, loop, timeout)[0m
[2025-01-09T19:33:35.991Z] [1;32m    139[0m return_result [38;5;241m=[39m [38;5;28mnext[39m([38;5;28miter[39m(finished))[38;5;241m.[39mresult()
[2025-01-09T19:33:35.991Z] [1;32m    141[0m [38;5;28;01mif[39;00m [38;5;28misinstance[39m(return_result, [38;5;167;01mBaseException[39;00m):
[2025-01-09T19:33:35.991Z] [0;32m--> 142[0m     [38;5;28;01mraise[39;00m return_result
[2025-01-09T19:33:35.991Z] [1;32m    143[0m [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.991Z] [1;32m    144[0m     [38;5;28;01mreturn[39;00m return_result
[2025-01-09T19:33:35.991Z] 
[2025-01-09T19:33:35.991Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/core/sync.py:98[0m, in [0;36m_runner[0;34m(coro)[0m
[2025-01-09T19:33:35.991Z] [1;32m     93[0m [38;5;250m[39m[38;5;124;03m"""[39;00m
[2025-01-09T19:33:35.991Z] [1;32m     94[0m [38;5;124;03mAwait a coroutine and return the result of running it. If awaiting the coroutine raises an[39;00m
[2025-01-09T19:33:35.991Z] [1;32m     95[0m [38;5;124;03mexception, the exception will be returned.[39;00m
[2025-01-09T19:33:35.991Z] [1;32m     96[0m [38;5;124;03m"""[39;00m
[2025-01-09T19:33:35.991Z] [1;32m     97[0m [38;5;28;01mtry[39;00m:
[2025-01-09T19:33:35.991Z] [0;32m---> 98[0m     [38;5;28;01mreturn[39;00m [38;5;28;01mawait[39;00m coro
[2025-01-09T19:33:35.991Z] [1;32m     99[0m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m [38;5;28;01mas[39;00m ex:
[2025-01-09T19:33:35.991Z] [1;32m    100[0m     [38;5;28;01mreturn[39;00m ex
[2025-01-09T19:33:35.991Z] 
[2025-01-09T19:33:35.991Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/api/asynchronous.py:346[0m, in [0;36mopen_consolidated[0;34m(use_consolidated, *args, **kwargs)[0m
[2025-01-09T19:33:35.991Z] [1;32m    341[0m [38;5;28;01mif[39;00m use_consolidated [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mTrue[39;00m:
[2025-01-09T19:33:35.991Z] [1;32m    342[0m     [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(
[2025-01-09T19:33:35.991Z] [1;32m    343[0m         [38;5;124m"[39m[38;5;124m'[39m[38;5;124muse_consolidated[39m[38;5;124m'[39m[38;5;124m must be [39m[38;5;124m'[39m[38;5;124mTrue[39m[38;5;124m'[39m[38;5;124m in [39m[38;5;124m'[39m[38;5;124mopen_consolidated[39m[38;5;124m'[39m[38;5;124m. Use [39m[38;5;124m'[39m[38;5;124mopen[39m[38;5;124m'[39m[38;5;124m with [39m[38;5;124m"[39m
[2025-01-09T19:33:35.991Z] [1;32m    344[0m         [38;5;124m"[39m[38;5;124m'[39m[38;5;124muse_consolidated=False[39m[38;5;124m'[39m[38;5;124m to bypass consolidated metadata.[39m[38;5;124m"[39m
[2025-01-09T19:33:35.991Z] [1;32m    345[0m     )
[2025-01-09T19:33:35.991Z] [0;32m--> 346[0m [38;5;28;01mreturn[39;00m [38;5;28;01mawait[39;00m open_group([38;5;241m*[39margs, use_consolidated[38;5;241m=[39muse_consolidated, [38;5;241m*[39m[38;5;241m*[39mkwargs)
[2025-01-09T19:33:35.991Z] 
[2025-01-09T19:33:35.991Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/api/asynchronous.py:800[0m, in [0;36mopen_group[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, zarr_format, meta_array, attributes, use_consolidated)[0m
[2025-01-09T19:33:35.991Z] [1;32m    797[0m [38;5;28;01mif[39;00m chunk_store [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m:
[2025-01-09T19:33:35.991Z] [1;32m    798[0m     warnings[38;5;241m.[39mwarn([38;5;124m"[39m[38;5;124mchunk_store is not yet implemented[39m[38;5;124m"[39m, [38;5;167;01mRuntimeWarning[39;00m, stacklevel[38;5;241m=[39m[38;5;241m2[39m)
[2025-01-09T19:33:35.991Z] [0;32m--> 800[0m store_path [38;5;241m=[39m [38;5;28;01mawait[39;00m make_store_path(store, mode[38;5;241m=[39mmode, storage_options[38;5;241m=[39mstorage_options, path[38;5;241m=[39mpath)
[2025-01-09T19:33:35.991Z] [1;32m    802[0m [38;5;28;01mif[39;00m attributes [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[2025-01-09T19:33:35.991Z] [1;32m    803[0m     attributes [38;5;241m=[39m {}
[2025-01-09T19:33:35.991Z] 
[2025-01-09T19:33:35.991Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/zarr/storage/_common.py:316[0m, in [0;36mmake_store_path[0;34m(store_like, path, mode, storage_options)[0m
[2025-01-09T19:33:35.991Z] [1;32m    314[0m     [38;5;28;01melse[39;00m:
[2025-01-09T19:33:35.992Z] [1;32m    315[0m         msg [38;5;241m=[39m [38;5;124mf[39m[38;5;124m"[39m[38;5;124mUnsupported type for store_like: [39m[38;5;124m'[39m[38;5;132;01m{[39;00m[38;5;28mtype[39m(store_like)[38;5;241m.[39m[38;5;18m__name__[39m[38;5;132;01m}[39;00m[38;5;124m'[39m[38;5;124m"[39m  [38;5;66;03m# type: ignore[unreachable][39;00m
[2025-01-09T19:33:35.992Z] [0;32m--> 316[0m         [38;5;28;01mraise[39;00m [38;5;167;01mTypeError[39;00m(msg)
[2025-01-09T19:33:35.992Z] [1;32m    318[0m     result [38;5;241m=[39m [38;5;28;01mawait[39;00m StorePath[38;5;241m.[39mopen(store, path[38;5;241m=[39mpath_normalized, mode[38;5;241m=[39mmode)
[2025-01-09T19:33:35.992Z] [1;32m    320[0m [38;5;28;01mif[39;00m storage_options [38;5;129;01mand[39;00m [38;5;129;01mnot[39;00m used_storage_options:
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] [0;31mTypeError[0m: Unsupported type for store_like: 'FSMap'
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] _ RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 12 _
[2025-01-09T19:33:35.992Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.992Z] [94mCell 12: Cell execution caused an exception
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] Input:
[2025-01-09T19:33:35.992Z] [0m# Here we need to make sure that our units are all in the correct format.
[2025-01-09T19:33:35.992Z] # You can play around with the tools we've seen thus far to explore the units and make sure everything is consistent.
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Let's start with precipitation:
[2025-01-09T19:33:35.992Z] # The CMIP data is a rate rather than an absolute value, so let's get the absolute values:
[2025-01-09T19:33:35.992Z] historical_pr = xclim.core.units.rate2amount(historical_pr)
[2025-01-09T19:33:35.992Z] future_pr = xclim.core.units.rate2amount(future_pr)
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Now we can actually convert units in absolute terms.
[2025-01-09T19:33:35.992Z] historical_pr = xclim.core.units.convert_units_to(historical_pr, "mm", context="hydro")
[2025-01-09T19:33:35.992Z] future_pr = xclim.core.units.convert_units_to(future_pr, "mm", context="hydro")
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Now let's do temperature:
[2025-01-09T19:33:35.992Z] historical_tasmin = xclim.core.units.convert_units_to(historical_tasmin, "degC")
[2025-01-09T19:33:35.992Z] historical_tasmax = xclim.core.units.convert_units_to(historical_tasmax, "degC")
[2025-01-09T19:33:35.992Z] future_tasmin = xclim.core.units.convert_units_to(future_tasmin, "degC")
[2025-01-09T19:33:35.992Z] future_tasmax = xclim.core.units.convert_units_to(future_tasmax, "degC")
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] [94mTraceback:[0m
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.992Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.992Z] Cell [0;32mIn[1], line 6[0m
[2025-01-09T19:33:35.992Z] [1;32m      1[0m [38;5;66;03m# Here we need to make sure that our units are all in the correct format.[39;00m
[2025-01-09T19:33:35.992Z] [1;32m      2[0m [38;5;66;03m# You can play around with the tools we've seen thus far to explore the units and make sure everything is consistent.[39;00m
[2025-01-09T19:33:35.992Z] [1;32m      3[0m 
[2025-01-09T19:33:35.992Z] [1;32m      4[0m [38;5;66;03m# Let's start with precipitation:[39;00m
[2025-01-09T19:33:35.992Z] [1;32m      5[0m [38;5;66;03m# The CMIP data is a rate rather than an absolute value, so let's get the absolute values:[39;00m
[2025-01-09T19:33:35.992Z] [0;32m----> 6[0m historical_pr [38;5;241m=[39m xclim[38;5;241m.[39mcore[38;5;241m.[39munits[38;5;241m.[39mrate2amount([43mhistorical_pr[49m)
[2025-01-09T19:33:35.992Z] [1;32m      7[0m future_pr [38;5;241m=[39m xclim[38;5;241m.[39mcore[38;5;241m.[39munits[38;5;241m.[39mrate2amount(future_pr)
[2025-01-09T19:33:35.992Z] [1;32m      9[0m [38;5;66;03m# Now we can actually convert units in absolute terms.[39;00m
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] [0;31mNameError[0m: name 'historical_pr' is not defined
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] _ RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 13 _
[2025-01-09T19:33:35.992Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.992Z] [94mCell 13: Cell execution caused an exception
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] Input:
[2025-01-09T19:33:35.992Z] [0m# Use xclim utilities (SDBA) to give information on the type of window used for the bias correction.
[2025-01-09T19:33:35.992Z] group_month_window = sdba.utils.Grouper("time.dayofyear", window=15)
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # This is an adjusting function.
[2025-01-09T19:33:35.992Z] # It builds the tool that will perform the corrections.
[2025-01-09T19:33:35.992Z] Adjustment = sdba.DetrendedQuantileMapping.train(
[2025-01-09T19:33:35.992Z]     ref=ERA5_weather.pr,
[2025-01-09T19:33:35.992Z]     hist=historical_pr,
[2025-01-09T19:33:35.992Z]     nquantiles=50,
[2025-01-09T19:33:35.992Z]     kind="+",
[2025-01-09T19:33:35.992Z]     group=group_month_window,
[2025-01-09T19:33:35.992Z] )
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Apply the correction factors on the reference period.
[2025-01-09T19:33:35.992Z] corrected_ref_precip = Adjustment.adjust(historical_pr, interp="linear")
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Apply the correction factors on the future period.
[2025-01-09T19:33:35.992Z] corrected_fut_precip = Adjustment.adjust(future_pr, interp="linear")
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Ensure that the precipitation is non-negative, which can happen with some climate models.
[2025-01-09T19:33:35.992Z] corrected_ref_precip = corrected_ref_precip.where(corrected_ref_precip > 0, 0)
[2025-01-09T19:33:35.992Z] corrected_fut_precip = corrected_fut_precip.where(corrected_fut_precip > 0, 0)
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Train the model to find the correction factors for the maximum temperature (tasmax) data.
[2025-01-09T19:33:35.992Z] Adjustment = sdba.DetrendedQuantileMapping.train(
[2025-01-09T19:33:35.992Z]     ref=ERA5_weather.tmax,
[2025-01-09T19:33:35.992Z]     hist=historical_tasmax,
[2025-01-09T19:33:35.992Z]     nquantiles=50,
[2025-01-09T19:33:35.992Z]     kind="+",
[2025-01-09T19:33:35.992Z]     group=group_month_window,
[2025-01-09T19:33:35.992Z] )
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Apply the correction factors on the reference period.
[2025-01-09T19:33:35.992Z] corrected_ref_tasmax = Adjustment.adjust(historical_tasmax, interp="linear")
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Apply the correction factors on the future period.
[2025-01-09T19:33:35.992Z] corrected_fut_tasmax = Adjustment.adjust(future_tasmax, interp="linear")
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Train the model to find the correction factors for the minimum temperature (tasmin) data.
[2025-01-09T19:33:35.992Z] Adjustment = sdba.DetrendedQuantileMapping.train(
[2025-01-09T19:33:35.992Z]     ref=ERA5_weather.tmin,
[2025-01-09T19:33:35.992Z]     hist=historical_tasmin,
[2025-01-09T19:33:35.992Z]     nquantiles=50,
[2025-01-09T19:33:35.992Z]     kind="+",
[2025-01-09T19:33:35.992Z]     group=group_month_window,
[2025-01-09T19:33:35.992Z] )
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Apply the correction factors on the reference period.
[2025-01-09T19:33:35.992Z] corrected_ref_tasmin = Adjustment.adjust(historical_tasmin, interp="linear")
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] # Apply the correction factors on the future period.
[2025-01-09T19:33:35.992Z] corrected_fut_tasmin = Adjustment.adjust(future_tasmin, interp="linear")
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] [94mTraceback:[0m
[2025-01-09T19:33:35.992Z] 
[2025-01-09T19:33:35.992Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.992Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.992Z] Cell [0;32mIn[1], line 8[0m
[2025-01-09T19:33:35.992Z] [1;32m      2[0m group_month_window [38;5;241m=[39m sdba[38;5;241m.[39mutils[38;5;241m.[39mGrouper([38;5;124m"[39m[38;5;124mtime.dayofyear[39m[38;5;124m"[39m, window[38;5;241m=[39m[38;5;241m15[39m)
[2025-01-09T19:33:35.992Z] [1;32m      4[0m [38;5;66;03m# This is an adjusting function.[39;00m
[2025-01-09T19:33:35.992Z] [1;32m      5[0m [38;5;66;03m# It builds the tool that will perform the corrections.[39;00m
[2025-01-09T19:33:35.992Z] [1;32m      6[0m Adjustment [38;5;241m=[39m sdba[38;5;241m.[39mDetrendedQuantileMapping[38;5;241m.[39mtrain(
[2025-01-09T19:33:35.992Z] [1;32m      7[0m     ref[38;5;241m=[39mERA5_weather[38;5;241m.[39mpr,
[2025-01-09T19:33:35.992Z] [0;32m----> 8[0m     hist[38;5;241m=[39m[43mhistorical_pr[49m,
[2025-01-09T19:33:35.992Z] [1;32m      9[0m     nquantiles[38;5;241m=[39m[38;5;241m50[39m,
[2025-01-09T19:33:35.992Z] [1;32m     10[0m     kind[38;5;241m=[39m[38;5;124m"[39m[38;5;124m+[39m[38;5;124m"[39m,
[2025-01-09T19:33:35.993Z] [1;32m     11[0m     group[38;5;241m=[39mgroup_month_window,
[2025-01-09T19:33:35.993Z] [1;32m     12[0m )
[2025-01-09T19:33:35.993Z] [1;32m     14[0m [38;5;66;03m# Apply the correction factors on the reference period.[39;00m
[2025-01-09T19:33:35.993Z] [1;32m     15[0m corrected_ref_precip [38;5;241m=[39m Adjustment[38;5;241m.[39madjust(historical_pr, interp[38;5;241m=[39m[38;5;124m"[39m[38;5;124mlinear[39m[38;5;124m"[39m)
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] [0;31mNameError[0m: name 'historical_pr' is not defined
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] _ RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 14 _
[2025-01-09T19:33:35.993Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.993Z] [94mCell 14: Cell execution caused an exception
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] Input:
[2025-01-09T19:33:35.993Z] [0m# Convert the reference corrected data into netCDF file.
[2025-01-09T19:33:35.993Z] # We will then apply a special code to remove a dimension in the dataset to make it applicable to the RAVEN models.
[2025-01-09T19:33:35.993Z] ref_dataset = xr.merge(
[2025-01-09T19:33:35.993Z]     [
[2025-01-09T19:33:35.993Z]         corrected_ref_precip.to_dataset(name="pr"),
[2025-01-09T19:33:35.993Z]         corrected_ref_tasmax.to_dataset(name="tasmax"),
[2025-01-09T19:33:35.993Z]         corrected_ref_tasmin.to_dataset(name="tasmin"),
[2025-01-09T19:33:35.993Z]     ]
[2025-01-09T19:33:35.993Z] )
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] # Write to temporary folder.
[2025-01-09T19:33:35.993Z] fn_tmp_ref = tmp / "reference_dataset_tmp.nc"
[2025-01-09T19:33:35.993Z] ref_dataset.to_netcdf(fn_tmp_ref)
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] # Convert the future corrected data into netCDF file.
[2025-01-09T19:33:35.993Z] fut_dataset = xr.merge(
[2025-01-09T19:33:35.993Z]     [
[2025-01-09T19:33:35.993Z]         corrected_fut_precip.to_dataset(name="pr"),
[2025-01-09T19:33:35.993Z]         corrected_fut_tasmax.to_dataset(name="tasmax"),
[2025-01-09T19:33:35.993Z]         corrected_fut_tasmin.to_dataset(name="tasmin"),
[2025-01-09T19:33:35.993Z]     ]
[2025-01-09T19:33:35.993Z] )
[2025-01-09T19:33:35.993Z] # Write to temporary folder.
[2025-01-09T19:33:35.993Z] with ProgressBar():
[2025-01-09T19:33:35.993Z]     fn_tmp_fut = tmp / "future_dataset_tmp.nc"
[2025-01-09T19:33:35.993Z]     fut_dataset.to_netcdf(fn_tmp_fut)
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z]     # Write the data to disk to a temporary location for future use.
[2025-01-09T19:33:35.993Z]     ref_dataset = xr.open_dataset(fn_tmp_ref)
[2025-01-09T19:33:35.993Z]     ref_dataset.isel(geom=0).squeeze().to_netcdf(tmp / "reference_dataset.nc")
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z]     fut_dataset = xr.open_dataset(fn_tmp_fut)
[2025-01-09T19:33:35.993Z]     fut_dataset.isel(geom=0).squeeze().to_netcdf(tmp / "future_dataset.nc")
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] [94mTraceback:[0m
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.993Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.993Z] Cell [0;32mIn[1], line 5[0m
[2025-01-09T19:33:35.993Z] [1;32m      1[0m [38;5;66;03m# Convert the reference corrected data into netCDF file.[39;00m
[2025-01-09T19:33:35.993Z] [1;32m      2[0m [38;5;66;03m# We will then apply a special code to remove a dimension in the dataset to make it applicable to the RAVEN models.[39;00m
[2025-01-09T19:33:35.993Z] [1;32m      3[0m ref_dataset [38;5;241m=[39m xr[38;5;241m.[39mmerge(
[2025-01-09T19:33:35.993Z] [1;32m      4[0m     [
[2025-01-09T19:33:35.993Z] [0;32m----> 5[0m         [43mcorrected_ref_precip[49m[38;5;241m.[39mto_dataset(name[38;5;241m=[39m[38;5;124m"[39m[38;5;124mpr[39m[38;5;124m"[39m),
[2025-01-09T19:33:35.993Z] [1;32m      6[0m         corrected_ref_tasmax[38;5;241m.[39mto_dataset(name[38;5;241m=[39m[38;5;124m"[39m[38;5;124mtasmax[39m[38;5;124m"[39m),
[2025-01-09T19:33:35.993Z] [1;32m      7[0m         corrected_ref_tasmin[38;5;241m.[39mto_dataset(name[38;5;241m=[39m[38;5;124m"[39m[38;5;124mtasmin[39m[38;5;124m"[39m),
[2025-01-09T19:33:35.993Z] [1;32m      8[0m     ]
[2025-01-09T19:33:35.993Z] [1;32m      9[0m )
[2025-01-09T19:33:35.993Z] [1;32m     11[0m [38;5;66;03m# Write to temporary folder.[39;00m
[2025-01-09T19:33:35.993Z] [1;32m     12[0m fn_tmp_ref [38;5;241m=[39m tmp [38;5;241m/[39m [38;5;124m"[39m[38;5;124mreference_dataset_tmp.nc[39m[38;5;124m"[39m
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] [0;31mNameError[0m: name 'corrected_ref_precip' is not defined
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] _ RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 18 _
[2025-01-09T19:33:35.993Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.993Z] [94mCell 18: Cell execution caused an exception
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] Input:
[2025-01-09T19:33:35.993Z] [0m# Set up a gauge for Raven to read-in the reference climate data, just like for ERA5.
[2025-01-09T19:33:35.993Z] gauge_ref = [
[2025-01-09T19:33:35.993Z]     rc.Gauge.from_nc(
[2025-01-09T19:33:35.993Z]         tmp
[2025-01-09T19:33:35.993Z]         / "reference_dataset.nc",  # Path to the CMIP6 model reference data netcdf file.
[2025-01-09T19:33:35.993Z]         data_type=data_type,
[2025-01-09T19:33:35.993Z]         alt_names=alt_names,
[2025-01-09T19:33:35.993Z]         data_kwds=data_kwds,
[2025-01-09T19:33:35.993Z]     )
[2025-01-09T19:33:35.993Z] ]
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] # Copy the configuration of the previous model that we will modify for our simulation on the reference period.
[2025-01-09T19:33:35.993Z] model_config_reference = model_validation.duplicate(
[2025-01-09T19:33:35.993Z]     Gauge=gauge_ref,
[2025-01-09T19:33:35.993Z]     StartDate=reference_start_day
[2025-01-09T19:33:35.993Z]     + dt.timedelta(days=1),  # Add a day here to account for the UTC lag in ERA5.
[2025-01-09T19:33:35.993Z]     EndDate=reference_end_day,
[2025-01-09T19:33:35.993Z] )
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] # Run the model from the configuration and get the outputs.
[2025-01-09T19:33:35.993Z] ref_output = Emulator(config=model_config_reference).run()
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] # Plot the model output.
[2025-01-09T19:33:35.993Z] # Note that both simulations should have similar hydrological regime but day-to-day variability is not expected to match.
[2025-01-09T19:33:35.993Z] ref_output.hydrograph.q_sim.plot(color="blue", label="Reference period simulation")
[2025-01-09T19:33:35.993Z] ref_output.hydrograph.q_obs.plot(color="black", label="Observation")
[2025-01-09T19:33:35.993Z] plt.legend()
[2025-01-09T19:33:35.993Z] plt.title("Reference period")
[2025-01-09T19:33:35.993Z] plt.ylabel("Streamflow (m��/s)")
[2025-01-09T19:33:35.993Z] plt.grid()
[2025-01-09T19:33:35.993Z] plt.show()
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] [94mTraceback:[0m
[2025-01-09T19:33:35.993Z] 
[2025-01-09T19:33:35.993Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.993Z] [0;31mValueError[0m                                Traceback (most recent call last)
[2025-01-09T19:33:35.993Z] Cell [0;32mIn[1], line 3[0m
[2025-01-09T19:33:35.993Z] [1;32m      1[0m [38;5;66;03m# Set up a gauge for Raven to read-in the reference climate data, just like for ERA5.[39;00m
[2025-01-09T19:33:35.993Z] [1;32m      2[0m gauge_ref [38;5;241m=[39m [
[2025-01-09T19:33:35.993Z] [0;32m----> 3[0m     [43mrc[49m[38;5;241;43m.[39;49m[43mGauge[49m[38;5;241;43m.[39;49m[43mfrom_nc[49m[43m([49m
[2025-01-09T19:33:35.993Z] [1;32m      4[0m [43m        [49m[43mtmp[49m
[2025-01-09T19:33:35.994Z] [1;32m      5[0m [43m        [49m[38;5;241;43m/[39;49m[43m [49m[38;5;124;43m"[39;49m[38;5;124;43mreference_dataset.nc[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m  [49m[38;5;66;43;03m# Path to the CMIP6 model reference data netcdf file.[39;49;00m
[2025-01-09T19:33:35.994Z] [1;32m      6[0m [43m        [49m[43mdata_type[49m[38;5;241;43m=[39;49m[43mdata_type[49m[43m,[49m
[2025-01-09T19:33:35.994Z] [1;32m      7[0m [43m        [49m[43malt_names[49m[38;5;241;43m=[39;49m[43malt_names[49m[43m,[49m
[2025-01-09T19:33:35.994Z] [1;32m      8[0m [43m        [49m[43mdata_kwds[49m[38;5;241;43m=[39;49m[43mdata_kwds[49m[43m,[49m
[2025-01-09T19:33:35.994Z] [1;32m      9[0m [43m    [49m[43m)[49m
[2025-01-09T19:33:35.994Z] [1;32m     10[0m ]
[2025-01-09T19:33:35.994Z] [1;32m     12[0m [38;5;66;03m# Copy the configuration of the previous model that we will modify for our simulation on the reference period.[39;00m
[2025-01-09T19:33:35.994Z] [1;32m     13[0m model_config_reference [38;5;241m=[39m model_validation[38;5;241m.[39mduplicate(
[2025-01-09T19:33:35.994Z] [1;32m     14[0m     Gauge[38;5;241m=[39mgauge_ref,
[2025-01-09T19:33:35.994Z] [1;32m     15[0m     StartDate[38;5;241m=[39mreference_start_day
[2025-01-09T19:33:35.994Z] [1;32m     16[0m     [38;5;241m+[39m dt[38;5;241m.[39mtimedelta(days[38;5;241m=[39m[38;5;241m1[39m),  [38;5;66;03m# Add a day here to account for the UTC lag in ERA5.[39;00m
[2025-01-09T19:33:35.994Z] [1;32m     17[0m     EndDate[38;5;241m=[39mreference_end_day,
[2025-01-09T19:33:35.994Z] [1;32m     18[0m )
[2025-01-09T19:33:35.994Z] 
[2025-01-09T19:33:35.994Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/ravenpy/config/commands.py:805[0m, in [0;36mGauge.from_nc[0;34m(cls, fn, data_type, station_idx, alt_names, mon_ave, data_kwds, engine, **kwds)[0m
[2025-01-09T19:33:35.994Z] [1;32m    802[0m     forcings[38;5;241m.[39mdifference_update(data)
[2025-01-09T19:33:35.994Z] [1;32m    804[0m [38;5;28;01mif[39;00m [38;5;28mlen[39m(data) [38;5;241m==[39m [38;5;241m0[39m:
[2025-01-09T19:33:35.994Z] [0;32m--> 805[0m     [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m(
[2025-01-09T19:33:35.994Z] [1;32m    806[0m         [38;5;124m"[39m[38;5;124mNo data found in netCDF files. Check that variable names follow CF conventions, [39m[38;5;124m"[39m
[2025-01-09T19:33:35.994Z] [1;32m    807[0m         [38;5;124m"[39m[38;5;124mor if not, provide `alt_names` mapping Raven data types to variable names.[39m[38;5;124m"[39m
[2025-01-09T19:33:35.994Z] [1;32m    808[0m     )
[2025-01-09T19:33:35.994Z] [1;32m    810[0m [38;5;66;03m# Default Gauge name[39;00m
[2025-01-09T19:33:35.994Z] [1;32m    811[0m attrs[[38;5;124m"[39m[38;5;124mname[39m[38;5;124m"[39m] [38;5;241m=[39m attrs[38;5;241m.[39mget([38;5;124m"[39m[38;5;124mname[39m[38;5;124m"[39m, [38;5;124mf[39m[38;5;124m"[39m[38;5;124mGauge_[39m[38;5;132;01m{[39;00midx[38;5;132;01m}[39;00m[38;5;124m"[39m)
[2025-01-09T19:33:35.994Z] 
[2025-01-09T19:33:35.994Z] [0;31mValueError[0m: No data found in netCDF files. Check that variable names follow CF conventions, or if not, provide `alt_names` mapping Raven data types to variable names.
[2025-01-09T19:33:35.994Z] 
[2025-01-09T19:33:35.994Z] _ RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 19 _
[2025-01-09T19:33:35.994Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.994Z] [94mCell 19: Cell execution caused an exception
[2025-01-09T19:33:35.994Z] 
[2025-01-09T19:33:35.994Z] Input:
[2025-01-09T19:33:35.994Z] [0m# Set up a gauge for Raven to read-in the future climate data, just like for the reference data.
[2025-01-09T19:33:35.994Z] gauge_fut = [
[2025-01-09T19:33:35.994Z]     rc.Gauge.from_nc(
[2025-01-09T19:33:35.994Z]         tmp / "future_dataset.nc",  # Path to the CMIP6 model reference data netcdf file
[2025-01-09T19:33:35.994Z]         data_type=data_type,
[2025-01-09T19:33:35.994Z]         alt_names=alt_names,
[2025-01-09T19:33:35.994Z]         data_kwds=data_kwds,
[2025-01-09T19:33:35.994Z]     )
[2025-01-09T19:33:35.994Z] ]
[2025-01-09T19:33:35.994Z] 
[2025-01-09T19:33:35.994Z] # Copy the configuration of the previous model that we will modify for our simulation on the reference period.
[2025-01-09T19:33:35.994Z] model_config_future = model_validation.duplicate(
[2025-01-09T19:33:35.994Z]     Gauge=gauge_fut,
[2025-01-09T19:33:35.994Z]     StartDate=future_start_day + dt.timedelta(days=1),
[2025-01-09T19:33:35.994Z]     EndDate=future_end_day,
[2025-01-09T19:33:35.994Z]     ObservationData=None,  # There are no observations for the future period.
[2025-01-09T19:33:35.994Z] )
[2025-01-09T19:33:35.994Z] 
[2025-01-09T19:33:35.994Z] # Run the model and get the outputs and hydrographs.
[2025-01-09T19:33:35.994Z] fut_output = Emulator(config=model_config_future).run()
[2025-01-09T19:33:35.994Z] 
[2025-01-09T19:33:35.994Z] # Plot the model output.
[2025-01-09T19:33:35.994Z] fut_output.hydrograph.q_sim.plot(color="blue", label="Future simulation")
[2025-01-09T19:33:35.994Z] plt.legend()
[2025-01-09T19:33:35.994Z] plt.title("Future period")
[2025-01-09T19:33:35.994Z] plt.ylabel("Streamflow (m��/s)")
[2025-01-09T19:33:35.994Z] plt.grid()
[2025-01-09T19:33:35.994Z] plt.show()
[2025-01-09T19:33:35.994Z] 
[2025-01-09T19:33:35.994Z] [94mTraceback:[0m
[2025-01-09T19:33:35.994Z] 
[2025-01-09T19:33:35.994Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.994Z] [0;31mValueError[0m                                Traceback (most recent call last)
[2025-01-09T19:33:35.994Z] Cell [0;32mIn[1], line 3[0m
[2025-01-09T19:33:35.994Z] [1;32m      1[0m [38;5;66;03m# Set up a gauge for Raven to read-in the future climate data, just like for the reference data.[39;00m
[2025-01-09T19:33:35.994Z] [1;32m      2[0m gauge_fut [38;5;241m=[39m [
[2025-01-09T19:33:35.994Z] [0;32m----> 3[0m     [43mrc[49m[38;5;241;43m.[39;49m[43mGauge[49m[38;5;241;43m.[39;49m[43mfrom_nc[49m[43m([49m
[2025-01-09T19:33:35.994Z] [1;32m      4[0m [43m        [49m[43mtmp[49m[43m [49m[38;5;241;43m/[39;49m[43m [49m[38;5;124;43m"[39;49m[38;5;124;43mfuture_dataset.nc[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m  [49m[38;5;66;43;03m# Path to the CMIP6 model reference data netcdf file[39;49;00m
[2025-01-09T19:33:35.994Z] [1;32m      5[0m [43m        [49m[43mdata_type[49m[38;5;241;43m=[39;49m[43mdata_type[49m[43m,[49m
[2025-01-09T19:33:35.994Z] [1;32m      6[0m [43m        [49m[43malt_names[49m[38;5;241;43m=[39;49m[43malt_names[49m[43m,[49m
[2025-01-09T19:33:35.994Z] [1;32m      7[0m [43m        [49m[43mdata_kwds[49m[38;5;241;43m=[39;49m[43mdata_kwds[49m[43m,[49m
[2025-01-09T19:33:35.994Z] [1;32m      8[0m [43m    [49m[43m)[49m
[2025-01-09T19:33:35.994Z] [1;32m      9[0m ]
[2025-01-09T19:33:35.994Z] [1;32m     11[0m [38;5;66;03m# Copy the configuration of the previous model that we will modify for our simulation on the reference period.[39;00m
[2025-01-09T19:33:35.994Z] [1;32m     12[0m model_config_future [38;5;241m=[39m model_validation[38;5;241m.[39mduplicate(
[2025-01-09T19:33:35.994Z] [1;32m     13[0m     Gauge[38;5;241m=[39mgauge_fut,
[2025-01-09T19:33:35.994Z] [1;32m     14[0m     StartDate[38;5;241m=[39mfuture_start_day [38;5;241m+[39m dt[38;5;241m.[39mtimedelta(days[38;5;241m=[39m[38;5;241m1[39m),
[2025-01-09T19:33:35.994Z] [1;32m     15[0m     EndDate[38;5;241m=[39mfuture_end_day,
[2025-01-09T19:33:35.994Z] [1;32m     16[0m     ObservationData[38;5;241m=[39m[38;5;28;01mNone[39;00m,  [38;5;66;03m# There are no observations for the future period.[39;00m
[2025-01-09T19:33:35.994Z] [1;32m     17[0m )
[2025-01-09T19:33:35.994Z] 
[2025-01-09T19:33:35.994Z] File [0;32m/opt/conda/envs/birdy/lib/python3.11/site-packages/ravenpy/config/commands.py:805[0m, in [0;36mGauge.from_nc[0;34m(cls, fn, data_type, station_idx, alt_names, mon_ave, data_kwds, engine, **kwds)[0m
[2025-01-09T19:33:35.994Z] [1;32m    802[0m     forcings[38;5;241m.[39mdifference_update(data)
[2025-01-09T19:33:35.994Z] [1;32m    804[0m [38;5;28;01mif[39;00m [38;5;28mlen[39m(data) [38;5;241m==[39m [38;5;241m0[39m:
[2025-01-09T19:33:35.994Z] [0;32m--> 805[0m     [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m(
[2025-01-09T19:33:35.994Z] [1;32m    806[0m         [38;5;124m"[39m[38;5;124mNo data found in netCDF files. Check that variable names follow CF conventions, [39m[38;5;124m"[39m
[2025-01-09T19:33:35.995Z] [1;32m    807[0m         [38;5;124m"[39m[38;5;124mor if not, provide `alt_names` mapping Raven data types to variable names.[39m[38;5;124m"[39m
[2025-01-09T19:33:35.995Z] [1;32m    808[0m     )
[2025-01-09T19:33:35.995Z] [1;32m    810[0m [38;5;66;03m# Default Gauge name[39;00m
[2025-01-09T19:33:35.995Z] [1;32m    811[0m attrs[[38;5;124m"[39m[38;5;124mname[39m[38;5;124m"[39m] [38;5;241m=[39m attrs[38;5;241m.[39mget([38;5;124m"[39m[38;5;124mname[39m[38;5;124m"[39m, [38;5;124mf[39m[38;5;124m"[39m[38;5;124mGauge_[39m[38;5;132;01m{[39;00midx[38;5;132;01m}[39;00m[38;5;124m"[39m)
[2025-01-09T19:33:35.995Z] 
[2025-01-09T19:33:35.995Z] [0;31mValueError[0m: No data found in netCDF files. Check that variable names follow CF conventions, or if not, provide `alt_names` mapping Raven data types to variable names.
[2025-01-09T19:33:35.995Z] 
[2025-01-09T19:33:35.995Z] _ RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 20 _
[2025-01-09T19:33:35.995Z] [91mNotebook cell execution failed[0m
[2025-01-09T19:33:35.995Z] [94mCell 20: Cell execution caused an exception
[2025-01-09T19:33:35.995Z] 
[2025-01-09T19:33:35.995Z] Input:
[2025-01-09T19:33:35.995Z] [0m# Extract the mean annual hydrograph for each simulation.
[2025-01-09T19:33:35.995Z] observed_flows = ref_output.hydrograph.q_obs.groupby("time.dayofyear").mean()
[2025-01-09T19:33:35.995Z] simulated_flows = sim_output.hydrograph.q_obs.groupby("time.dayofyear").mean()
[2025-01-09T19:33:35.995Z] reference_flows = ref_output.hydrograph.q_sim.groupby("time.dayofyear").mean()
[2025-01-09T19:33:35.995Z] future_flows = fut_output.hydrograph.q_sim.groupby("time.dayofyear").mean()
[2025-01-09T19:33:35.995Z] 
[2025-01-09T19:33:35.995Z] # Plot the model output.
[2025-01-09T19:33:35.995Z] observed_flows.plot(color="black", label="Observation", x="dayofyear")
[2025-01-09T19:33:35.995Z] simulated_flows.plot(color="green", label="Simulation", x="dayofyear")
[2025-01-09T19:33:35.995Z] reference_flows.plot(color="blue", label="Reference", x="dayofyear")
[2025-01-09T19:33:35.995Z] future_flows.plot(color="red", label="Future", x="dayofyear")
[2025-01-09T19:33:35.995Z] plt.legend()
[2025-01-09T19:33:35.995Z] plt.ylabel("Streamflow (m��/s)")
[2025-01-09T19:33:35.995Z] plt.xlabel("Day of year")
[2025-01-09T19:33:35.995Z] plt.xlim([0, 365])
[2025-01-09T19:33:35.995Z] plt.title("Comparison of mean annual hydrographs")
[2025-01-09T19:33:35.995Z] plt.grid()
[2025-01-09T19:33:35.995Z] plt.show()
[2025-01-09T19:33:35.995Z] 
[2025-01-09T19:33:35.995Z] [94mTraceback:[0m
[2025-01-09T19:33:35.995Z] 
[2025-01-09T19:33:35.995Z] [0;31m---------------------------------------------------------------------------[0m
[2025-01-09T19:33:35.995Z] [0;31mNameError[0m                                 Traceback (most recent call last)
[2025-01-09T19:33:35.995Z] Cell [0;32mIn[1], line 2[0m
[2025-01-09T19:33:35.995Z] [1;32m      1[0m [38;5;66;03m# Extract the mean annual hydrograph for each simulation.[39;00m
[2025-01-09T19:33:35.995Z] [0;32m----> 2[0m observed_flows [38;5;241m=[39m [43mref_output[49m[38;5;241m.[39mhydrograph[38;5;241m.[39mq_obs[38;5;241m.[39mgroupby([38;5;124m"[39m[38;5;124mtime.dayofyear[39m[38;5;124m"[39m)[38;5;241m.[39mmean()
[2025-01-09T19:33:35.995Z] [1;32m      3[0m simulated_flows [38;5;241m=[39m sim_output[38;5;241m.[39mhydrograph[38;5;241m.[39mq_obs[38;5;241m.[39mgroupby([38;5;124m"[39m[38;5;124mtime.dayofyear[39m[38;5;124m"[39m)[38;5;241m.[39mmean()
[2025-01-09T19:33:35.995Z] [1;32m      4[0m reference_flows [38;5;241m=[39m ref_output[38;5;241m.[39mhydrograph[38;5;241m.[39mq_sim[38;5;241m.[39mgroupby([38;5;124m"[39m[38;5;124mtime.dayofyear[39m[38;5;124m"[39m)[38;5;241m.[39mmean()
[2025-01-09T19:33:35.995Z] 
[2025-01-09T19:33:35.995Z] [0;31mNameError[0m: name 'ref_output' is not defined
[2025-01-09T19:33:35.995Z] 
[2025-01-09T19:33:35.995Z] =========================== short test summary info ============================
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 3
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 4
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 5
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 6
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 7
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 8
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 9
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb::Cell 10
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 7
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 9
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 12
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 13
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 14
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 15
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb::Cell 16
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/HydroShare_integration.ipynb::Cell 0
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/HydroShare_integration.ipynb::Cell 1
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/HydroShare_integration.ipynb::Cell 2
[2025-01-09T19:33:35.995Z] FAILED RavenPy-master/docs/notebooks/HydroShare_integration.ipynb::Cell 3
[2025-01-09T19:33:35.996Z] FAILED RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 11
[2025-01-09T19:33:35.996Z] FAILED RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 12
[2025-01-09T19:33:35.996Z] FAILED RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 13
[2025-01-09T19:33:35.996Z] FAILED RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 14
[2025-01-09T19:33:35.996Z] FAILED RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 18
[2025-01-09T19:33:35.996Z] FAILED RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 19
[2025-01-09T19:33:35.996Z] FAILED RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb::Cell 20
[2025-01-09T19:33:35.996Z] ================== 26 failed, 216 passed in 652.30s (0:10:52) ==================
[2025-01-09T19:33:36.250Z] + EXIT_CODE=1
[2025-01-09T19:33:36.250Z] + echo true
[2025-01-09T19:33:36.250Z] + tr [:upper:] [:lower:]
[2025-01-09T19:33:36.250Z] + SAVE_RESULTING_NOTEBOOK=true
[2025-01-09T19:33:36.250Z] + [ xtrue = xtrue ]
[2025-01-09T19:33:36.250Z] + mkdir -p buildout
[2025-01-09T19:33:36.250Z] + basename raven-main/docs/source/notebooks/Region_selection.ipynb
[2025-01-09T19:33:36.250Z] + filename=Region_selection.ipynb
[2025-01-09T19:33:36.250Z] + echo Region_selection.ipynb
[2025-01-09T19:33:36.251Z] + sed s/.ipynb$//
[2025-01-09T19:33:36.251Z] + filename=Region_selection
[2025-01-09T19:33:36.251Z] + [ -e buildout/Region_selection.output.ipynb ]
[2025-01-09T19:33:36.251Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Region_selection.output.ipynb raven-main/docs/source/notebooks/Region_selection.ipynb
[2025-01-09T19:33:38.766Z] [NbConvertApp] Converting notebook raven-main/docs/source/notebooks/Region_selection.ipynb to notebook
[2025-01-09T19:33:53.596Z] [NbConvertApp] Writing 107224 bytes to buildout/Region_selection.output.ipynb
[2025-01-09T19:33:53.596Z] + basename raven-main/docs/source/notebooks/Subset_climate_data_over_watershed.ipynb
[2025-01-09T19:33:53.596Z] + filename=Subset_climate_data_over_watershed.ipynb
[2025-01-09T19:33:53.596Z] + echo Subset_climate_data_over_watershed.ipynb
[2025-01-09T19:33:53.596Z] + sed s/.ipynb$//
[2025-01-09T19:33:53.596Z] + filename=Subset_climate_data_over_watershed
[2025-01-09T19:33:53.596Z] + [ -e buildout/Subset_climate_data_over_watershed.output.ipynb ]
[2025-01-09T19:33:53.596Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Subset_climate_data_over_watershed.output.ipynb raven-main/docs/source/notebooks/Subset_climate_data_over_watershed.ipynb
[2025-01-09T19:33:53.596Z] [NbConvertApp] Converting notebook raven-main/docs/source/notebooks/Subset_climate_data_over_watershed.ipynb to notebook
[2025-01-09T19:34:11.703Z] [NbConvertApp] Writing 95104 bytes to buildout/Subset_climate_data_over_watershed.output.ipynb
[2025-01-09T19:34:11.703Z] + basename RavenPy-master/docs/notebooks/00_Introduction_to_JupyterLab.ipynb
[2025-01-09T19:34:11.703Z] + filename=00_Introduction_to_JupyterLab.ipynb
[2025-01-09T19:34:11.703Z] + echo 00_Introduction_to_JupyterLab.ipynb
[2025-01-09T19:34:11.703Z] + sed s/.ipynb$//
[2025-01-09T19:34:11.703Z] + filename=00_Introduction_to_JupyterLab
[2025-01-09T19:34:11.703Z] + [ -e buildout/00_Introduction_to_JupyterLab.output.ipynb ]
[2025-01-09T19:34:11.703Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 00_Introduction_to_JupyterLab.output.ipynb RavenPy-master/docs/notebooks/00_Introduction_to_JupyterLab.ipynb
[2025-01-09T19:34:11.703Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/00_Introduction_to_JupyterLab.ipynb to notebook
[2025-01-09T19:34:13.590Z] [NbConvertApp] Writing 13180 bytes to buildout/00_Introduction_to_JupyterLab.output.ipynb
[2025-01-09T19:34:13.849Z] + basename RavenPy-master/docs/notebooks/01_Getting_watershed_boundaries.ipynb
[2025-01-09T19:34:13.849Z] + filename=01_Getting_watershed_boundaries.ipynb
[2025-01-09T19:34:13.849Z] + echo 01_Getting_watershed_boundaries.ipynb
[2025-01-09T19:34:13.849Z] + sed s/.ipynb$//
[2025-01-09T19:34:13.849Z] + filename=01_Getting_watershed_boundaries
[2025-01-09T19:34:13.849Z] + [ -e buildout/01_Getting_watershed_boundaries.output.ipynb ]
[2025-01-09T19:34:13.849Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 01_Getting_watershed_boundaries.output.ipynb RavenPy-master/docs/notebooks/01_Getting_watershed_boundaries.ipynb
[2025-01-09T19:34:15.785Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/01_Getting_watershed_boundaries.ipynb to notebook
[2025-01-09T19:34:30.614Z] [NbConvertApp] Writing 109427 bytes to buildout/01_Getting_watershed_boundaries.output.ipynb
[2025-01-09T19:34:30.614Z] + basename RavenPy-master/docs/notebooks/02_Extract_geographical_watershed_properties.ipynb
[2025-01-09T19:34:30.614Z] + filename=02_Extract_geographical_watershed_properties.ipynb
[2025-01-09T19:34:30.614Z] + echo 02_Extract_geographical_watershed_properties.ipynb
[2025-01-09T19:34:30.614Z] + sed s/.ipynb$//
[2025-01-09T19:34:30.614Z] + filename=02_Extract_geographical_watershed_properties
[2025-01-09T19:34:30.614Z] + [ -e buildout/02_Extract_geographical_watershed_properties.output.ipynb ]
[2025-01-09T19:34:30.614Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 02_Extract_geographical_watershed_properties.output.ipynb RavenPy-master/docs/notebooks/02_Extract_geographical_watershed_properties.ipynb
[2025-01-09T19:34:30.614Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/02_Extract_geographical_watershed_properties.ipynb to notebook
[2025-01-09T19:34:48.650Z] [NbConvertApp] Writing 279636 bytes to buildout/02_Extract_geographical_watershed_properties.output.ipynb
[2025-01-09T19:34:48.650Z] + basename RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb
[2025-01-09T19:34:48.650Z] + filename=03_Extracting_forcing_data.ipynb
[2025-01-09T19:34:48.650Z] + echo 03_Extracting_forcing_data.ipynb
[2025-01-09T19:34:48.650Z] + sed s/.ipynb$//
[2025-01-09T19:34:48.650Z] + filename=03_Extracting_forcing_data
[2025-01-09T19:34:48.650Z] + [ -e buildout/03_Extracting_forcing_data.output.ipynb ]
[2025-01-09T19:34:48.650Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 03_Extracting_forcing_data.output.ipynb RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb
[2025-01-09T19:34:48.650Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/03_Extracting_forcing_data.ipynb to notebook
[2025-01-09T19:35:03.488Z] [NbConvertApp] Writing 26855 bytes to buildout/03_Extracting_forcing_data.output.ipynb
[2025-01-09T19:35:03.488Z] + basename RavenPy-master/docs/notebooks/04_Emulating_hydrological_models.ipynb
[2025-01-09T19:35:03.488Z] + filename=04_Emulating_hydrological_models.ipynb
[2025-01-09T19:35:03.488Z] + echo 04_Emulating_hydrological_models.ipynb
[2025-01-09T19:35:03.488Z] + sed s/.ipynb$//
[2025-01-09T19:35:03.488Z] + filename=04_Emulating_hydrological_models
[2025-01-09T19:35:03.488Z] + [ -e buildout/04_Emulating_hydrological_models.output.ipynb ]
[2025-01-09T19:35:03.489Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 04_Emulating_hydrological_models.output.ipynb RavenPy-master/docs/notebooks/04_Emulating_hydrological_models.ipynb
[2025-01-09T19:35:04.419Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/04_Emulating_hydrological_models.ipynb to notebook
[2025-01-09T19:35:22.472Z] [NbConvertApp] Writing 395904 bytes to buildout/04_Emulating_hydrological_models.output.ipynb
[2025-01-09T19:35:22.472Z] + basename RavenPy-master/docs/notebooks/05_Advanced_RavenPy_configuration.ipynb
[2025-01-09T19:35:22.472Z] + filename=05_Advanced_RavenPy_configuration.ipynb
[2025-01-09T19:35:22.472Z] + echo 05_Advanced_RavenPy_configuration.ipynb
[2025-01-09T19:35:22.472Z] + sed s/.ipynb$//
[2025-01-09T19:35:22.472Z] + filename=05_Advanced_RavenPy_configuration
[2025-01-09T19:35:22.472Z] + [ -e buildout/05_Advanced_RavenPy_configuration.output.ipynb ]
[2025-01-09T19:35:22.472Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 05_Advanced_RavenPy_configuration.output.ipynb RavenPy-master/docs/notebooks/05_Advanced_RavenPy_configuration.ipynb
[2025-01-09T19:35:22.472Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/05_Advanced_RavenPy_configuration.ipynb to notebook
[2025-01-09T19:35:40.536Z] [NbConvertApp] Writing 305148 bytes to buildout/05_Advanced_RavenPy_configuration.output.ipynb
[2025-01-09T19:35:40.536Z] + basename RavenPy-master/docs/notebooks/06_Raven_calibration.ipynb
[2025-01-09T19:35:40.536Z] + filename=06_Raven_calibration.ipynb
[2025-01-09T19:35:40.536Z] + echo 06_Raven_calibration.ipynb
[2025-01-09T19:35:40.536Z] + sed s/.ipynb$//
[2025-01-09T19:35:40.536Z] + filename=06_Raven_calibration
[2025-01-09T19:35:40.536Z] + [ -e buildout/06_Raven_calibration.output.ipynb ]
[2025-01-09T19:35:40.536Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 06_Raven_calibration.output.ipynb RavenPy-master/docs/notebooks/06_Raven_calibration.ipynb
[2025-01-09T19:35:41.100Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/06_Raven_calibration.ipynb to notebook
[2025-01-09T19:35:55.930Z] [NbConvertApp] Writing 18799 bytes to buildout/06_Raven_calibration.output.ipynb
[2025-01-09T19:35:55.930Z] + basename RavenPy-master/docs/notebooks/07_Making_and_using_hotstart_files.ipynb
[2025-01-09T19:35:55.930Z] + filename=07_Making_and_using_hotstart_files.ipynb
[2025-01-09T19:35:55.930Z] + + sed s/.ipynb$//
[2025-01-09T19:35:55.930Z] echo 07_Making_and_using_hotstart_files.ipynb
[2025-01-09T19:35:55.930Z] + filename=07_Making_and_using_hotstart_files
[2025-01-09T19:35:55.930Z] + [ -e buildout/07_Making_and_using_hotstart_files.output.ipynb ]
[2025-01-09T19:35:55.930Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 07_Making_and_using_hotstart_files.output.ipynb RavenPy-master/docs/notebooks/07_Making_and_using_hotstart_files.ipynb
[2025-01-09T19:35:55.930Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/07_Making_and_using_hotstart_files.ipynb to notebook
[2025-01-09T19:36:08.093Z] [NbConvertApp] Writing 193897 bytes to buildout/07_Making_and_using_hotstart_files.output.ipynb
[2025-01-09T19:36:08.093Z] + basename RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb
[2025-01-09T19:36:08.093Z] + filename=08_Getting_and_bias_correcting_CMIP6_data.ipynb
[2025-01-09T19:36:08.093Z] + sed s/.ipynb$//
[2025-01-09T19:36:08.093Z] + echo 08_Getting_and_bias_correcting_CMIP6_data.ipynb
[2025-01-09T19:36:08.093Z] + filename=08_Getting_and_bias_correcting_CMIP6_data
[2025-01-09T19:36:08.093Z] + [ -e buildout/08_Getting_and_bias_correcting_CMIP6_data.output.ipynb ]
[2025-01-09T19:36:08.093Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 08_Getting_and_bias_correcting_CMIP6_data.output.ipynb RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb
[2025-01-09T19:36:08.668Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/08_Getting_and_bias_correcting_CMIP6_data.ipynb to notebook
[2025-01-09T19:37:16.405Z] [NbConvertApp] Writing 130630 bytes to buildout/08_Getting_and_bias_correcting_CMIP6_data.output.ipynb
[2025-01-09T19:37:16.405Z] + basename RavenPy-master/docs/notebooks/09_Hydrological_impacts_of_climate_change.ipynb
[2025-01-09T19:37:16.405Z] + filename=09_Hydrological_impacts_of_climate_change.ipynb
[2025-01-09T19:37:16.405Z] + echo 09_Hydrological_impacts_of_climate_change.ipynb
[2025-01-09T19:37:16.405Z] + sed s/.ipynb$//
[2025-01-09T19:37:16.405Z] + filename=09_Hydrological_impacts_of_climate_change
[2025-01-09T19:37:16.405Z] + [ -e buildout/09_Hydrological_impacts_of_climate_change.output.ipynb ]
[2025-01-09T19:37:16.405Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 09_Hydrological_impacts_of_climate_change.output.ipynb RavenPy-master/docs/notebooks/09_Hydrological_impacts_of_climate_change.ipynb
[2025-01-09T19:37:16.405Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/09_Hydrological_impacts_of_climate_change.ipynb to notebook
[2025-01-09T19:37:28.565Z] [NbConvertApp] Writing 124107 bytes to buildout/09_Hydrological_impacts_of_climate_change.output.ipynb
[2025-01-09T19:37:28.565Z] + basename RavenPy-master/docs/notebooks/10_Data_assimilation.ipynb
[2025-01-09T19:37:28.565Z] + filename=10_Data_assimilation.ipynb
[2025-01-09T19:37:28.566Z] + echo 10_Data_assimilation.ipynb
[2025-01-09T19:37:28.566Z] + sed s/.ipynb$//
[2025-01-09T19:37:28.566Z] + filename=10_Data_assimilation
[2025-01-09T19:37:28.566Z] + [ -e buildout/10_Data_assimilation.output.ipynb ]
[2025-01-09T19:37:28.566Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 10_Data_assimilation.output.ipynb RavenPy-master/docs/notebooks/10_Data_assimilation.ipynb
[2025-01-09T19:37:29.938Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/10_Data_assimilation.ipynb to notebook
[2025-01-09T19:38:16.569Z] [NbConvertApp] Writing 381190 bytes to buildout/10_Data_assimilation.output.ipynb
[2025-01-09T19:38:16.569Z] + basename RavenPy-master/docs/notebooks/11_Climatological_ESP_forecasting.ipynb
[2025-01-09T19:38:16.569Z] + filename=11_Climatological_ESP_forecasting.ipynb
[2025-01-09T19:38:16.569Z] + echo 11_Climatological_ESP_forecasting.ipynb
[2025-01-09T19:38:16.569Z] + sed s/.ipynb$//
[2025-01-09T19:38:16.569Z] + filename=11_Climatological_ESP_forecasting
[2025-01-09T19:38:16.569Z] + [ -e buildout/11_Climatological_ESP_forecasting.output.ipynb ]
[2025-01-09T19:38:16.569Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 11_Climatological_ESP_forecasting.output.ipynb RavenPy-master/docs/notebooks/11_Climatological_ESP_forecasting.ipynb
[2025-01-09T19:38:17.932Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/11_Climatological_ESP_forecasting.ipynb to notebook
[2025-01-09T19:39:04.542Z] [NbConvertApp] Writing 175701 bytes to buildout/11_Climatological_ESP_forecasting.output.ipynb
[2025-01-09T19:39:04.542Z] + basename RavenPy-master/docs/notebooks/12_Performing_hindcasting_experiments.ipynb
[2025-01-09T19:39:04.542Z] + filename=12_Performing_hindcasting_experiments.ipynb
[2025-01-09T19:39:04.542Z] + echo 12_Performing_hindcasting_experiments.ipynb
[2025-01-09T19:39:04.542Z] + sed s/.ipynb$//
[2025-01-09T19:39:04.542Z] + filename=12_Performing_hindcasting_experiments
[2025-01-09T19:39:04.542Z] + [ -e buildout/12_Performing_hindcasting_experiments.output.ipynb ]
[2025-01-09T19:39:04.542Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output 12_Performing_hindcasting_experiments.output.ipynb RavenPy-master/docs/notebooks/12_Performing_hindcasting_experiments.ipynb
[2025-01-09T19:39:05.904Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/12_Performing_hindcasting_experiments.ipynb to notebook
[2025-01-09T19:39:37.921Z] [NbConvertApp] Writing 148633 bytes to buildout/12_Performing_hindcasting_experiments.output.ipynb
[2025-01-09T19:39:37.921Z] + basename RavenPy-master/docs/notebooks/Assess_probabilistic_flood_risk.ipynb
[2025-01-09T19:39:37.921Z] + filename=Assess_probabilistic_flood_risk.ipynb
[2025-01-09T19:39:37.921Z] + sed s/.ipynb$//
[2025-01-09T19:39:37.921Z] + echo Assess_probabilistic_flood_risk.ipynb
[2025-01-09T19:39:37.921Z] + filename=Assess_probabilistic_flood_risk
[2025-01-09T19:39:37.921Z] + [ -e buildout/Assess_probabilistic_flood_risk.output.ipynb ]
[2025-01-09T19:39:37.922Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Assess_probabilistic_flood_risk.output.ipynb RavenPy-master/docs/notebooks/Assess_probabilistic_flood_risk.ipynb
[2025-01-09T19:39:37.922Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/Assess_probabilistic_flood_risk.ipynb to notebook
[2025-01-09T19:40:16.657Z] [NbConvertApp] Writing 158839 bytes to buildout/Assess_probabilistic_flood_risk.output.ipynb
[2025-01-09T19:40:16.657Z] + basename RavenPy-master/docs/notebooks/Comparing_hindcasts_and_ESP_forecasts.ipynb
[2025-01-09T19:40:16.657Z] + filename=Comparing_hindcasts_and_ESP_forecasts.ipynb
[2025-01-09T19:40:16.657Z] + echo Comparing_hindcasts_and_ESP_forecasts.ipynb
[2025-01-09T19:40:16.657Z] + sed s/.ipynb$//
[2025-01-09T19:40:16.657Z] + filename=Comparing_hindcasts_and_ESP_forecasts
[2025-01-09T19:40:16.657Z] + [ -e buildout/Comparing_hindcasts_and_ESP_forecasts.output.ipynb ]
[2025-01-09T19:40:16.657Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Comparing_hindcasts_and_ESP_forecasts.output.ipynb RavenPy-master/docs/notebooks/Comparing_hindcasts_and_ESP_forecasts.ipynb
[2025-01-09T19:40:17.583Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/Comparing_hindcasts_and_ESP_forecasts.ipynb to notebook
[2025-01-09T19:41:04.180Z] [NbConvertApp] Writing 302917 bytes to buildout/Comparing_hindcasts_and_ESP_forecasts.output.ipynb
[2025-01-09T19:41:04.180Z] + basename RavenPy-master/docs/notebooks/Distributed_hydrological_modelling.ipynb
[2025-01-09T19:41:04.180Z] + filename=Distributed_hydrological_modelling.ipynb
[2025-01-09T19:41:04.180Z] + echo Distributed_hydrological_modelling.ipynb
[2025-01-09T19:41:04.180Z] + sed s/.ipynb$//
[2025-01-09T19:41:04.180Z] + filename=Distributed_hydrological_modelling
[2025-01-09T19:41:04.180Z] + [ -e buildout/Distributed_hydrological_modelling.output.ipynb ]
[2025-01-09T19:41:04.181Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Distributed_hydrological_modelling.output.ipynb RavenPy-master/docs/notebooks/Distributed_hydrological_modelling.ipynb
[2025-01-09T19:41:04.181Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/Distributed_hydrological_modelling.ipynb to notebook
[2025-01-09T19:41:30.701Z] [NbConvertApp] Writing 101017 bytes to buildout/Distributed_hydrological_modelling.output.ipynb
[2025-01-09T19:41:30.701Z] + basename RavenPy-master/docs/notebooks/HydroShare_integration.ipynb
[2025-01-09T19:41:30.701Z] + filename=HydroShare_integration.ipynb
[2025-01-09T19:41:30.701Z] + sed s/.ipynb$//
[2025-01-09T19:41:30.701Z] + echo HydroShare_integration.ipynb
[2025-01-09T19:41:30.701Z] + filename=HydroShare_integration
[2025-01-09T19:41:30.701Z] + [ -e buildout/HydroShare_integration.output.ipynb ]
[2025-01-09T19:41:30.701Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output HydroShare_integration.output.ipynb RavenPy-master/docs/notebooks/HydroShare_integration.ipynb
[2025-01-09T19:41:31.264Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/HydroShare_integration.ipynb to notebook
[2025-01-09T19:41:36.503Z] [NbConvertApp] Writing 13075 bytes to buildout/HydroShare_integration.output.ipynb
[2025-01-09T19:41:36.503Z] + basename RavenPy-master/docs/notebooks/Hydrological_realtime_forecasting.ipynb
[2025-01-09T19:41:36.503Z] + filename=Hydrological_realtime_forecasting.ipynb
[2025-01-09T19:41:36.503Z] + echo Hydrological_realtime_forecasting.ipynb
[2025-01-09T19:41:36.503Z] + sed s/.ipynb$//
[2025-01-09T19:41:36.503Z] + filename=Hydrological_realtime_forecasting
[2025-01-09T19:41:36.503Z] + [ -e buildout/Hydrological_realtime_forecasting.output.ipynb ]
[2025-01-09T19:41:36.503Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Hydrological_realtime_forecasting.output.ipynb RavenPy-master/docs/notebooks/Hydrological_realtime_forecasting.ipynb
[2025-01-09T19:41:37.863Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/Hydrological_realtime_forecasting.ipynb to notebook
[2025-01-09T19:42:09.881Z] [NbConvertApp] Writing 152876 bytes to buildout/Hydrological_realtime_forecasting.output.ipynb
[2025-01-09T19:42:09.881Z] + basename RavenPy-master/docs/notebooks/Managing_Jupyter_Environments.ipynb
[2025-01-09T19:42:09.881Z] + filename=Managing_Jupyter_Environments.ipynb
[2025-01-09T19:42:09.881Z] + sed s/.ipynb$//
[2025-01-09T19:42:09.881Z] + echo Managing_Jupyter_Environments.ipynb
[2025-01-09T19:42:09.881Z] + filename=Managing_Jupyter_Environments
[2025-01-09T19:42:09.881Z] + [ -e buildout/Managing_Jupyter_Environments.output.ipynb ]
[2025-01-09T19:42:09.881Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Managing_Jupyter_Environments.output.ipynb RavenPy-master/docs/notebooks/Managing_Jupyter_Environments.ipynb
[2025-01-09T19:42:11.769Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/Managing_Jupyter_Environments.ipynb to notebook
[2025-01-09T19:42:18.294Z] [NbConvertApp] Writing 9450 bytes to buildout/Managing_Jupyter_Environments.output.ipynb
[2025-01-09T19:42:18.294Z] + basename RavenPy-master/docs/notebooks/Perform_Regionalization.ipynb
[2025-01-09T19:42:18.294Z] + filename=Perform_Regionalization.ipynb
[2025-01-09T19:42:18.294Z] + echo Perform_Regionalization.ipynb
[2025-01-09T19:42:18.294Z] + sed s/.ipynb$//
[2025-01-09T19:42:18.294Z] + filename=Perform_Regionalization
[2025-01-09T19:42:18.294Z] + [ -e buildout/Perform_Regionalization.output.ipynb ]
[2025-01-09T19:42:18.294Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Perform_Regionalization.output.ipynb RavenPy-master/docs/notebooks/Perform_Regionalization.ipynb
[2025-01-09T19:42:19.225Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/Perform_Regionalization.ipynb to notebook
[2025-01-09T19:42:51.244Z] [NbConvertApp] Writing 119590 bytes to buildout/Perform_Regionalization.output.ipynb
[2025-01-09T19:42:51.244Z] + basename RavenPy-master/docs/notebooks/Running_HMETS_with_CANOPEX_dataset.ipynb
[2025-01-09T19:42:51.244Z] + filename=Running_HMETS_with_CANOPEX_dataset.ipynb
[2025-01-09T19:42:51.244Z] + echo Running_HMETS_with_CANOPEX_dataset.ipynb
[2025-01-09T19:42:51.244Z] + sed s/.ipynb$//
[2025-01-09T19:42:51.244Z] + filename=Running_HMETS_with_CANOPEX_dataset
[2025-01-09T19:42:51.244Z] + [ -e buildout/Running_HMETS_with_CANOPEX_dataset.output.ipynb ]
[2025-01-09T19:42:51.245Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Running_HMETS_with_CANOPEX_dataset.output.ipynb RavenPy-master/docs/notebooks/Running_HMETS_with_CANOPEX_dataset.ipynb
[2025-01-09T19:42:51.245Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/Running_HMETS_with_CANOPEX_dataset.ipynb to notebook
[2025-01-09T19:43:06.073Z] [NbConvertApp] Writing 107007 bytes to buildout/Running_HMETS_with_CANOPEX_dataset.output.ipynb
[2025-01-09T19:43:06.073Z] + basename RavenPy-master/docs/notebooks/Sensitivity_analysis.ipynb
[2025-01-09T19:43:06.073Z] + filename=Sensitivity_analysis.ipynb
[2025-01-09T19:43:06.073Z] + echo Sensitivity_analysis.ipynb
[2025-01-09T19:43:06.073Z] + sed s/.ipynb$//
[2025-01-09T19:43:06.073Z] + filename=Sensitivity_analysis
[2025-01-09T19:43:06.073Z] + [ -e buildout/Sensitivity_analysis.output.ipynb ]
[2025-01-09T19:43:06.073Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Sensitivity_analysis.output.ipynb RavenPy-master/docs/notebooks/Sensitivity_analysis.ipynb
[2025-01-09T19:43:06.632Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/Sensitivity_analysis.ipynb to notebook
[2025-01-09T19:43:28.510Z] [NbConvertApp] Writing 28257 bytes to buildout/Sensitivity_analysis.output.ipynb
[2025-01-09T19:43:28.510Z] + basename RavenPy-master/docs/notebooks/time_series_analysis.ipynb
[2025-01-09T19:43:28.510Z] + filename=time_series_analysis.ipynb
[2025-01-09T19:43:28.510Z] + sed s/.ipynb$//
[2025-01-09T19:43:28.510Z] + echo time_series_analysis.ipynb
[2025-01-09T19:43:28.510Z] + filename=time_series_analysis
[2025-01-09T19:43:28.510Z] + [ -e buildout/time_series_analysis.output.ipynb ]
[2025-01-09T19:43:28.510Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output time_series_analysis.output.ipynb RavenPy-master/docs/notebooks/time_series_analysis.ipynb
[2025-01-09T19:43:28.510Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/time_series_analysis.ipynb to notebook
[2025-01-09T19:43:36.600Z] [NbConvertApp] Writing 187526 bytes to buildout/time_series_analysis.output.ipynb
[2025-01-09T19:43:36.600Z] + basename RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb
[2025-01-09T19:43:36.600Z] + filename=Perform_a_climate_change_impact_study_on_a_watershed.ipynb
[2025-01-09T19:43:36.601Z] + echo Perform_a_climate_change_impact_study_on_a_watershed.ipynb
[2025-01-09T19:43:36.601Z] + sed s/.ipynb$//
[2025-01-09T19:43:36.601Z] + filename=Perform_a_climate_change_impact_study_on_a_watershed
[2025-01-09T19:43:36.601Z] + [ -e buildout/Perform_a_climate_change_impact_study_on_a_watershed.output.ipynb ]
[2025-01-09T19:43:36.601Z] + jupyter nbconvert --to notebook --execute --ExecutePreprocessor.timeout=600 --allow-errors --output-dir buildout --output Perform_a_climate_change_impact_study_on_a_watershed.output.ipynb RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb
[2025-01-09T19:43:37.981Z] [NbConvertApp] Converting notebook RavenPy-master/docs/notebooks/paper/Perform_a_climate_change_impact_study_on_a_watershed.ipynb to notebook
[2025-01-09T19:45:44.401Z] [NbConvertApp] Writing 187525 bytes to buildout/Perform_a_climate_change_impact_study_on_a_watershed.output.ipynb
[2025-01-09T19:45:44.401Z] + exit 1
[2025-01-09T19:45:44.401Z] + EXIT_CODE=1
[2025-01-09T19:45:44.401Z] + ENV_DUMP_DIR=buildout/env-dump
[2025-01-09T19:45:44.401Z] + mkdir -p buildout/env-dump
[2025-01-09T19:45:44.401Z] + ENV_EXPORT_FILE=buildout/env-dump/environment-export-birdy.yml
[2025-01-09T19:45:44.401Z] + rm -fv buildout/env-dump/environment-export-birdy.yml
[2025-01-09T19:45:44.401Z] + conda env export -n birdy
[2025-01-09T19:45:45.764Z] + LIST_EXPLICIT_FILE=buildout/env-dump/conda-list-explicit-birdy.txt
[2025-01-09T19:45:45.764Z] + rm -fv buildout/env-dump/conda-list-explicit-birdy.txt
[2025-01-09T19:45:45.764Z] + conda list -n birdy --explicit
[2025-01-09T19:45:52.292Z] + PIP_FREEZE_FILE=buildout/env-dump/pip-freeze-birdy-requirements.txt
[2025-01-09T19:45:52.292Z] + rm -fv buildout/env-dump/pip-freeze-birdy-requirements.txt
[2025-01-09T19:45:52.292Z] + pip freeze
[2025-01-09T19:45:53.654Z] + exit 1
[Pipeline] }
[Pipeline] // withCredentials
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Declarative: Post Actions)
[Pipeline] archiveArtifacts
[2025-01-09T19:45:54.019Z] Archiving artifacts
[2025-01-09T19:45:54.036Z] Recording fingerprints
[Pipeline] archiveArtifacts
[2025-01-09T19:45:54.094Z] Archiving artifacts
[2025-01-09T19:45:54.781Z] Recording fingerprints
[Pipeline] archiveArtifacts
[2025-01-09T19:45:54.873Z] Archiving artifacts
[2025-01-09T19:45:54.887Z] Recording fingerprints
[Pipeline] archiveArtifacts
[2025-01-09T19:45:54.918Z] Archiving artifacts
[2025-01-09T19:45:54.933Z] Recording fingerprints
[Pipeline] archiveArtifacts
[2025-01-09T19:45:54.953Z] Archiving artifacts
[2025-01-09T19:45:54.973Z] Recording fingerprints
[Pipeline] archiveArtifacts
[2025-01-09T19:45:55.012Z] Archiving artifacts
[2025-01-09T19:45:55.041Z] Recording fingerprints
[Pipeline] archiveArtifacts
[2025-01-09T19:45:55.214Z] Archiving artifacts
[2025-01-09T19:45:55.222Z] Recording fingerprints
[Pipeline] archiveArtifacts
[2025-01-09T19:45:55.237Z] Archiving artifacts
[2025-01-09T19:45:55.286Z] Recording fingerprints
[Pipeline] archiveArtifacts
[2025-01-09T19:45:55.324Z] Archiving artifacts
[2025-01-09T19:45:55.814Z] Recording fingerprints
[Pipeline] archiveArtifacts
[2025-01-09T19:45:55.906Z] Archiving artifacts
[2025-01-09T19:45:56.228Z] Recording fingerprints
[Pipeline] archiveArtifacts
[2025-01-09T19:45:56.440Z] Archiving artifacts
[2025-01-09T19:45:56.459Z] Recording fingerprints
[Pipeline] emailextrecipients
[Pipeline] step
[2025-01-09T19:45:56.549Z] Sending e-mails to: vu.long@ouranos.ca
[Pipeline] }
[Pipeline] // stage
[Pipeline] }
[Pipeline] // timeout
[Pipeline] }
[Pipeline] // timestamps
[Pipeline] }
[Pipeline] // ansiColor
[Pipeline] }
$ docker stop --time=1 e606fce6e884cbfc727842848edd63e06ef3529ac74bebbe6cb9fd762aa3c6d2
$ docker rm -f e606fce6e884cbfc727842848edd63e06ef3529ac74bebbe6cb9fd762aa3c6d2
[Pipeline] // withDockerContainer
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // node
[Pipeline] End of Pipeline
ERROR: script returned exit code 1
Finished: FAILURE
