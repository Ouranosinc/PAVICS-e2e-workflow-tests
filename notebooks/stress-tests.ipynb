{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Various stress tests to see if instance and services response adequately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inputs and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVICS_HOST:  [localhost]\n",
      "TWITCHER_URL: [http://localhost:8001/ows/proxy]\n",
      "TEST_BIRDS:   ['malleefowl']\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "from inspect import cleandoc\n",
    "from dataclasses import dataclass\n",
    "\n",
    "PAVICS_HOST = os.getenv(\"PAVICS_HOST\", \"pavics.ouranos.ca\").rstrip(\"/\")\n",
    "if not PAVICS_HOST:\n",
    "    raise ValueError(\"Cannot run test without a PAVICS_HOST value.\")\n",
    "\n",
    "PAVICS_URL = f\"https://{PAVICS_HOST}\"\n",
    "VERIFY_SSL = True if \"DISABLE_VERIFY_SSL\" not in os.environ else False\n",
    "MAGPIE_URL = PAVICS_URL + \"/magpie\"\n",
    "TWITCHER_PROXY = \"/twitcher/ows/proxy\"\n",
    "TWITCHER_URL = os.getenv(\"TWITCHER_URL\", PAVICS_URL + TWITCHER_PROXY)\n",
    "\n",
    "# test config\n",
    "TEST_BIRDS = str(os.getenv(\"TEST_BIRDS\", \"finch,flyingpigeon,raven\"))\n",
    "TEST_BIRDS = [bird.strip() for bird in TEST_BIRDS.split(\",\")]\n",
    "if not len(TEST_BIRDS):\n",
    "    raise ValueError(\"Cannot run test without at least one service in TEST_BIRDS.\")\n",
    "TEST_RUNS = int(os.getenv(\"TEST_RUNS\", 100))  # number of requests per tested bird\n",
    "TEST_MAX_AVG_TIME = int(os.getenv(\"TEST_MAX_AVG_TIME\", 1))     # maximum allowed request seconds on average for success\n",
    "TEST_MAX_ERR_CODE = int(os.getenv(\"TEST_MAX_ERR_CODE\", 0))     # maximum allowed amount of incorrect request status code\n",
    "TEST_TIMEOUT_ABORT = int(os.getenv(\"TEST_TIMEOUT_ABORT\", 5))   # maximum timeout duration to wait before abort request\n",
    "TEST_TIMEOUT_RETRY = int(os.getenv(\"TEST_ABORT_THRESHOLD\", 3)) # maximum request timeout retries before bird is aborted\n",
    "\n",
    "print(f\"PAVICS_HOST:  [{PAVICS_HOST}]\")\n",
    "print(f\"TWITCHER_URL: [{TWITCHER_URL}]\")\n",
    "print(f\"TEST_BIRDS:   {TEST_BIRDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StressTestResult:\n",
    "    code: int = 200\n",
    "    runs: int = 0\n",
    "    max_avg_time: float = 0\n",
    "    max_err_code: int = 0\n",
    "    timeout_abort: int = 0\n",
    "    timeout_retry: int = 0\n",
    "    timeout_count: int = 0\n",
    "    method: str = \"GET\"\n",
    "    url: str = None\n",
    "    request_args: dict = None\n",
    "    status: int = 0  # see description of stress-test\n",
    "    codes = []\n",
    "    delta = []\n",
    "    times = []\n",
    "\n",
    "    @property\n",
    "    def avg_time(self):\n",
    "        return sum(self.times) / self.runs\n",
    "\n",
    "    @property\n",
    "    def min_time(self):\n",
    "        return min(self.times)\n",
    "\n",
    "    @property\n",
    "    def max_time(self):\n",
    "        return max(self.times)\n",
    "\n",
    "    @property\n",
    "    def sum_err_code(self):\n",
    "        return sum([code != self.code for code in self.codes])\n",
    "\n",
    "    def __str__(self):\n",
    "        columns = [\"Run\", \"Codes\", \"Delta\", \"Times\"]\n",
    "        idx = len(str(self.runs))\n",
    "        r = max(len(columns[0]), idx)\n",
    "        w = 10\n",
    "        header = \"\".join(f\"{c:>{w if i else r}}\" for i, c in enumerate(columns))\n",
    "        offset = 16\n",
    "        data = [f\"{i+1:>{r+(offset if i else 0)}}\"\n",
    "                f\"{('(!) ' if c != self.code else '(x) ' if self.code == 408 else '') + str(c):>{w}}\"\n",
    "                f\"{d:>{w-1}.3f}s\"\n",
    "                f\"{t:>{w-1}.3f}s\"\n",
    "                for i, (c, d, t)\n",
    "                in enumerate(zip(self.codes, self.delta, self.times))]\n",
    "        lines = \"\\n\".join(data)\n",
    "        summary = \"Undefined failure result status condition encountered.\"\n",
    "        if results.status == 0:\n",
    "            summary = [\n",
    "                \"All passing conditions have been achieved.\",\n",
    "            ]\n",
    "        elif results.status == -1:\n",
    "            summary = [\n",
    "                f\"Detected {self.sum_err_code} erroneous HTTP codes not equal to expected {self.code}.\"\n",
    "            ]\n",
    "        elif results.status == -2:\n",
    "            summary = [\n",
    "                f\"Detected regression with long request time.\",\n",
    "                f\"Expected max-avg-time: ({self.max_avg_time:.3f}s <= {self.max_time:.3f}s).\"\n",
    "            ]\n",
    "        elif results.status == -3:\n",
    "            summary = [\n",
    "\n",
    "            ]\n",
    "        summary.append(f\"Test {'succeeded' if results.status == 0 else 'failed'}.\")\n",
    "        summary = \"\\n\".join([f\"{s:>{r+(offset if i else 0)}}\" for i, s in enumerate(summary)])\n",
    "        return cleandoc(f\"\"\"\n",
    "        Stress Test:\n",
    "            Test:\n",
    "                code: {self.code}\n",
    "                runs: {self.runs}\n",
    "                max-avg-time:  {self.max_avg_time}s\n",
    "                max-err-code:  {self.max_err_code}\n",
    "                sum-err-code:  {self.sum_err_code}\n",
    "                timeout-abort: {self.timeout_abort}s\n",
    "                timeout-retry: {self.timeout_retry}\n",
    "                timeout-count: {self.timeout_count}\n",
    "            Request:\n",
    "                method: {self.method}\n",
    "                url:    {self.url}\n",
    "                args:   {self.request_args}\n",
    "            Times:\n",
    "                min: {self.min_time:.3f}s\n",
    "                avg: {self.avg_time:.3f}s\n",
    "                max: {self.max_time:.3f}s\n",
    "            Results:\n",
    "                {header}\n",
    "                {lines}\n",
    "            Summary:\n",
    "                {summary}\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "def stress_test_requests(url: str, method=\"GET\", runs=100, code=200, delays=True,\n",
    "                         max_err_code=0, max_avg_time=None,\n",
    "                         abort_timeout=5, abort_retries=3, **req_kwargs) -> StressTestResult:\n",
    "    \"\"\"\n",
    "    Executes the request for the number of demanded runs and validates the expected status is always returned.\n",
    "\n",
    "    Outputs the results of each request and a summary of their execution time.\n",
    "    If requested, also validates that all responses were returned on average faster than the maximum allowed time.\n",
    "\n",
    "    :param url: endpoint to stress test\n",
    "    :param method: HTTP method for request\n",
    "    :param runs: number of stress test request\n",
    "    :param code: expected HTTP code from requests\n",
    "    :param delays: whether to apply small random delays between requests\n",
    "       Otherwise, sequential requests are executed as quickly as possible, when the previous response is obtained.\n",
    "    :param max_err_code: maximum amount of erroneous HTTP status code allowed to consider the test successful.\n",
    "    :param max_avg_time: maximum average time of requests permitted to consider the test successful.\n",
    "    :param abort_timeout: duration to wait until a request is aborted, sets 408 (Read Timeout) as HTTP status code.\n",
    "    :param abort_retries: number of failed timeout requests allowed before abort of whole stress test for this endpoint.\n",
    "    :returns:\n",
    "        StressTestResult with individual request results and one of below status:\n",
    "        -  0 (success) for no error and all conditions achieved\n",
    "        - -1 (failure) for maximum amount of HTT error code reached\n",
    "        - -2 (failure) for maximum request time on average reached\n",
    "        - -3 (failure) for aborted test due to too many timeout\n",
    "    \"\"\"\n",
    "    print(f\"\\nStress Test with [{runs}] calls to [{url}]\")\n",
    "    req_kwargs.pop(\"timeout\", None)\n",
    "    result = StressTestResult()\n",
    "    result.runs = runs\n",
    "    result.url = url\n",
    "    result.method = method\n",
    "    result.request_args = req_kwargs\n",
    "    result.max_err_code = max_err_code\n",
    "    result.max_avg_time = max_avg_time\n",
    "    result.abort_timeout = abort_timeout\n",
    "    result.abort_retries = abort_retries\n",
    "    result.codes = []\n",
    "    result.times = []\n",
    "    result.delta = [0.] + [float((random.randint(1, 100) / 1000) if delays else 0) for _ in range(1, runs)]\n",
    "\n",
    "    char = len(str(runs))\n",
    "    for i in range(runs):\n",
    "        if not i % 10:\n",
    "            print(f\"Progress: {i:>{char}}/{runs}\")\n",
    "        start = time.perf_counter()\n",
    "        try:\n",
    "            resp = requests.request(method, url, timeout=abort_timeout, **req_kwargs)\n",
    "        except requests.exceptions.Timeout:\n",
    "            result.times.append(abort_timeout)\n",
    "            result.codes.append(408)  # read timeout\n",
    "            result.timeout_count += 1\n",
    "        else:\n",
    "            result.times.append(time.perf_counter() - start)\n",
    "            result.codes.append(resp.status_code)\n",
    "        if result.timeout_count > abort_timeout:\n",
    "            result.status = -3\n",
    "            print(f\"Aborted: Too Many Timeout ({result.timeout_count})\")\n",
    "            return result\n",
    "        if i == runs:\n",
    "            break\n",
    "        if result.delta[i]:\n",
    "            time.sleep(result.delta[i])\n",
    "    print(f\"Progress: {runs:>{char}}/{runs}\")\n",
    "    if max_avg_time and result.avg_time > max_avg_time:\n",
    "        result.status = -2\n",
    "    elif len([c for c in result.codes if c == code]) >= (runs - max_err_code):\n",
    "        result.status = 0\n",
    "    else:\n",
    "        result.status = -1\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "\n",
    "test_statuses = []\n",
    "for bird in TEST_BIRDS:\n",
    "    bird_url = f\"{TWITCHER_URL}/{bird}/wps?service=wps&request=getcapabilities\"\n",
    "    expect_status_code = 200\n",
    "    results = stress_test_requests(bird_url, runs=TEST_RUNS, code=expect_status_code,\n",
    "                                   max_err_code=TEST_MAX_ERR_CODE, max_avg_time=TEST_MAX_AVG_TIME,\n",
    "                                   abort_retries=TEST_TIMEOUT_RETRY, abort_timeout=TEST_TIMEOUT_ABORT)\n",
    "    test_statuses.append(results.status)\n",
    "    print(results)\n",
    "failed_tests = sum(test_statuses) \n",
    "assert not failed_tests, f\"Failed {failed_tests} tests.\"\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}