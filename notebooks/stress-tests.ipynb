{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Various stress tests to see if instance and services response adequately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inputs and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVICS_HOST:    [pavics.ouranos.ca]\n",
      "TWITCHER_URL:   [https://pavics.ouranos.ca/twitcher/ows/proxy]\n",
      "TEST_WPS_BIRDS: ['finch', 'flyingpigeon', 'raven', 'hummingbird']\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime \n",
    "from inspect import cleandoc\n",
    "from dataclasses import dataclass\n",
    "import threading\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "PAVICS_HOST = os.getenv(\"PAVICS_HOST\", \"pavics.ouranos.ca\").rstrip(\"/\")\n",
    "if not PAVICS_HOST:\n",
    "    raise ValueError(\"Cannot run test without a PAVICS_HOST value.\")\n",
    "\n",
    "PAVICS_URL = f\"https://{PAVICS_HOST}\"\n",
    "VERIFY_SSL = True if \"DISABLE_VERIFY_SSL\" not in os.environ else False\n",
    "MAGPIE_URL = PAVICS_URL + \"/magpie\"\n",
    "TWITCHER_PROXY = \"/twitcher/ows/proxy\"\n",
    "TWITCHER_URL = PAVICS_URL + TWITCHER_PROXY\n",
    "TWITCHER_URL = os.getenv(\"TWITCHER_URL\") or TWITCHER_URL\n",
    "\n",
    "# test config\n",
    "TEST_WPS_BIRDS = str(os.getenv(\"TEST_WPS_BIRDS\", \"finch,flyingpigeon,raven,hummingbird\"))\n",
    "TEST_WPS_BIRDS = [bird.strip() for bird in TEST_WPS_BIRDS.split(\",\")]\n",
    "if not len(TEST_WPS_BIRDS):\n",
    "    raise ValueError(\"Cannot run test without at least one service in TEST_WPS_BIRDS.\")\n",
    "\n",
    "TEST_MAX_AVG_TIME = int(os.getenv(\"TEST_MAX_AVG_TIME\", 1))     # maximum allowed request seconds on average for success\n",
    "TEST_MAX_ERR_CODE = int(os.getenv(\"TEST_MAX_ERR_CODE\", 0))     # maximum allowed amount of incorrect request status code\n",
    "TEST_TIMEOUT_ABORT = int(os.getenv(\"TEST_TIMEOUT_ABORT\", 5))   # maximum timeout duration to wait before abort request\n",
    "TEST_TIMEOUT_RETRY = int(os.getenv(\"TEST_ABORT_THRESHOLD\", 3)) # maximum request timeout retries before bird is aborted\n",
    "\n",
    "TEST_RUNS = int(os.getenv(\"TEST_RUNS\", 100))  # number of requests per tested bird\n",
    "TEST_RUNS_THREDDS = int(os.getenv(\"TEST_RUNS_THREDDS\", 500)) # number of requests for thredds test\n",
    "\n",
    "TEST_N_THREADS_WPS = int(os.getenv(\"TEST_N_THREADS_WPS\", 3)) # number of threads testing in parallel each bird\n",
    "TEST_N_THREADS_THREDDS = int(os.getenv(\"TEST_N_THREADS_THREDDS\", 3)) # number of threads testing in parallel thredds\n",
    "\n",
    "\n",
    "print(f\"PAVICS_HOST:    [{PAVICS_HOST}]\")\n",
    "print(f\"TWITCHER_URL:   [{TWITCHER_URL}]\")\n",
    "print(f\"TEST_WPS_BIRDS: {TEST_WPS_BIRDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Progression:\n",
    "    \"\"\"\n",
    "    Class used by threads to keep track of the amount of request and progression of the tests. \n",
    "    Passed to each threads so that we know the progression in between threads\n",
    "    \"\"\"\n",
    "    count: int = 0\n",
    "    n_threads: int = 0\n",
    "    runs_per_threads: int = 0\n",
    "    total_runs: int = 0\n",
    "    \n",
    "    def __init__(self, n_threads:int, runs_per_threads: int):\n",
    "        \"\"\"\n",
    "        :param n_threads: number of threads \n",
    "        :param runs_per_threads: number of stress test request\n",
    "        \"\"\"\n",
    "        self.count = 0 \n",
    "        self.n_threads = n_threads\n",
    "        self.runs_per_threads = runs_per_threads\n",
    "        self.total_runs = runs_per_threads * n_threads\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)\n",
    "\n",
    "        \n",
    "    def increase(self, amount):\n",
    "        self.count = self.count + amount\n",
    "        \n",
    "        if threading.current_thread().name:\n",
    "            thread_name = threading.current_thread().name\n",
    "            print(f'    {thread_name} --> Progress : {self.count}/{self.total_runs}   ')\n",
    "        else :\n",
    "            print(f'    Progress : {self.count}/{self.total_runs} ')\n",
    "            \n",
    "@dataclass\n",
    "class StressTestResult:\n",
    "    code: int = 200\n",
    "    runs: int = 0\n",
    "    max_avg_time: float = 0\n",
    "    max_err_code: int = 0\n",
    "    timeout_abort: int = 0\n",
    "    timeout_retry: int = 0\n",
    "    timeout_count: int = 0\n",
    "    method: str = \"GET\"\n",
    "    url: str = None\n",
    "    request_args: dict = None\n",
    "    status: int = 0  # see description of stress-test\n",
    "    codes = []\n",
    "    delta = []\n",
    "    times = []\n",
    "    timestamps = []\n",
    "    \n",
    "    @property\n",
    "    def avg_time(self):\n",
    "        return sum(self.times) / self.runs\n",
    "\n",
    "    @property\n",
    "    def min_time(self):\n",
    "        return min(self.times)\n",
    "\n",
    "    @property\n",
    "    def max_time(self):\n",
    "        return max(self.times)\n",
    "\n",
    "    @property\n",
    "    def sum_err_code(self):\n",
    "        return sum([code != self.code for code in self.codes])\n",
    "\n",
    "    def __str__(self):\n",
    "        columns = [\"Run\", \"Codes\", \"Delta\", \"Times\", \"Timestamps\"]\n",
    "        idx = len(str(self.runs))\n",
    "        r = max(len(columns[0]), idx)\n",
    "        w = 22\n",
    "        header = \"\".join(f\"{c:>{w if i else r}}\" for i, c in enumerate(columns))\n",
    "        offset = 16  # spaces offset of result lines, relative to this file\n",
    "        data = [f\"{i+1:>{r+(offset if i else 0)}}\"\n",
    "                f\"{('(!) ' if c != self.code else '(x) ' if self.code == 408 else '') + str(c):>{w}}\"\n",
    "                f\"{d:>{w-1}.3f}s\"\n",
    "                f\"{t:>{w-1}.3f}s\"\n",
    "                f\"{ts:>{w}}\"\n",
    "                for i, (c, d, t, ts)\n",
    "                in enumerate(zip(self.codes, self.delta, self.times, self.timestamps))]\n",
    "        lines = \"\\n\".join(data)\n",
    "        summary = \"Undefined failure result status condition encountered.\"\n",
    "        if self.status == 0:\n",
    "            summary = [\n",
    "                \"All passing conditions have been achieved.\",\n",
    "            ]\n",
    "        elif self.status == -1:\n",
    "            summary = [\n",
    "                f\"Detected {self.sum_err_code} erroneous HTTP codes not equal to expected {self.code}.\"\n",
    "            ]\n",
    "        elif self.status == -2:\n",
    "            summary = [\n",
    "                f\"Detected regression with long request time.\",\n",
    "                f\"Expected max-avg-time: ({self.max_avg_time:.3f}s <= {self.max_time:.3f}s).\"\n",
    "            ]\n",
    "        elif self.status == -3:\n",
    "            summary = [\n",
    "                f\"Maximum number of timeout ({self.timeout_abort}s) requests exceeded ({self.timeout_count}).\",\n",
    "                \"Test was aborted to avoid further delays.\"\n",
    "            ]\n",
    "        summary.append(f\"Test {'succeeded' if self.status == 0 else 'failed'} (status={self.status}).\")\n",
    "        summary = (\"\\n\" + offset * \" \").join(summary)\n",
    "        return cleandoc(f\"\"\"\n",
    "        Stress Test:\n",
    "            Test:\n",
    "                code: {self.code}\n",
    "                runs: {self.runs}\n",
    "                max-avg-time:  {self.max_avg_time}s\n",
    "                max-err-code:  {self.max_err_code}\n",
    "                sum-err-code:  {self.sum_err_code}\n",
    "                timeout-abort: {self.timeout_abort}s\n",
    "                timeout-retry: {self.timeout_retry}\n",
    "                timeout-count: {self.timeout_count}\n",
    "            Request:\n",
    "                method: {self.method}\n",
    "                url:    {self.url}\n",
    "                args:   {self.request_args}\n",
    "            Times:\n",
    "                min: {self.min_time:.3f}s\n",
    "                avg: {self.avg_time:.3f}s\n",
    "                max: {self.max_time:.3f}s\n",
    "            Results:\n",
    "                {header}\n",
    "                {lines}\n",
    "            Summary:\n",
    "                {summary}\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "def stress_test_requests(progression: Progression, url: str, method=\"GET\", runs=100, code=200, delays=True,\n",
    "                         max_err_code=0, max_avg_time=None,\n",
    "                         abort_timeout=5, abort_retries=3, **req_kwargs) -> StressTestResult:\n",
    "    \"\"\"\n",
    "    Executes the request for the number of demanded runs and validates the expected status is always returned.\n",
    "\n",
    "    Outputs the results of each request and a summary of their execution time.\n",
    "    If requested, also validates that all responses were returned on average faster than the maximum allowed time.\n",
    "\n",
    "    :param url: endpoint to stress test\n",
    "    :param method: HTTP method for request\n",
    "    :param runs: number of stress test request\n",
    "    :param code: expected HTTP code from requests\n",
    "    :param delays: whether to apply small random delays between requests\n",
    "       Otherwise, sequential requests are executed as quickly as possible, when the previous response is obtained.\n",
    "    :param max_err_code: maximum amount of erroneous HTTP status code allowed to consider the test successful.\n",
    "    :param max_avg_time: maximum average time of requests permitted to consider the test successful.\n",
    "    :param abort_timeout: duration to wait until a request is aborted, sets 408 (Read Timeout) as HTTP status code.\n",
    "    :param abort_retries: number of failed timeout requests allowed before abort of whole stress test for this endpoint.\n",
    "    :returns:\n",
    "        StressTestResult with individual request results and one of below status:\n",
    "        -  0 (success) for no error and all conditions achieved\n",
    "        - -1 (failure) for maximum amount of HTT error code reached\n",
    "        - -2 (failure) for maximum request time on average reached\n",
    "        - -3 (failure) for aborted test due to too many timeout\n",
    "    \"\"\"\n",
    "    thread_name = threading.current_thread().name\n",
    "    req_kwargs.pop(\"timeout\", None)\n",
    "    result = StressTestResult()\n",
    "    result.runs = runs\n",
    "    result.url = url\n",
    "    result.method = method\n",
    "    result.request_args = req_kwargs\n",
    "    result.max_err_code = max_err_code\n",
    "    result.max_avg_time = max_avg_time\n",
    "    result.abort_timeout = abort_timeout\n",
    "    result.abort_retries = abort_retries\n",
    "    result.codes = []\n",
    "    result.times = []\n",
    "    result.timestamps = []\n",
    "    result.delta = [0.] + [float((random.randint(1, 100) / 1000) if delays else 0) for _ in range(1, runs)]\n",
    "\n",
    "    char = len(str(runs))\n",
    "    for i in range(runs):\n",
    "        start = time.perf_counter()\n",
    "        try:\n",
    "            resp = requests.request(method, url, timeout=abort_timeout, **req_kwargs)\n",
    "        except requests.exceptions.Timeout:\n",
    "            result.times.append(abort_timeout)\n",
    "            result.codes.append(408)  # read timeout\n",
    "            result.timeout_count += 1\n",
    "        else:\n",
    "            result.times.append(time.perf_counter() - start)\n",
    "            result.timestamps.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            result.codes.append(resp.status_code)\n",
    "        if resp.status_code == 500:\n",
    "            print(resp.text)\n",
    "        if result.timeout_count > abort_timeout:\n",
    "            result.status = -3\n",
    "            print(f\"Aborted: Too Many Timeout ({result.timeout_count})\")\n",
    "            return result\n",
    "        if i == runs:\n",
    "            break\n",
    "        if result.delta[i]:\n",
    "            time.sleep(result.delta[i])\n",
    "        progress_update = 50\n",
    "        if i!=0 and not (i-1)%progress_update:\n",
    "            progression.increase(progress_update)\n",
    "    if max_avg_time and result.avg_time > max_avg_time:\n",
    "        result.status = -2\n",
    "    elif len([c for c in result.codes if c == code]) >= (runs - max_err_code):\n",
    "        result.status = 0\n",
    "    else:\n",
    "        result.status = -1\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_threads(target_test, url, execution_id:int = 1, n_threads:int = 1, runs_per_threads:int = 100):\n",
    "    \"\"\"\n",
    "    This methode launch n new thread with the target fonction to be executed.\n",
    "    \n",
    "    :param target_test: Fonction to be executed by the threads\n",
    "    :param url: url to be called by the test\n",
    "    :param execution_id: execution id to keep track of multiple execution, if this fonction is ran in a loop \n",
    "    :param n_threads: number of threads to be launched \n",
    "    :param runs_per_threads: number of stress test request per threads\n",
    "    \"\"\"\n",
    "    \n",
    "    progression = Progression(n_threads, runs_per_threads)\n",
    "\n",
    "    line = '-'*104\n",
    "    print(line)\n",
    "    print(f'URL Execution-{execution_id}')\n",
    "    print(f'- Starting {n_threads} threads with {runs_per_threads} runs per threads targeting \"{target_test.__name__}\" fonction.')\n",
    "    print(f'- URL : {url}')\n",
    "    print(f'- Initial progression values : {progression}')\n",
    "    print(line)\n",
    "\n",
    "    \n",
    "    threads_list = [Thread(target = target_test, args=(url, progression), name=f\"Thread-{i+1}\") for i in range(n_threads)]\n",
    "    \n",
    "    for t in threads_list:\n",
    "        t.start()\n",
    "        \n",
    "    for t in threads_list:\n",
    "        t.join()\n",
    "        \n",
    "    \n",
    "        \n",
    "def stress_test(url:str, progression: Progression):\n",
    "    \"\"\"\n",
    "    This methode launch n new thread with the target fonction to be executed.\n",
    "    \n",
    "    :param url: url to be requested \n",
    "    :param progression: Progression object to follow the progress of all requests\n",
    "    \"\"\"\n",
    "    \n",
    "    failed_count = 0\n",
    "    failed_results = \"\"\n",
    "    \n",
    "    n_runs = progression.runs_per_threads\n",
    "\n",
    "    expect_status_code = 200\n",
    "    results = stress_test_requests(progression, url, runs=n_runs, code=expect_status_code,\n",
    "                                   max_err_code=TEST_MAX_ERR_CODE, max_avg_time=TEST_MAX_AVG_TIME,\n",
    "                                   abort_retries=TEST_TIMEOUT_RETRY, abort_timeout=TEST_TIMEOUT_ABORT)\n",
    "    \n",
    "    thread_name = threading.current_thread().name\n",
    "    print(f\"\\n({thread_name}) Stress Test with [{n_runs}] calls \\n to : [{url}]\")\n",
    "    print(results)\n",
    "    if results.status != 0:\n",
    "        failed_count += 1\n",
    "        failed_results = f\"{failed_results}\\n{results}\"\n",
    "            \n",
    "    assert failed_count == 0, f\"Failed {failed_count} tests.  Failed results: {failed_results}\"\n",
    "    print(f\"\\n{thread_name} : All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# # Executing WPS test on multiple threads\n",
    "# wps_urls = [f\"{TWITCHER_URL}/{bird}/wps?service=wps&request=getcapabilities\" for bird in TEST_WPS_BIRDS]\n",
    "\n",
    "# for execution, url in enumerate(wps_urls):\n",
    "#     run_threads(target_test = stress_test,\n",
    "#                 url = url,\n",
    "#                 execution_id = execution,\n",
    "#                 n_threads = TEST_N_THREADS_WPS,\n",
    "#                 runs_per_threads = TEST_RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Executing THREDDS test on multiple threads\n",
    "thredds_url = f\"{TWITCHER_URL}/thredds/catalog/birdhouse/testdata/catalog.html?dataset=birdhouse/testdata/ta_Amon_MRI-CGCM3_decadal1980_r1i1p1_199101-200012.nc\"\n",
    "\n",
    "run_threads(target_test = stress_test,\n",
    "            url = thredds_url,\n",
    "            n_threads = TEST_N_THREADS_THREDDS,\n",
    "            runs_per_threads = TEST_RUNS_THREDDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
