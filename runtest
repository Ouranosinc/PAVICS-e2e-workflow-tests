#!/bin/sh

DEFAULT_PRODUCTION_HOST="pavics.ouranos.ca"

NOTEBOOKS="$1"
if [ -z "$NOTEBOOKS" ]; then
    NOTEBOOKS="notebooks/*.ipynb"
fi

set -x

if [ -n "$FORCE_PAVICS_HOST" ]; then
    # jenkins work-around for envinject incompatibility with pipeline
    echo "FORCE_PAVICS_HOST='$FORCE_PAVICS_HOST'"
    echo "Overriding PAVICS_HOST with value from FORCE_PAVICS_HOST"
    PAVICS_HOST="$FORCE_PAVICS_HOST"
fi

if [ ! -z "$PAVICS_HOST" ]; then
    echo "Will run notebooks against $PAVICS_HOST"

    if [ -z "$TEST_NO_USE_PROD_DATA" ]; then
        # * .ncml links will always comes from the production server, not the server
        # under test since we do not perform regex replace for .ncml links.
        #
        # * Any lines marked with TEST_USE_PROD_DATA will also use data from prod
        # and avoid having to replicate data to test servers.
        sed -i "/\(\.ncml\|TEST_USE_PROD_DATA\)/!s/$DEFAULT_PRODUCTION_HOST/$PAVICS_HOST/g" $NOTEBOOKS
    else
        # Change everything to $PAVICS_HOST (system under test).
        sed -i "s/$DEFAULT_PRODUCTION_HOST/$PAVICS_HOST/g" $NOTEBOOKS
    fi

    git diff  # not working for notebooks from other repos
fi

# suppress "InsecureRequestWarning: Unverified HTTPS request is being made"
# so tests still pass when user want to disable ssl cert verification
export PYTHONWARNINGS="ignore:Unverified HTTPS request"

# Allow full override of ALL configs before running test suite.
if [ -n "$CONFIG_OVERRIDE_SCRIPT_URL" ]; then
    TMP_CONF_OVERRIDE="/tmp/conf_override"
    rm -vf "$TMP_CONF_OVERRIDE"

    # Log URL for traceability.
    echo "CONFIG_OVERRIDE_SCRIPT_URL=$CONFIG_OVERRIDE_SCRIPT_URL"
    curl "$CONFIG_OVERRIDE_SCRIPT_URL" --output "$TMP_CONF_OVERRIDE"

    # Log content of override script for traceability.
    echo "=== START config override script ========================
$TMP_CONF_OVERRIDE
===END config override script ========================
"
    # Source script so it can alter ALL existing variables in the current context.
    . "$TMP_CONF_OVERRIDE"
fi

py.test --nbval $NOTEBOOKS --sanitize-with notebooks/output-sanitize.cfg $PYTEST_EXTRA_OPTS
EXIT_CODE="$?"

# lowercase SAVE_RESULTING_NOTEBOOK string
SAVE_RESULTING_NOTEBOOK="`echo "$SAVE_RESULTING_NOTEBOOK" | tr '[:upper:]' '[:lower:]'`"


# save notebooks resulting from the run
# this might not be the same as what py.test have seen since it's another run

# user can manually diff the original with the resulting notebooks this way:
# nbdiff original.ipynb resulting.ipynb.output.ipynb (conda install nbdime)

# work-around as nbval can not save the result of the run
# see https://github.com/computationalmodelling/nbval/issues/112

if [ x"$SAVE_RESULTING_NOTEBOOK" = xtrue ]; then
    mkdir -p buildout
    for nb in $NOTEBOOKS; do
        filename="`basename "$nb"`"
        filename="`echo "$filename" | sed "s/.ipynb$//"`"  # remove .ipynb ext
        if [ -e "buildout/${filename}.output.ipynb" ]; then
            # prevent name clash
            filename="${filename}_`date '+%s'`"
        fi
        # Timeout must not be more than 240s (4 mins).
        # Tutorial notebooks should be fast so user do not lose patience waiting
        # for them to run.  If more than 4 mins, in addition to simplifying the
        # notebook, should also check machine performance.
        jupyter nbconvert --to notebook --execute \
            --ExecutePreprocessor.timeout=240 --allow-errors \
            --output-dir buildout --output "${filename}.output.ipynb" "$nb"
    done
fi

# exit with return code from py.test
exit $EXIT_CODE
